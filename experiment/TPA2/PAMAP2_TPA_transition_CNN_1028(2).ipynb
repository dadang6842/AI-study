{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E4uCySeItgam",
        "outputId": "e8a0a34b-033e-4821-b10a-50942f0e3f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "================================================================================\n",
            "UNIFIED MODEL COMPARISON: GAP vs TPA vs Gated-TPA\n",
            "================================================================================\n",
            "\n",
            "Total datasets to test: 32\n",
            "  - Original: 1\n",
            "  - transitions: 32\n",
            "\n",
            "[Progress: 1/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Standing_TO_Walking_10PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Standing_TO_Walking_10PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Standing_TO_Walking_10PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9441, Val Acc=0.9434, F1=0.9358\n",
            "  Epoch  20: Train Acc=0.9753, Val Acc=0.9719, F1=0.9695\n",
            "  Epoch  30: Train Acc=0.9856, Val Acc=0.9820, F1=0.9810\n",
            "  Epoch  40: Train Acc=0.9901, Val Acc=0.9870, F1=0.9864\n",
            "  Epoch  50: Train Acc=0.9928, Val Acc=0.9876, F1=0.9868\n",
            "  Epoch  60: Train Acc=0.9937, Val Acc=0.9896, F1=0.9893\n",
            "  Epoch  70: Train Acc=0.9950, Val Acc=0.9920, F1=0.9917\n",
            "  Epoch  80: Train Acc=0.9957, Val Acc=0.9920, F1=0.9916\n",
            "  Epoch  90: Train Acc=0.9958, Val Acc=0.9924, F1=0.9918\n",
            "  Epoch 100: Train Acc=0.9963, Val Acc=0.9925, F1=0.9919\n",
            "  Best Val Acc: 0.9936\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9936\n",
            "  Test Acc: 0.9920, F1: 0.9914\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9683, Val Acc=0.9567, F1=0.9498\n",
            "  Epoch  20: Train Acc=0.9886, Val Acc=0.9760, F1=0.9743\n",
            "  Epoch  30: Train Acc=0.9942, Val Acc=0.9785, F1=0.9763\n",
            "  Epoch  40: Train Acc=0.9955, Val Acc=0.9807, F1=0.9786\n",
            "  Epoch  50: Train Acc=0.9969, Val Acc=0.9832, F1=0.9820\n",
            "  Epoch  60: Train Acc=0.9972, Val Acc=0.9839, F1=0.9817\n",
            "  Epoch  70: Train Acc=0.9972, Val Acc=0.9852, F1=0.9838\n",
            "  Epoch  80: Train Acc=0.9978, Val Acc=0.9849, F1=0.9826\n",
            "  Epoch  90: Train Acc=0.9977, Val Acc=0.9822, F1=0.9802\n",
            "  Epoch 100: Train Acc=0.9978, Val Acc=0.9845, F1=0.9827\n",
            "  Best Val Acc: 0.9864\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9864\n",
            "  Test Acc: 0.9848, F1: 0.9829\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9660, Val Acc=0.9598, F1=0.9518\n",
            "  Epoch  20: Train Acc=0.9883, Val Acc=0.9719, F1=0.9678\n",
            "  Epoch  30: Train Acc=0.9934, Val Acc=0.9765, F1=0.9738\n",
            "  Epoch  40: Train Acc=0.9955, Val Acc=0.9763, F1=0.9731\n",
            "  Epoch  50: Train Acc=0.9963, Val Acc=0.9789, F1=0.9766\n",
            "  Epoch  60: Train Acc=0.9975, Val Acc=0.9797, F1=0.9766\n",
            "  Epoch  70: Train Acc=0.9970, Val Acc=0.9803, F1=0.9780\n",
            "  Epoch  80: Train Acc=0.9973, Val Acc=0.9803, F1=0.9773\n",
            "  Epoch  90: Train Acc=0.9973, Val Acc=0.9803, F1=0.9771\n",
            "  Early stopping at epoch 92\n",
            "  Best Val Acc: 0.9822\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9822\n",
            "  Test Acc: 0.9807, F1: 0.9782\n",
            "\n",
            "[Progress: 2/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Standing_TO_Walking_20PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Standing_TO_Walking_20PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Standing_TO_Walking_20PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9460, Val Acc=0.9430, F1=0.9377\n",
            "  Epoch  20: Train Acc=0.9752, Val Acc=0.9727, F1=0.9708\n",
            "  Epoch  30: Train Acc=0.9851, Val Acc=0.9825, F1=0.9821\n",
            "  Epoch  40: Train Acc=0.9902, Val Acc=0.9860, F1=0.9855\n",
            "  Epoch  50: Train Acc=0.9922, Val Acc=0.9874, F1=0.9871\n",
            "  Epoch  60: Train Acc=0.9935, Val Acc=0.9902, F1=0.9901\n",
            "  Epoch  70: Train Acc=0.9954, Val Acc=0.9918, F1=0.9919\n",
            "  Epoch  80: Train Acc=0.9957, Val Acc=0.9912, F1=0.9906\n",
            "  Epoch  90: Train Acc=0.9961, Val Acc=0.9924, F1=0.9923\n",
            "  Epoch 100: Train Acc=0.9969, Val Acc=0.9933, F1=0.9932\n",
            "  Best Val Acc: 0.9933\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9933\n",
            "  Test Acc: 0.9925, F1: 0.9922\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9694, Val Acc=0.9594, F1=0.9517\n",
            "  Epoch  20: Train Acc=0.9893, Val Acc=0.9749, F1=0.9703\n",
            "  Epoch  30: Train Acc=0.9947, Val Acc=0.9807, F1=0.9777\n",
            "  Epoch  40: Train Acc=0.9960, Val Acc=0.9827, F1=0.9801\n",
            "  Epoch  50: Train Acc=0.9970, Val Acc=0.9823, F1=0.9799\n",
            "  Epoch  60: Train Acc=0.9971, Val Acc=0.9832, F1=0.9807\n",
            "  Epoch  70: Train Acc=0.9978, Val Acc=0.9826, F1=0.9807\n",
            "  Epoch  80: Train Acc=0.9980, Val Acc=0.9845, F1=0.9828\n",
            "  Epoch  90: Train Acc=0.9982, Val Acc=0.9833, F1=0.9819\n",
            "  Epoch 100: Train Acc=0.9983, Val Acc=0.9838, F1=0.9820\n",
            "  Best Val Acc: 0.9854\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9854\n",
            "  Test Acc: 0.9840, F1: 0.9820\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9664, Val Acc=0.9569, F1=0.9504\n",
            "  Epoch  20: Train Acc=0.9888, Val Acc=0.9744, F1=0.9717\n",
            "  Epoch  30: Train Acc=0.9937, Val Acc=0.9794, F1=0.9765\n",
            "  Epoch  40: Train Acc=0.9955, Val Acc=0.9801, F1=0.9780\n",
            "  Epoch  50: Train Acc=0.9959, Val Acc=0.9807, F1=0.9787\n",
            "  Epoch  60: Train Acc=0.9962, Val Acc=0.9806, F1=0.9771\n",
            "  Epoch  70: Train Acc=0.9968, Val Acc=0.9804, F1=0.9775\n",
            "  Epoch  80: Train Acc=0.9970, Val Acc=0.9814, F1=0.9783\n",
            "  Epoch  90: Train Acc=0.9973, Val Acc=0.9829, F1=0.9807\n",
            "  Epoch 100: Train Acc=0.9976, Val Acc=0.9826, F1=0.9801\n",
            "  Best Val Acc: 0.9839\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9839\n",
            "  Test Acc: 0.9813, F1: 0.9790\n",
            "\n",
            "[Progress: 3/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Standing_TO_Walking_30PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Standing_TO_Walking_30PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Standing_TO_Walking_30PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9434, Val Acc=0.9443, F1=0.9359\n",
            "  Epoch  20: Train Acc=0.9745, Val Acc=0.9681, F1=0.9630\n",
            "  Epoch  30: Train Acc=0.9847, Val Acc=0.9813, F1=0.9792\n",
            "  Epoch  40: Train Acc=0.9894, Val Acc=0.9844, F1=0.9833\n",
            "  Epoch  50: Train Acc=0.9924, Val Acc=0.9880, F1=0.9871\n",
            "  Epoch  60: Train Acc=0.9940, Val Acc=0.9893, F1=0.9884\n",
            "  Epoch  70: Train Acc=0.9944, Val Acc=0.9893, F1=0.9882\n",
            "  Epoch  80: Train Acc=0.9952, Val Acc=0.9911, F1=0.9908\n",
            "  Epoch  90: Train Acc=0.9958, Val Acc=0.9920, F1=0.9917\n",
            "  Epoch 100: Train Acc=0.9963, Val Acc=0.9921, F1=0.9917\n",
            "  Best Val Acc: 0.9927\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9927\n",
            "  Test Acc: 0.9911, F1: 0.9903\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9689, Val Acc=0.9577, F1=0.9494\n",
            "  Epoch  20: Train Acc=0.9893, Val Acc=0.9751, F1=0.9718\n",
            "  Epoch  30: Train Acc=0.9948, Val Acc=0.9789, F1=0.9764\n",
            "  Epoch  40: Train Acc=0.9955, Val Acc=0.9820, F1=0.9792\n",
            "  Epoch  50: Train Acc=0.9967, Val Acc=0.9830, F1=0.9807\n",
            "  Epoch  60: Train Acc=0.9967, Val Acc=0.9835, F1=0.9812\n",
            "  Epoch  70: Train Acc=0.9978, Val Acc=0.9848, F1=0.9825\n",
            "  Epoch  80: Train Acc=0.9974, Val Acc=0.9842, F1=0.9824\n",
            "  Epoch  90: Train Acc=0.9982, Val Acc=0.9857, F1=0.9833\n",
            "  Epoch 100: Train Acc=0.9981, Val Acc=0.9857, F1=0.9830\n",
            "  Best Val Acc: 0.9874\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9874\n",
            "  Test Acc: 0.9846, F1: 0.9827\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9639, Val Acc=0.9563, F1=0.9466\n",
            "  Epoch  20: Train Acc=0.9885, Val Acc=0.9715, F1=0.9669\n",
            "  Epoch  30: Train Acc=0.9935, Val Acc=0.9769, F1=0.9731\n",
            "  Epoch  40: Train Acc=0.9949, Val Acc=0.9797, F1=0.9767\n",
            "  Epoch  50: Train Acc=0.9957, Val Acc=0.9788, F1=0.9757\n",
            "  Epoch  60: Train Acc=0.9969, Val Acc=0.9811, F1=0.9790\n",
            "  Epoch  70: Train Acc=0.9970, Val Acc=0.9801, F1=0.9773\n",
            "  Epoch  80: Train Acc=0.9972, Val Acc=0.9811, F1=0.9780\n",
            "  Epoch  90: Train Acc=0.9974, Val Acc=0.9830, F1=0.9807\n",
            "  Epoch 100: Train Acc=0.9977, Val Acc=0.9819, F1=0.9792\n",
            "  Best Val Acc: 0.9841\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9841\n",
            "  Test Acc: 0.9820, F1: 0.9806\n",
            "\n",
            "[Progress: 4/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Standing_TO_Walking_40PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Standing_TO_Walking_40PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Standing_TO_Walking_40PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9440, Val Acc=0.9465, F1=0.9374\n",
            "  Epoch  20: Train Acc=0.9750, Val Acc=0.9725, F1=0.9677\n",
            "  Epoch  30: Train Acc=0.9851, Val Acc=0.9804, F1=0.9771\n",
            "  Epoch  40: Train Acc=0.9902, Val Acc=0.9860, F1=0.9845\n",
            "  Epoch  50: Train Acc=0.9927, Val Acc=0.9884, F1=0.9871\n",
            "  Epoch  60: Train Acc=0.9939, Val Acc=0.9896, F1=0.9889\n",
            "  Epoch  70: Train Acc=0.9955, Val Acc=0.9914, F1=0.9905\n",
            "  Epoch  80: Train Acc=0.9960, Val Acc=0.9909, F1=0.9898\n",
            "  Epoch  90: Train Acc=0.9963, Val Acc=0.9920, F1=0.9911\n",
            "  Epoch 100: Train Acc=0.9965, Val Acc=0.9924, F1=0.9919\n",
            "  Best Val Acc: 0.9930\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9930\n",
            "  Test Acc: 0.9905, F1: 0.9893\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9690, Val Acc=0.9608, F1=0.9513\n",
            "  Epoch  20: Train Acc=0.9900, Val Acc=0.9779, F1=0.9752\n",
            "  Epoch  30: Train Acc=0.9949, Val Acc=0.9787, F1=0.9752\n",
            "  Epoch  40: Train Acc=0.9958, Val Acc=0.9827, F1=0.9794\n",
            "  Epoch  50: Train Acc=0.9971, Val Acc=0.9832, F1=0.9811\n",
            "  Epoch  60: Train Acc=0.9975, Val Acc=0.9839, F1=0.9813\n",
            "  Epoch  70: Train Acc=0.9977, Val Acc=0.9845, F1=0.9821\n",
            "  Epoch  80: Train Acc=0.9980, Val Acc=0.9854, F1=0.9829\n",
            "  Early stopping at epoch 82\n",
            "  Best Val Acc: 0.9858\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9858\n",
            "  Test Acc: 0.9820, F1: 0.9795\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9646, Val Acc=0.9563, F1=0.9469\n",
            "  Epoch  20: Train Acc=0.9880, Val Acc=0.9737, F1=0.9689\n",
            "  Epoch  30: Train Acc=0.9937, Val Acc=0.9792, F1=0.9755\n",
            "  Epoch  40: Train Acc=0.9956, Val Acc=0.9779, F1=0.9738\n",
            "  Epoch  50: Train Acc=0.9960, Val Acc=0.9778, F1=0.9739\n",
            "  Epoch  60: Train Acc=0.9973, Val Acc=0.9791, F1=0.9750\n",
            "  Epoch  70: Train Acc=0.9971, Val Acc=0.9808, F1=0.9770\n",
            "  Epoch  80: Train Acc=0.9974, Val Acc=0.9803, F1=0.9771\n",
            "  Early stopping at epoch 85\n",
            "  Best Val Acc: 0.9822\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9822\n",
            "  Test Acc: 0.9775, F1: 0.9740\n",
            "\n",
            "[Progress: 5/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Walking_TO_Standing_10PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Walking_TO_Standing_10PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Walking_TO_Standing_10PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9446, Val Acc=0.9415, F1=0.9315\n",
            "  Epoch  20: Train Acc=0.9743, Val Acc=0.9716, F1=0.9679\n",
            "  Epoch  30: Train Acc=0.9851, Val Acc=0.9779, F1=0.9758\n",
            "  Epoch  40: Train Acc=0.9897, Val Acc=0.9825, F1=0.9810\n",
            "  Epoch  50: Train Acc=0.9921, Val Acc=0.9860, F1=0.9845\n",
            "  Epoch  60: Train Acc=0.9947, Val Acc=0.9880, F1=0.9870\n",
            "  Epoch  70: Train Acc=0.9951, Val Acc=0.9896, F1=0.9892\n",
            "  Epoch  80: Train Acc=0.9965, Val Acc=0.9902, F1=0.9895\n",
            "  Epoch  90: Train Acc=0.9967, Val Acc=0.9914, F1=0.9909\n",
            "  Epoch 100: Train Acc=0.9966, Val Acc=0.9921, F1=0.9918\n",
            "  Best Val Acc: 0.9927\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9927\n",
            "  Test Acc: 0.9915, F1: 0.9903\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9718, Val Acc=0.9621, F1=0.9564\n",
            "  Epoch  20: Train Acc=0.9890, Val Acc=0.9756, F1=0.9729\n",
            "  Epoch  30: Train Acc=0.9947, Val Acc=0.9788, F1=0.9764\n",
            "  Epoch  40: Train Acc=0.9963, Val Acc=0.9825, F1=0.9808\n",
            "  Epoch  50: Train Acc=0.9967, Val Acc=0.9825, F1=0.9805\n",
            "  Epoch  60: Train Acc=0.9972, Val Acc=0.9825, F1=0.9803\n",
            "  Epoch  70: Train Acc=0.9979, Val Acc=0.9832, F1=0.9815\n",
            "  Early stopping at epoch 76\n",
            "  Best Val Acc: 0.9839\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9839\n",
            "  Test Acc: 0.9832, F1: 0.9809\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9691, Val Acc=0.9534, F1=0.9455\n",
            "  Epoch  20: Train Acc=0.9890, Val Acc=0.9725, F1=0.9687\n",
            "  Epoch  30: Train Acc=0.9947, Val Acc=0.9762, F1=0.9731\n",
            "  Epoch  40: Train Acc=0.9962, Val Acc=0.9781, F1=0.9754\n",
            "  Epoch  50: Train Acc=0.9964, Val Acc=0.9785, F1=0.9757\n",
            "  Early stopping at epoch 58\n",
            "  Best Val Acc: 0.9798\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9798\n",
            "  Test Acc: 0.9786, F1: 0.9749\n",
            "\n",
            "[Progress: 6/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Walking_TO_Standing_20PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Walking_TO_Standing_20PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Walking_TO_Standing_20PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9430, Val Acc=0.9434, F1=0.9337\n",
            "  Epoch  20: Train Acc=0.9738, Val Acc=0.9738, F1=0.9700\n",
            "  Epoch  30: Train Acc=0.9844, Val Acc=0.9798, F1=0.9774\n",
            "  Epoch  40: Train Acc=0.9891, Val Acc=0.9842, F1=0.9826\n",
            "  Epoch  50: Train Acc=0.9920, Val Acc=0.9861, F1=0.9848\n",
            "  Epoch  60: Train Acc=0.9935, Val Acc=0.9889, F1=0.9877\n",
            "  Epoch  70: Train Acc=0.9950, Val Acc=0.9892, F1=0.9883\n",
            "  Epoch  80: Train Acc=0.9954, Val Acc=0.9901, F1=0.9887\n",
            "  Epoch  90: Train Acc=0.9956, Val Acc=0.9909, F1=0.9901\n",
            "  Epoch 100: Train Acc=0.9967, Val Acc=0.9917, F1=0.9909\n",
            "  Best Val Acc: 0.9918\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9918\n",
            "  Test Acc: 0.9920, F1: 0.9916\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9713, Val Acc=0.9624, F1=0.9571\n",
            "  Epoch  20: Train Acc=0.9895, Val Acc=0.9744, F1=0.9711\n",
            "  Epoch  30: Train Acc=0.9944, Val Acc=0.9788, F1=0.9755\n",
            "  Epoch  40: Train Acc=0.9959, Val Acc=0.9803, F1=0.9774\n",
            "  Epoch  50: Train Acc=0.9973, Val Acc=0.9810, F1=0.9787\n",
            "  Epoch  60: Train Acc=0.9976, Val Acc=0.9816, F1=0.9790\n",
            "  Epoch  70: Train Acc=0.9973, Val Acc=0.9822, F1=0.9798\n",
            "  Epoch  80: Train Acc=0.9980, Val Acc=0.9836, F1=0.9815\n",
            "  Epoch  90: Train Acc=0.9976, Val Acc=0.9822, F1=0.9799\n",
            "  Epoch 100: Train Acc=0.9984, Val Acc=0.9825, F1=0.9803\n",
            "  Best Val Acc: 0.9839\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9839\n",
            "  Test Acc: 0.9857, F1: 0.9837\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9677, Val Acc=0.9561, F1=0.9489\n",
            "  Epoch  20: Train Acc=0.9876, Val Acc=0.9719, F1=0.9690\n",
            "  Epoch  30: Train Acc=0.9944, Val Acc=0.9747, F1=0.9716\n",
            "  Epoch  40: Train Acc=0.9958, Val Acc=0.9760, F1=0.9725\n",
            "  Epoch  50: Train Acc=0.9965, Val Acc=0.9751, F1=0.9715\n",
            "  Epoch  60: Train Acc=0.9966, Val Acc=0.9769, F1=0.9740\n",
            "  Early stopping at epoch 61\n",
            "  Best Val Acc: 0.9791\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9791\n",
            "  Test Acc: 0.9782, F1: 0.9753\n",
            "\n",
            "[Progress: 7/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Walking_TO_Standing_30PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Walking_TO_Standing_30PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Walking_TO_Standing_30PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9433, Val Acc=0.9458, F1=0.9377\n",
            "  Epoch  20: Train Acc=0.9754, Val Acc=0.9708, F1=0.9674\n",
            "  Epoch  30: Train Acc=0.9860, Val Acc=0.9811, F1=0.9791\n",
            "  Epoch  40: Train Acc=0.9898, Val Acc=0.9857, F1=0.9843\n",
            "  Epoch  50: Train Acc=0.9923, Val Acc=0.9877, F1=0.9869\n",
            "  Epoch  60: Train Acc=0.9944, Val Acc=0.9874, F1=0.9867\n",
            "  Epoch  70: Train Acc=0.9952, Val Acc=0.9890, F1=0.9883\n",
            "  Epoch  80: Train Acc=0.9961, Val Acc=0.9889, F1=0.9884\n",
            "  Epoch  90: Train Acc=0.9962, Val Acc=0.9901, F1=0.9895\n",
            "  Early stopping at epoch 92\n",
            "  Best Val Acc: 0.9908\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9908\n",
            "  Test Acc: 0.9898, F1: 0.9888\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9730, Val Acc=0.9613, F1=0.9556\n",
            "  Epoch  20: Train Acc=0.9915, Val Acc=0.9734, F1=0.9699\n",
            "  Epoch  30: Train Acc=0.9949, Val Acc=0.9763, F1=0.9739\n",
            "  Epoch  40: Train Acc=0.9960, Val Acc=0.9800, F1=0.9784\n",
            "  Epoch  50: Train Acc=0.9970, Val Acc=0.9794, F1=0.9772\n",
            "  Epoch  60: Train Acc=0.9972, Val Acc=0.9807, F1=0.9787\n",
            "  Epoch  70: Train Acc=0.9978, Val Acc=0.9817, F1=0.9796\n",
            "  Epoch  80: Train Acc=0.9975, Val Acc=0.9822, F1=0.9802\n",
            "  Epoch  90: Train Acc=0.9978, Val Acc=0.9823, F1=0.9806\n",
            "  Epoch 100: Train Acc=0.9979, Val Acc=0.9822, F1=0.9801\n",
            "  Best Val Acc: 0.9841\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9841\n",
            "  Test Acc: 0.9840, F1: 0.9820\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9676, Val Acc=0.9545, F1=0.9472\n",
            "  Epoch  20: Train Acc=0.9898, Val Acc=0.9697, F1=0.9664\n",
            "  Epoch  30: Train Acc=0.9943, Val Acc=0.9731, F1=0.9702\n",
            "  Epoch  40: Train Acc=0.9958, Val Acc=0.9744, F1=0.9720\n",
            "  Epoch  50: Train Acc=0.9960, Val Acc=0.9751, F1=0.9727\n",
            "  Epoch  60: Train Acc=0.9967, Val Acc=0.9760, F1=0.9735\n",
            "  Epoch  70: Train Acc=0.9967, Val Acc=0.9759, F1=0.9731\n",
            "  Epoch  80: Train Acc=0.9973, Val Acc=0.9749, F1=0.9723\n",
            "  Early stopping at epoch 85\n",
            "  Best Val Acc: 0.9778\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9778\n",
            "  Test Acc: 0.9784, F1: 0.9760\n",
            "\n",
            "[Progress: 8/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Walking_TO_Standing_40PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Walking_TO_Standing_40PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Walking_TO_Standing_40PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9434, Val Acc=0.9469, F1=0.9384\n",
            "  Epoch  20: Train Acc=0.9732, Val Acc=0.9743, F1=0.9707\n",
            "  Epoch  30: Train Acc=0.9848, Val Acc=0.9823, F1=0.9798\n",
            "  Epoch  40: Train Acc=0.9885, Val Acc=0.9855, F1=0.9840\n",
            "  Epoch  50: Train Acc=0.9913, Val Acc=0.9899, F1=0.9889\n",
            "  Epoch  60: Train Acc=0.9930, Val Acc=0.9906, F1=0.9899\n",
            "  Epoch  70: Train Acc=0.9942, Val Acc=0.9908, F1=0.9900\n",
            "  Epoch  80: Train Acc=0.9949, Val Acc=0.9918, F1=0.9911\n",
            "  Epoch  90: Train Acc=0.9955, Val Acc=0.9924, F1=0.9916\n",
            "  Epoch 100: Train Acc=0.9963, Val Acc=0.9928, F1=0.9921\n",
            "  Best Val Acc: 0.9930\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9930\n",
            "  Test Acc: 0.9904, F1: 0.9895\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9705, Val Acc=0.9618, F1=0.9566\n",
            "  Epoch  20: Train Acc=0.9894, Val Acc=0.9747, F1=0.9710\n",
            "  Epoch  30: Train Acc=0.9935, Val Acc=0.9782, F1=0.9753\n",
            "  Epoch  40: Train Acc=0.9955, Val Acc=0.9813, F1=0.9790\n",
            "  Epoch  50: Train Acc=0.9964, Val Acc=0.9838, F1=0.9819\n",
            "  Epoch  60: Train Acc=0.9970, Val Acc=0.9832, F1=0.9814\n",
            "  Epoch  70: Train Acc=0.9970, Val Acc=0.9835, F1=0.9815\n",
            "  Epoch  80: Train Acc=0.9974, Val Acc=0.9836, F1=0.9825\n",
            "  Epoch  90: Train Acc=0.9974, Val Acc=0.9832, F1=0.9816\n",
            "  Early stopping at epoch 92\n",
            "  Best Val Acc: 0.9857\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9857\n",
            "  Test Acc: 0.9842, F1: 0.9829\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9656, Val Acc=0.9580, F1=0.9503\n",
            "  Epoch  20: Train Acc=0.9886, Val Acc=0.9741, F1=0.9708\n",
            "  Epoch  30: Train Acc=0.9937, Val Acc=0.9775, F1=0.9743\n",
            "  Epoch  40: Train Acc=0.9959, Val Acc=0.9782, F1=0.9750\n",
            "  Epoch  50: Train Acc=0.9961, Val Acc=0.9797, F1=0.9771\n",
            "  Epoch  60: Train Acc=0.9965, Val Acc=0.9816, F1=0.9788\n",
            "  Epoch  70: Train Acc=0.9968, Val Acc=0.9792, F1=0.9761\n",
            "  Epoch  80: Train Acc=0.9973, Val Acc=0.9784, F1=0.9753\n",
            "  Early stopping at epoch 84\n",
            "  Best Val Acc: 0.9825\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9825\n",
            "  Test Acc: 0.9771, F1: 0.9741\n",
            "\n",
            "[Progress: 9/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Walking_TO_Running_10PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Walking_TO_Running_10PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Walking_TO_Running_10PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9425, Val Acc=0.9494, F1=0.9415\n",
            "  Epoch  20: Train Acc=0.9752, Val Acc=0.9727, F1=0.9680\n",
            "  Epoch  30: Train Acc=0.9856, Val Acc=0.9778, F1=0.9742\n",
            "  Epoch  40: Train Acc=0.9893, Val Acc=0.9811, F1=0.9783\n",
            "  Epoch  50: Train Acc=0.9925, Val Acc=0.9844, F1=0.9818\n",
            "  Epoch  60: Train Acc=0.9935, Val Acc=0.9867, F1=0.9846\n",
            "  Epoch  70: Train Acc=0.9949, Val Acc=0.9889, F1=0.9874\n",
            "  Epoch  80: Train Acc=0.9959, Val Acc=0.9887, F1=0.9869\n",
            "  Epoch  90: Train Acc=0.9958, Val Acc=0.9905, F1=0.9892\n",
            "  Epoch 100: Train Acc=0.9961, Val Acc=0.9923, F1=0.9909\n",
            "  Best Val Acc: 0.9923\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9923\n",
            "  Test Acc: 0.9927, F1: 0.9920\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9712, Val Acc=0.9640, F1=0.9571\n",
            "  Epoch  20: Train Acc=0.9899, Val Acc=0.9750, F1=0.9705\n",
            "  Epoch  30: Train Acc=0.9944, Val Acc=0.9795, F1=0.9761\n",
            "  Epoch  40: Train Acc=0.9958, Val Acc=0.9822, F1=0.9791\n",
            "  Epoch  50: Train Acc=0.9965, Val Acc=0.9825, F1=0.9795\n",
            "  Epoch  60: Train Acc=0.9972, Val Acc=0.9830, F1=0.9802\n",
            "  Epoch  70: Train Acc=0.9973, Val Acc=0.9822, F1=0.9792\n",
            "  Epoch  80: Train Acc=0.9977, Val Acc=0.9833, F1=0.9807\n",
            "  Epoch  90: Train Acc=0.9978, Val Acc=0.9830, F1=0.9807\n",
            "  Early stopping at epoch 97\n",
            "  Best Val Acc: 0.9846\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9846\n",
            "  Test Acc: 0.9846, F1: 0.9826\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9679, Val Acc=0.9611, F1=0.9540\n",
            "  Epoch  20: Train Acc=0.9895, Val Acc=0.9732, F1=0.9695\n",
            "  Epoch  30: Train Acc=0.9935, Val Acc=0.9744, F1=0.9707\n",
            "  Epoch  40: Train Acc=0.9958, Val Acc=0.9781, F1=0.9749\n",
            "  Epoch  50: Train Acc=0.9962, Val Acc=0.9798, F1=0.9768\n",
            "  Epoch  60: Train Acc=0.9966, Val Acc=0.9801, F1=0.9773\n",
            "  Epoch  70: Train Acc=0.9969, Val Acc=0.9807, F1=0.9778\n",
            "  Epoch  80: Train Acc=0.9974, Val Acc=0.9832, F1=0.9808\n",
            "  Epoch  90: Train Acc=0.9971, Val Acc=0.9829, F1=0.9803\n",
            "  Early stopping at epoch 92\n",
            "  Best Val Acc: 0.9833\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9833\n",
            "  Test Acc: 0.9806, F1: 0.9773\n",
            "\n",
            "[Progress: 10/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Walking_TO_Running_20PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Walking_TO_Running_20PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Walking_TO_Running_20PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9444, Val Acc=0.9443, F1=0.9354\n",
            "  Epoch  20: Train Acc=0.9750, Val Acc=0.9694, F1=0.9649\n",
            "  Epoch  30: Train Acc=0.9856, Val Acc=0.9785, F1=0.9761\n",
            "  Epoch  40: Train Acc=0.9902, Val Acc=0.9822, F1=0.9803\n",
            "  Epoch  50: Train Acc=0.9919, Val Acc=0.9845, F1=0.9831\n",
            "  Epoch  60: Train Acc=0.9941, Val Acc=0.9883, F1=0.9874\n",
            "  Epoch  70: Train Acc=0.9948, Val Acc=0.9882, F1=0.9872\n",
            "  Epoch  80: Train Acc=0.9957, Val Acc=0.9892, F1=0.9883\n",
            "  Epoch  90: Train Acc=0.9959, Val Acc=0.9903, F1=0.9898\n",
            "  Epoch 100: Train Acc=0.9962, Val Acc=0.9909, F1=0.9903\n",
            "  Best Val Acc: 0.9915\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9915\n",
            "  Test Acc: 0.9909, F1: 0.9898\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9715, Val Acc=0.9595, F1=0.9532\n",
            "  Epoch  20: Train Acc=0.9903, Val Acc=0.9718, F1=0.9678\n",
            "  Epoch  30: Train Acc=0.9946, Val Acc=0.9768, F1=0.9739\n",
            "  Epoch  40: Train Acc=0.9957, Val Acc=0.9784, F1=0.9756\n",
            "  Epoch  50: Train Acc=0.9966, Val Acc=0.9813, F1=0.9790\n",
            "  Epoch  60: Train Acc=0.9975, Val Acc=0.9806, F1=0.9779\n",
            "  Epoch  70: Train Acc=0.9976, Val Acc=0.9811, F1=0.9788\n",
            "  Epoch  80: Train Acc=0.9976, Val Acc=0.9830, F1=0.9810\n",
            "  Epoch  90: Train Acc=0.9980, Val Acc=0.9814, F1=0.9793\n",
            "  Epoch 100: Train Acc=0.9979, Val Acc=0.9827, F1=0.9810\n",
            "  Early stopping at epoch 100\n",
            "  Best Val Acc: 0.9830\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9830\n",
            "  Test Acc: 0.9833, F1: 0.9810\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9673, Val Acc=0.9558, F1=0.9494\n",
            "  Epoch  20: Train Acc=0.9894, Val Acc=0.9722, F1=0.9684\n",
            "  Epoch  30: Train Acc=0.9946, Val Acc=0.9737, F1=0.9704\n",
            "  Epoch  40: Train Acc=0.9958, Val Acc=0.9757, F1=0.9724\n",
            "  Epoch  50: Train Acc=0.9962, Val Acc=0.9778, F1=0.9753\n",
            "  Epoch  60: Train Acc=0.9966, Val Acc=0.9775, F1=0.9748\n",
            "  Epoch  70: Train Acc=0.9974, Val Acc=0.9792, F1=0.9765\n",
            "  Epoch  80: Train Acc=0.9971, Val Acc=0.9776, F1=0.9747\n",
            "  Epoch  90: Train Acc=0.9973, Val Acc=0.9800, F1=0.9777\n",
            "  Epoch 100: Train Acc=0.9973, Val Acc=0.9794, F1=0.9765\n",
            "  Best Val Acc: 0.9813\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9813\n",
            "  Test Acc: 0.9794, F1: 0.9762\n",
            "\n",
            "[Progress: 11/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Walking_TO_Running_30PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Walking_TO_Running_30PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Walking_TO_Running_30PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9440, Val Acc=0.9431, F1=0.9335\n",
            "  Epoch  20: Train Acc=0.9753, Val Acc=0.9706, F1=0.9658\n",
            "  Epoch  30: Train Acc=0.9848, Val Acc=0.9797, F1=0.9771\n",
            "  Epoch  40: Train Acc=0.9899, Val Acc=0.9848, F1=0.9826\n",
            "  Epoch  50: Train Acc=0.9923, Val Acc=0.9861, F1=0.9840\n",
            "  Epoch  60: Train Acc=0.9940, Val Acc=0.9867, F1=0.9851\n",
            "  Epoch  70: Train Acc=0.9955, Val Acc=0.9887, F1=0.9871\n",
            "  Epoch  80: Train Acc=0.9957, Val Acc=0.9898, F1=0.9881\n",
            "  Epoch  90: Train Acc=0.9969, Val Acc=0.9918, F1=0.9906\n",
            "  Epoch 100: Train Acc=0.9963, Val Acc=0.9911, F1=0.9898\n",
            "  Best Val Acc: 0.9918\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9918\n",
            "  Test Acc: 0.9918, F1: 0.9912\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9709, Val Acc=0.9594, F1=0.9534\n",
            "  Epoch  20: Train Acc=0.9893, Val Acc=0.9759, F1=0.9722\n",
            "  Epoch  30: Train Acc=0.9942, Val Acc=0.9782, F1=0.9754\n",
            "  Epoch  40: Train Acc=0.9961, Val Acc=0.9811, F1=0.9783\n",
            "  Epoch  50: Train Acc=0.9969, Val Acc=0.9807, F1=0.9785\n",
            "  Epoch  60: Train Acc=0.9969, Val Acc=0.9797, F1=0.9770\n",
            "  Epoch  70: Train Acc=0.9974, Val Acc=0.9810, F1=0.9789\n",
            "  Epoch  80: Train Acc=0.9973, Val Acc=0.9819, F1=0.9801\n",
            "  Early stopping at epoch 87\n",
            "  Best Val Acc: 0.9832\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9832\n",
            "  Test Acc: 0.9827, F1: 0.9807\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9678, Val Acc=0.9561, F1=0.9488\n",
            "  Epoch  20: Train Acc=0.9891, Val Acc=0.9715, F1=0.9671\n",
            "  Epoch  30: Train Acc=0.9939, Val Acc=0.9741, F1=0.9707\n",
            "  Epoch  40: Train Acc=0.9952, Val Acc=0.9776, F1=0.9744\n",
            "  Epoch  50: Train Acc=0.9963, Val Acc=0.9772, F1=0.9738\n",
            "  Epoch  60: Train Acc=0.9966, Val Acc=0.9775, F1=0.9742\n",
            "  Epoch  70: Train Acc=0.9963, Val Acc=0.9797, F1=0.9767\n",
            "  Epoch  80: Train Acc=0.9972, Val Acc=0.9789, F1=0.9758\n",
            "  Epoch  90: Train Acc=0.9974, Val Acc=0.9797, F1=0.9770\n",
            "  Early stopping at epoch 92\n",
            "  Best Val Acc: 0.9806\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9806\n",
            "  Test Acc: 0.9813, F1: 0.9788\n",
            "\n",
            "[Progress: 12/32]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: Walking_TO_Running_40PCT\n",
            "================================================================================\n",
            "\n",
            "Loading Walking_TO_Running_40PCT...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets/Walking_TO_Running_40PCT\n",
            "  Train: (34192, 100, 27), Test: (8549, 100, 27)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 27353, Val: 6839, Test: 8549\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9426, Val Acc=0.9468, F1=0.9390\n",
            "  Epoch  20: Train Acc=0.9746, Val Acc=0.9706, F1=0.9665\n",
            "  Epoch  30: Train Acc=0.9854, Val Acc=0.9768, F1=0.9739\n",
            "  Epoch  40: Train Acc=0.9901, Val Acc=0.9848, F1=0.9838\n",
            "  Epoch  50: Train Acc=0.9928, Val Acc=0.9855, F1=0.9845\n",
            "  Epoch  60: Train Acc=0.9936, Val Acc=0.9868, F1=0.9856\n",
            "  Epoch  70: Train Acc=0.9947, Val Acc=0.9884, F1=0.9873\n",
            "  Epoch  80: Train Acc=0.9958, Val Acc=0.9884, F1=0.9874\n",
            "  Epoch  90: Train Acc=0.9962, Val Acc=0.9896, F1=0.9889\n",
            "  Epoch 100: Train Acc=0.9963, Val Acc=0.9898, F1=0.9887\n",
            "  Best Val Acc: 0.9903\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9903\n",
            "  Test Acc: 0.9895, F1: 0.9882\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9696, Val Acc=0.9615, F1=0.9559\n",
            "  Epoch  20: Train Acc=0.9907, Val Acc=0.9750, F1=0.9719\n",
            "  Epoch  30: Train Acc=0.9953, Val Acc=0.9792, F1=0.9770\n",
            "  Epoch  40: Train Acc=0.9959, Val Acc=0.9826, F1=0.9805\n",
            "  Epoch  50: Train Acc=0.9966, Val Acc=0.9810, F1=0.9789\n",
            "  Epoch  60: Train Acc=0.9971, Val Acc=0.9833, F1=0.9814\n",
            "  Epoch  70: Train Acc=0.9976, Val Acc=0.9833, F1=0.9816\n",
            "  Epoch  80: Train Acc=0.9977, Val Acc=0.9835, F1=0.9817\n",
            "  Epoch  90: Train Acc=0.9981, Val Acc=0.9819, F1=0.9802\n",
            "  Epoch 100: Train Acc=0.9982, Val Acc=0.9825, F1=0.9816\n",
            "  Best Val Acc: 0.9846\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9846\n",
            "  Test Acc: 0.9825, F1: 0.9803\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9668, Val Acc=0.9553, F1=0.9478\n",
            "  Epoch  20: Train Acc=0.9882, Val Acc=0.9709, F1=0.9671\n",
            "  Epoch  30: Train Acc=0.9946, Val Acc=0.9769, F1=0.9744\n",
            "  Epoch  40: Train Acc=0.9957, Val Acc=0.9765, F1=0.9740\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3328399198.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n[Progress: {i}/{len(datasets)}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3328399198.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(dataset_name, cfg)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;31m# Create and train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# Evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3328399198.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, cfg, model_name)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3328399198.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, opt, cfg)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Unified Model Comparison: GAP, TPA, Gated-TPA\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, random, time, copy, json\n",
        "import numpy as np\n",
        "from typing import Tuple, Dict, List\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ========================\n",
        "# Config & Reproducibility\n",
        "# ========================\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    data_dir: str = \"/content/drive/MyDrive/AI_data/TPA2/pamap2_transition_datasets\"\n",
        "    save_dir: str = \"/content/drive/MyDrive/AI_data/TPA2\"\n",
        "\n",
        "    epochs: int = 100\n",
        "    batch_size: int = 128\n",
        "    lr: float = 1e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    grad_clip: float = 1.0\n",
        "    label_smoothing: float = 0.05\n",
        "\n",
        "    patience: int = 20\n",
        "    min_delta: float = 0.0001\n",
        "    val_split: float = 0.2\n",
        "\n",
        "    d_model: int = 128\n",
        "\n",
        "    # TPA hyperparameters\n",
        "    tpa_num_prototypes: int = 16\n",
        "    tpa_heads: int = 4\n",
        "    tpa_dropout: float = 0.1\n",
        "    tpa_temperature: float = 0.07\n",
        "    tpa_topk_ratio: float = 0.25\n",
        "\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    num_workers: int = 2\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# ========================\n",
        "# Dataset Class\n",
        "# ========================\n",
        "class PreloadedDataset(Dataset):\n",
        "    \"\"\"Dataset for pre-loaded numpy arrays\"\"\"\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
        "        super().__init__()\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "\n",
        "        # Label     (1-6 -> 0-5)\n",
        "        if y.min() >= 1:\n",
        "            y = y - 1\n",
        "\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ========================\n",
        "# Data Loading Functions\n",
        "# ========================\n",
        "def load_dataset(base_dir: str, dataset_name: str):\n",
        "    \"\"\"\n",
        "    Load pre-augmented dataset\n",
        "    Args:\n",
        "        base_dir: base directory containing all datasets\n",
        "        dataset_name: e.g., \"ORIGINAL\", \"STANDING_TO_SITTING_10pct\", etc.\n",
        "    Returns:\n",
        "        train_dataset, test_dataset\n",
        "    \"\"\"\n",
        "    dataset_dir = os.path.join(base_dir, dataset_name)\n",
        "\n",
        "    print(f\"\\nLoading {dataset_name}...\")\n",
        "    print(f\"  Path: {dataset_dir}\")\n",
        "\n",
        "    # Load data\n",
        "    X_train = np.load(os.path.join(dataset_dir, \"X_train.npy\"))\n",
        "    y_train = np.load(os.path.join(dataset_dir, \"y_train.npy\"))\n",
        "    X_test = np.load(os.path.join(dataset_dir, \"X_test.npy\"))\n",
        "    y_test = np.load(os.path.join(dataset_dir, \"y_test.npy\"))\n",
        "\n",
        "    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "    train_dataset = PreloadedDataset(X_train, y_train)\n",
        "    test_dataset = PreloadedDataset(X_test, y_test)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "# ========================\n",
        "# Model Components\n",
        "# ========================\n",
        "class ConvBNAct(nn.Module):\n",
        "    def __init__(self, c_in, c_out, k, s=1, p=None, g=1):\n",
        "        super().__init__()\n",
        "        self.c = nn.Conv1d(c_in, c_out, k, s, k//2 if p is None else p, groups=g, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(c_out)\n",
        "        self.act = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.c(x)))\n",
        "\n",
        "class MultiPathCNN(nn.Module):\n",
        "    \"\"\"Shared backbone for all models\"\"\"\n",
        "    def __init__(self, in_ch=27, d_model=128, branches=(3,5,9,15), stride=2):\n",
        "        super().__init__()\n",
        "        h = d_model // 2\n",
        "        self.pre = ConvBNAct(in_ch, h, 1)\n",
        "        self.branches = nn.ModuleList([\n",
        "            nn.Sequential(ConvBNAct(h, h, k, stride, g=h), ConvBNAct(h, h, 1))\n",
        "            for k in branches\n",
        "        ])\n",
        "        self.post = ConvBNAct(len(branches)*h, d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.post(torch.cat([b(self.pre(x)) for b in self.branches], dim=1))\n",
        "\n",
        "# ========================\n",
        "# GAP Model\n",
        "# ========================\n",
        "class GAPModel(nn.Module):\n",
        "    \"\"\"Baseline: Global Average Pooling\"\"\"\n",
        "    def __init__(self, d_model=128, num_classes=12):\n",
        "        super().__init__()\n",
        "        self.backbone = MultiPathCNN(d_model=d_model)\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [B, T, C] -> transpose to [B, C, T] for Conv1d\n",
        "        x = x.transpose(1, 2)  # [B, C, T]\n",
        "        fmap = self.backbone(x)  # [B, D, T]\n",
        "        features = fmap.transpose(1, 2)  # [B, T, D]\n",
        "        pooled = features.mean(dim=1)  # [B, D]\n",
        "        logits = self.fc(pooled)\n",
        "        return logits\n",
        "\n",
        "# ========================\n",
        "# Pure-TPA\n",
        "# ========================\n",
        "class ProductionTPA(nn.Module):\n",
        "    \"\"\"Pure TPA\"\"\"\n",
        "    def __init__(self, dim, num_prototypes=16, heads=4, dropout=0.1,\n",
        "                 temperature=0.07, topk_ratio=0.25):\n",
        "        super().__init__()\n",
        "        assert dim % heads == 0\n",
        "\n",
        "        self.dim = dim\n",
        "        self.heads = heads\n",
        "        self.head_dim = dim // heads\n",
        "        self.num_prototypes = num_prototypes\n",
        "        self.temperature = temperature\n",
        "        self.topk_ratio = topk_ratio\n",
        "\n",
        "        self.proto = nn.Parameter(torch.randn(num_prototypes, dim) * 0.02)\n",
        "\n",
        "        self.pre_norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.q_proj = nn.Linear(dim, dim, bias=False)\n",
        "        self.k_proj = nn.Linear(dim, dim, bias=False)\n",
        "        self.v_proj = nn.Linear(dim, dim, bias=False)\n",
        "\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, D = x.shape\n",
        "        P = self.num_prototypes\n",
        "\n",
        "        x_norm = self.pre_norm(x)\n",
        "\n",
        "        K = self.k_proj(x_norm)\n",
        "        V = self.v_proj(x_norm)\n",
        "        Qp = self.q_proj(self.proto).unsqueeze(0).expand(B, -1, -1)\n",
        "\n",
        "        def split_heads(t, length):\n",
        "            return t.view(B, length, self.heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        Qh = split_heads(Qp, P)\n",
        "        Kh = split_heads(K, T)\n",
        "        Vh = split_heads(V, T)\n",
        "\n",
        "        Qh = F.normalize(Qh, dim=-1)\n",
        "        Kh = F.normalize(Kh, dim=-1)\n",
        "\n",
        "        scores = torch.matmul(Qh, Kh.transpose(-2, -1)) / self.temperature\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        attn = torch.nan_to_num(attn, nan=0.0)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        proto_tokens = torch.matmul(attn, Vh)\n",
        "        proto_tokens = proto_tokens.transpose(1, 2).contiguous().view(B, P, D)\n",
        "\n",
        "        z_tpa = proto_tokens.mean(dim=1)\n",
        "\n",
        "        z = self.fuse(z_tpa)\n",
        "\n",
        "        return z\n",
        "\n",
        "class TPAModel(nn.Module):\n",
        "    def __init__(self, d_model=128, num_classes=12, tpa_config=None):\n",
        "        super().__init__()\n",
        "        self.backbone = MultiPathCNN(d_model=d_model)\n",
        "        self.tpa = ProductionTPA(\n",
        "            dim=d_model,\n",
        "            num_prototypes=tpa_config['num_prototypes'],\n",
        "            heads=tpa_config['heads'],\n",
        "            dropout=tpa_config['dropout'],\n",
        "            temperature=tpa_config['temperature'],\n",
        "            topk_ratio=tpa_config['topk_ratio']\n",
        "        )\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [B, T, C] -> transpose to [B, C, T] for Conv1d\n",
        "        x = x.transpose(1, 2)  # [B, C, T]\n",
        "        fmap = self.backbone(x)  # [B, D, T]\n",
        "        features = fmap.transpose(1, 2)  # [B, T, D]\n",
        "        z = self.tpa(features)  # [B, D]\n",
        "        logits = self.classifier(z)\n",
        "        return logits\n",
        "\n",
        "# ========================\n",
        "# Gated-TPA\n",
        "# ========================\n",
        "class GatedTPAModel(nn.Module):\n",
        "    def __init__(self, d_model=128, num_classes=12, tpa_config=None):\n",
        "        super().__init__()\n",
        "        self.backbone = MultiPathCNN(d_model=d_model)\n",
        "        self.tpa = ProductionTPA(\n",
        "            dim=d_model,\n",
        "            num_prototypes=tpa_config['num_prototypes'],\n",
        "            heads=tpa_config['heads'],\n",
        "            dropout=tpa_config['dropout'],\n",
        "            temperature=tpa_config['temperature'],\n",
        "            topk_ratio=tpa_config['topk_ratio']\n",
        "        )\n",
        "\n",
        "        # Gating mechanism\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(d_model * 2, d_model),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [B, T, C] -> transpose to [B, C, T] for Conv1d\n",
        "        x = x.transpose(1, 2)  # [B, C, T]\n",
        "        fmap = self.backbone(x)  # [B, D, T]\n",
        "        features = fmap.transpose(1, 2)  # [B, T, D]\n",
        "\n",
        "        # GAP branch\n",
        "        z_gap = features.mean(dim=1)  # [B, D]\n",
        "\n",
        "        # TPA branch\n",
        "        z_tpa = self.tpa(features)  # [B, D]\n",
        "\n",
        "        # Gating\n",
        "        gate_input = torch.cat([z_gap, z_tpa], dim=-1)\n",
        "        g = self.gate(gate_input)\n",
        "\n",
        "        # Gated fusion\n",
        "        z = g * z_gap + (1 - g) * z_tpa\n",
        "\n",
        "        logits = self.classifier(z)\n",
        "        return logits\n",
        "\n",
        "# ========================\n",
        "# Training & Evaluation\n",
        "# ========================\n",
        "def train_one_epoch(model, loader, opt, cfg: Config):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(cfg.device).float(), y.to(cfg.device)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(x)\n",
        "\n",
        "        loss = F.cross_entropy(logits, y, label_smoothing=cfg.label_smoothing)\n",
        "        if torch.isnan(loss):\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "        opt.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = logits.argmax(dim=-1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            loss_sum += loss.item() * y.size(0)\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss_sum / total if total > 0 else 0,\n",
        "        \"acc\": correct / total if total > 0 else 0\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, cfg: Config):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(cfg.device), y.to(cfg.device)\n",
        "        logits = model(x)\n",
        "        ps.append(logits.argmax(dim=-1).cpu().numpy())\n",
        "        ys.append(y.cpu().numpy())\n",
        "\n",
        "    y_true, y_pred = np.concatenate(ys), np.concatenate(ps)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return acc, f1\n",
        "\n",
        "def train_model(model, train_loader, val_loader, cfg: Config, model_name: str):\n",
        "    \"\"\"Train a single model\"\"\"\n",
        "    print(f\"\\n[Training {model_name}]\")\n",
        "\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "\n",
        "    best_acc, best_wts = 0.0, None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, cfg.epochs + 1):\n",
        "        stats = train_one_epoch(model, train_loader, opt, cfg)\n",
        "        val_acc, val_f1 = evaluate(model, val_loader, cfg)\n",
        "\n",
        "        if val_acc > best_acc + cfg.min_delta:\n",
        "            best_acc = val_acc\n",
        "            best_wts = copy.deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"  Epoch {epoch:3d}: Train Acc={stats['acc']:.4f}, Val Acc={val_acc:.4f}, F1={val_f1:.4f}\")\n",
        "\n",
        "        if patience_counter >= cfg.patience:\n",
        "            print(f\"  Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    if best_wts:\n",
        "        model.load_state_dict(best_wts)\n",
        "\n",
        "    print(f\"  Best Val Acc: {best_acc:.4f}\")\n",
        "    return best_acc\n",
        "\n",
        "def create_model(model_name: str, cfg: Config):\n",
        "    \"\"\"Create model by name\"\"\"\n",
        "    tpa_config = {\n",
        "        'num_prototypes': cfg.tpa_num_prototypes,\n",
        "        'heads': cfg.tpa_heads,\n",
        "        'dropout': cfg.tpa_dropout,\n",
        "        'temperature': cfg.tpa_temperature,\n",
        "        'topk_ratio': cfg.tpa_topk_ratio\n",
        "    }\n",
        "\n",
        "    if model_name == \"GAP\":\n",
        "        return GAPModel(d_model=cfg.d_model).to(cfg.device).float()\n",
        "    elif model_name == \"TPA\":\n",
        "        return TPAModel(d_model=cfg.d_model, tpa_config=tpa_config).to(cfg.device).float()\n",
        "    elif model_name == \"Gated-TPA\":\n",
        "        return GatedTPAModel(d_model=cfg.d_model, tpa_config=tpa_config).to(cfg.device).float()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "\n",
        "# ========================\n",
        "# Main Experiment\n",
        "# ========================\n",
        "def run_experiment(dataset_name: str, cfg: Config):\n",
        "    \"\"\"Run complete experiment for one dataset\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EXPERIMENT: {dataset_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Load data\n",
        "    train_dataset, test_dataset = load_dataset(cfg.data_dir, dataset_name)\n",
        "\n",
        "    # Split train into train/val using indices\n",
        "    n_total = len(train_dataset)\n",
        "    indices = np.arange(n_total)\n",
        "\n",
        "    # Get labels for stratification\n",
        "    y_labels = train_dataset.y.numpy()\n",
        "\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        indices,\n",
        "        test_size=cfg.val_split,\n",
        "        random_state=SEED,\n",
        "        stratify=y_labels\n",
        "    )\n",
        "\n",
        "    # Create subsets using Subset\n",
        "    from torch.utils.data import Subset\n",
        "    train_subset = Subset(train_dataset, train_indices)\n",
        "    val_subset = Subset(train_dataset, val_indices)\n",
        "\n",
        "    # Create data loaders\n",
        "    g = torch.Generator(device='cpu').manual_seed(SEED)\n",
        "    train_loader = DataLoader(train_subset, cfg.batch_size, shuffle=True,\n",
        "                              num_workers=cfg.num_workers, generator=g)\n",
        "    val_loader = DataLoader(val_subset, cfg.batch_size, num_workers=cfg.num_workers)\n",
        "    test_loader = DataLoader(test_dataset, cfg.batch_size, num_workers=cfg.num_workers)\n",
        "\n",
        "    print(f\"\\nDataset splits:\")\n",
        "    print(f\"  Train: {len(train_subset)}, Val: {len(val_subset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "    # Train and evaluate all models\n",
        "    results = []\n",
        "    model_names = [\"GAP\", \"TPA\", \"Gated-TPA\"]\n",
        "\n",
        "    for model_name in model_names:\n",
        "        # Reset seed for each model\n",
        "        random.seed(SEED)\n",
        "        np.random.seed(SEED)\n",
        "        torch.manual_seed(SEED)\n",
        "\n",
        "        # Create and train model\n",
        "        model = create_model(model_name, cfg)\n",
        "        best_val_acc = train_model(model, train_loader, val_loader, cfg, model_name)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_acc, test_f1 = evaluate(model, test_loader, cfg)\n",
        "\n",
        "        print(f\"\\n[{model_name} Results]\")\n",
        "        print(f\"  Val Acc: {best_val_acc:.4f}\")\n",
        "        print(f\"  Test Acc: {test_acc:.4f}, F1: {test_f1:.4f}\")\n",
        "\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Dataset': dataset_name,\n",
        "            'Val_Accuracy': float(best_val_acc),\n",
        "            'Test_Accuracy': float(test_acc),\n",
        "            'Test_F1_Score': float(test_f1)\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# ========================\n",
        "# Run All Experiments\n",
        "# ========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"UNIFIED MODEL COMPARISON: GAP vs TPA vs Gated-TPA\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    datasets = []\n",
        "\n",
        "    transitions = [\n",
        "        'Standing_TO_Walking',\n",
        "        'Walking_TO_Standing',\n",
        "        'Walking_TO_Running',\n",
        "        'Running_TO_Walking',\n",
        "        'Walking_TO_Ascending_stairs',\n",
        "        'Walking_TO_Descending_stairs',\n",
        "        'Ascending_stairs_TO_Walking',\n",
        "        'Descending_stairs_TO_Walking'\n",
        "    ]\n",
        "\n",
        "    #    10%, 20%, 30%, 40% \n",
        "    mix_pcts = [10, 20, 30, 40]\n",
        "\n",
        "    for transition in transitions:\n",
        "        for pct in mix_pcts:\n",
        "            datasets.append(f\"{transition}_{pct}PCT\")\n",
        "\n",
        "    print(f\"\\nTotal datasets to test: {len(datasets)}\")\n",
        "    print(f\"  - Original: 1\")\n",
        "    print(f\"  - transitions: {len(transitions) * len(mix_pcts)}\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Run experiments\n",
        "    for i, dataset_name in enumerate(datasets, 1):\n",
        "        print(f\"\\n[Progress: {i}/{len(datasets)}]\")\n",
        "        results = run_experiment(dataset_name, cfg)\n",
        "        all_results.extend(results)\n",
        "\n",
        "    # Save all results\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SAVING RESULTS\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    results_dict = {\n",
        "        'experiment_info': {\n",
        "            'date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'models': ['GAP', 'TPA', 'Gated-TPA'],\n",
        "            'total_datasets': len(datasets),\n",
        "            'datasets': datasets,\n",
        "            'config': {\n",
        "                'epochs': cfg.epochs,\n",
        "                'batch_size': cfg.batch_size,\n",
        "                'lr': cfg.lr,\n",
        "                'd_model': cfg.d_model,\n",
        "                'tpa_num_prototypes': cfg.tpa_num_prototypes,\n",
        "                'tpa_heads': cfg.tpa_heads\n",
        "            }\n",
        "        },\n",
        "        'results': all_results\n",
        "    }\n",
        "\n",
        "    # Save to JSON\n",
        "    json_path = os.path.join(cfg.save_dir, \"pamap2_tpa_transition_cnn.json\")\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(results_dict, f, indent=2)\n",
        "\n",
        "    print(f\"\\nResults saved to: {json_path}\")\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Total experiments: {len(all_results)}\")\n",
        "    print(f\"Total datasets tested: {len(datasets)}\")\n",
        "    print(f\"Models compared: 3 (GAP, TPA, Gated-TPA)\")\n",
        "\n",
        "    # Calculate average performance per model\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"AVERAGE PERFORMANCE (All Datasets)\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    for model_name in ['GAP', 'TPA', 'Gated-TPA']:\n",
        "        model_results = [r for r in all_results if r['Model'] == model_name]\n",
        "        avg_acc = np.mean([r['Test_Accuracy'] for r in model_results])\n",
        "        avg_f1 = np.mean([r['Test_F1_Score'] for r in model_results])\n",
        "        print(f\"{model_name:12s}: Acc={avg_acc:.4f}, F1={avg_f1:.4f}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"EXPERIMENT COMPLETE\")\n",
        "    print(f\"{'='*80}\")"
      ]
    }
  ]
}