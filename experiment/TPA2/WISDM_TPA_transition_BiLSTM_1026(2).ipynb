{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj7xi96X01yO",
        "outputId": "aff5ee6d-11c4-4416-e488-4a64811bc46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "================================================================================\n",
            "UNIFIED MODEL COMPARISON: GAP vs TPA vs Gated-TPA\n",
            "Testing on 41 Datasets (1 Original + 40 Transition)\n",
            "================================================================================\n",
            "\n",
            "Total datasets to test: 27\n",
            "  - transitions: 27\n",
            "\n",
            "[Progress: 1/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_STANDING_20pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_STANDING_20pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_STANDING_20pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9055, Val Acc=0.9079, F1=0.8578\n",
            "  Epoch  20: Train Acc=0.9452, Val Acc=0.9541, F1=0.9281\n",
            "  Epoch  30: Train Acc=0.9628, Val Acc=0.9619, F1=0.9408\n",
            "  Epoch  40: Train Acc=0.9716, Val Acc=0.9772, F1=0.9631\n",
            "  Epoch  50: Train Acc=0.9784, Val Acc=0.9774, F1=0.9639\n",
            "  Epoch  60: Train Acc=0.9839, Val Acc=0.9855, F1=0.9777\n",
            "  Epoch  70: Train Acc=0.9855, Val Acc=0.9874, F1=0.9797\n",
            "  Epoch  80: Train Acc=0.9884, Val Acc=0.9878, F1=0.9800\n",
            "  Epoch  90: Train Acc=0.9915, Val Acc=0.9899, F1=0.9832\n",
            "  Epoch 100: Train Acc=0.9920, Val Acc=0.9888, F1=0.9823\n",
            "  Best Val Acc: 0.9915\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9915\n",
            "  Test Acc: 0.9881, F1: 0.9820\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9591, Val Acc=0.9696, F1=0.9482\n",
            "  Epoch  20: Train Acc=0.9830, Val Acc=0.9872, F1=0.9758\n",
            "  Epoch  30: Train Acc=0.9897, Val Acc=0.9901, F1=0.9833\n",
            "  Epoch  40: Train Acc=0.9923, Val Acc=0.9917, F1=0.9859\n",
            "  Epoch  50: Train Acc=0.9939, Val Acc=0.9932, F1=0.9868\n",
            "  Early stopping at epoch 58\n",
            "  Best Val Acc: 0.9936\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9936\n",
            "  Test Acc: 0.9911, F1: 0.9851\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9559, Val Acc=0.9679, F1=0.9468\n",
            "  Epoch  20: Train Acc=0.9788, Val Acc=0.9859, F1=0.9756\n",
            "  Epoch  30: Train Acc=0.9875, Val Acc=0.9907, F1=0.9841\n",
            "  Epoch  40: Train Acc=0.9906, Val Acc=0.9923, F1=0.9864\n",
            "  Epoch  50: Train Acc=0.9930, Val Acc=0.9905, F1=0.9849\n",
            "  Epoch  60: Train Acc=0.9945, Val Acc=0.9923, F1=0.9881\n",
            "  Epoch  70: Train Acc=0.9958, Val Acc=0.9928, F1=0.9878\n",
            "  Epoch  80: Train Acc=0.9969, Val Acc=0.9928, F1=0.9872\n",
            "  Early stopping at epoch 83\n",
            "  Best Val Acc: 0.9938\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9938\n",
            "  Test Acc: 0.9897, F1: 0.9835\n",
            "\n",
            "[Progress: 2/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_STANDING_30pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_STANDING_30pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_STANDING_30pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9075, Val Acc=0.9104, F1=0.8581\n",
            "  Epoch  20: Train Acc=0.9416, Val Acc=0.9478, F1=0.9189\n",
            "  Epoch  30: Train Acc=0.9624, Val Acc=0.9617, F1=0.9391\n",
            "  Epoch  40: Train Acc=0.9725, Val Acc=0.9725, F1=0.9567\n",
            "  Epoch  50: Train Acc=0.9794, Val Acc=0.9787, F1=0.9641\n",
            "  Epoch  60: Train Acc=0.9822, Val Acc=0.9820, F1=0.9703\n",
            "  Epoch  70: Train Acc=0.9869, Val Acc=0.9855, F1=0.9757\n",
            "  Epoch  80: Train Acc=0.9872, Val Acc=0.9832, F1=0.9725\n",
            "  Epoch  90: Train Acc=0.9897, Val Acc=0.9861, F1=0.9779\n",
            "  Epoch 100: Train Acc=0.9918, Val Acc=0.9865, F1=0.9771\n",
            "  Best Val Acc: 0.9888\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9888\n",
            "  Test Acc: 0.9881, F1: 0.9801\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9614, Val Acc=0.9632, F1=0.9363\n",
            "  Epoch  20: Train Acc=0.9826, Val Acc=0.9837, F1=0.9703\n",
            "  Epoch  30: Train Acc=0.9888, Val Acc=0.9874, F1=0.9767\n",
            "  Epoch  40: Train Acc=0.9932, Val Acc=0.9892, F1=0.9802\n",
            "  Epoch  50: Train Acc=0.9944, Val Acc=0.9894, F1=0.9814\n",
            "  Epoch  60: Train Acc=0.9955, Val Acc=0.9892, F1=0.9820\n",
            "  Early stopping at epoch 66\n",
            "  Best Val Acc: 0.9915\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9915\n",
            "  Test Acc: 0.9874, F1: 0.9777\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9596, Val Acc=0.9667, F1=0.9447\n",
            "  Epoch  20: Train Acc=0.9816, Val Acc=0.9810, F1=0.9664\n",
            "  Epoch  30: Train Acc=0.9897, Val Acc=0.9855, F1=0.9748\n",
            "  Epoch  40: Train Acc=0.9927, Val Acc=0.9861, F1=0.9784\n",
            "  Epoch  50: Train Acc=0.9948, Val Acc=0.9894, F1=0.9822\n",
            "  Epoch  60: Train Acc=0.9960, Val Acc=0.9884, F1=0.9813\n",
            "  Epoch  70: Train Acc=0.9969, Val Acc=0.9880, F1=0.9804\n",
            "  Early stopping at epoch 70\n",
            "  Best Val Acc: 0.9894\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9894\n",
            "  Test Acc: 0.9854, F1: 0.9756\n",
            "\n",
            "[Progress: 3/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_STANDING_40pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_STANDING_40pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_STANDING_40pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9066, Val Acc=0.9191, F1=0.8765\n",
            "  Epoch  20: Train Acc=0.9398, Val Acc=0.9431, F1=0.9109\n",
            "  Epoch  30: Train Acc=0.9637, Val Acc=0.9642, F1=0.9465\n",
            "  Epoch  40: Train Acc=0.9720, Val Acc=0.9493, F1=0.9308\n",
            "  Epoch  50: Train Acc=0.9772, Val Acc=0.9776, F1=0.9640\n",
            "  Epoch  60: Train Acc=0.9823, Val Acc=0.9745, F1=0.9611\n",
            "  Epoch  70: Train Acc=0.9849, Val Acc=0.9849, F1=0.9744\n",
            "  Epoch  80: Train Acc=0.9888, Val Acc=0.9880, F1=0.9801\n",
            "  Epoch  90: Train Acc=0.9909, Val Acc=0.9880, F1=0.9782\n",
            "  Epoch 100: Train Acc=0.9918, Val Acc=0.9894, F1=0.9830\n",
            "  Best Val Acc: 0.9894\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9894\n",
            "  Test Acc: 0.9874, F1: 0.9789\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9586, Val Acc=0.9646, F1=0.9403\n",
            "  Epoch  20: Train Acc=0.9825, Val Acc=0.9837, F1=0.9718\n",
            "  Epoch  30: Train Acc=0.9891, Val Acc=0.9863, F1=0.9775\n",
            "  Epoch  40: Train Acc=0.9928, Val Acc=0.9874, F1=0.9784\n",
            "  Epoch  50: Train Acc=0.9947, Val Acc=0.9886, F1=0.9801\n",
            "  Epoch  60: Train Acc=0.9959, Val Acc=0.9894, F1=0.9819\n",
            "  Epoch  70: Train Acc=0.9965, Val Acc=0.9897, F1=0.9815\n",
            "  Early stopping at epoch 71\n",
            "  Best Val Acc: 0.9901\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9901\n",
            "  Test Acc: 0.9869, F1: 0.9761\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9596, Val Acc=0.9627, F1=0.9389\n",
            "  Epoch  20: Train Acc=0.9814, Val Acc=0.9810, F1=0.9679\n",
            "  Epoch  30: Train Acc=0.9893, Val Acc=0.9874, F1=0.9805\n",
            "  Epoch  40: Train Acc=0.9920, Val Acc=0.9897, F1=0.9827\n",
            "  Epoch  50: Train Acc=0.9936, Val Acc=0.9886, F1=0.9810\n",
            "  Epoch  60: Train Acc=0.9951, Val Acc=0.9894, F1=0.9824\n",
            "  Epoch  70: Train Acc=0.9959, Val Acc=0.9888, F1=0.9825\n",
            "  Epoch  80: Train Acc=0.9971, Val Acc=0.9905, F1=0.9843\n",
            "  Epoch  90: Train Acc=0.9978, Val Acc=0.9901, F1=0.9838\n",
            "  Early stopping at epoch 91\n",
            "  Best Val Acc: 0.9915\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9915\n",
            "  Test Acc: 0.9873, F1: 0.9777\n",
            "\n",
            "[Progress: 4/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_JOGGING_10pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_JOGGING_10pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_JOGGING_10pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9139, Val Acc=0.9114, F1=0.8576\n",
            "  Epoch  20: Train Acc=0.9415, Val Acc=0.9412, F1=0.9059\n",
            "  Epoch  30: Train Acc=0.9614, Val Acc=0.9528, F1=0.9313\n",
            "  Epoch  40: Train Acc=0.9715, Val Acc=0.9737, F1=0.9592\n",
            "  Epoch  50: Train Acc=0.9794, Val Acc=0.9841, F1=0.9744\n",
            "  Epoch  60: Train Acc=0.9850, Val Acc=0.9865, F1=0.9777\n",
            "  Epoch  70: Train Acc=0.9874, Val Acc=0.9882, F1=0.9799\n",
            "  Epoch  80: Train Acc=0.9901, Val Acc=0.9884, F1=0.9797\n",
            "  Epoch  90: Train Acc=0.9907, Val Acc=0.9799, F1=0.9711\n",
            "  Epoch 100: Train Acc=0.9930, Val Acc=0.9899, F1=0.9817\n",
            "  Best Val Acc: 0.9911\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9911\n",
            "  Test Acc: 0.9874, F1: 0.9780\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9647, Val Acc=0.9634, F1=0.9347\n",
            "  Epoch  20: Train Acc=0.9855, Val Acc=0.9830, F1=0.9706\n",
            "  Epoch  30: Train Acc=0.9905, Val Acc=0.9888, F1=0.9789\n",
            "  Epoch  40: Train Acc=0.9938, Val Acc=0.9901, F1=0.9833\n",
            "  Epoch  50: Train Acc=0.9947, Val Acc=0.9901, F1=0.9816\n",
            "  Epoch  60: Train Acc=0.9957, Val Acc=0.9913, F1=0.9846\n",
            "  Epoch  70: Train Acc=0.9967, Val Acc=0.9911, F1=0.9841\n",
            "  Early stopping at epoch 74\n",
            "  Best Val Acc: 0.9925\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9925\n",
            "  Test Acc: 0.9879, F1: 0.9812\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9596, Val Acc=0.9659, F1=0.9412\n",
            "  Epoch  20: Train Acc=0.9832, Val Acc=0.9834, F1=0.9681\n",
            "  Epoch  30: Train Acc=0.9915, Val Acc=0.9892, F1=0.9820\n",
            "  Epoch  40: Train Acc=0.9922, Val Acc=0.9878, F1=0.9799\n",
            "  Epoch  50: Train Acc=0.9948, Val Acc=0.9903, F1=0.9827\n",
            "  Epoch  60: Train Acc=0.9962, Val Acc=0.9905, F1=0.9837\n",
            "  Early stopping at epoch 61\n",
            "  Best Val Acc: 0.9917\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9917\n",
            "  Test Acc: 0.9869, F1: 0.9790\n",
            "\n",
            "[Progress: 5/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_JOGGING_20pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_JOGGING_20pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_JOGGING_20pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9076, Val Acc=0.9129, F1=0.8666\n",
            "  Epoch  20: Train Acc=0.9401, Val Acc=0.9530, F1=0.9295\n",
            "  Epoch  30: Train Acc=0.9619, Val Acc=0.9652, F1=0.9481\n",
            "  Epoch  40: Train Acc=0.9724, Val Acc=0.9710, F1=0.9566\n",
            "  Epoch  50: Train Acc=0.9788, Val Acc=0.9803, F1=0.9708\n",
            "  Epoch  60: Train Acc=0.9827, Val Acc=0.9795, F1=0.9693\n",
            "  Epoch  70: Train Acc=0.9863, Val Acc=0.9834, F1=0.9746\n",
            "  Epoch  80: Train Acc=0.9886, Val Acc=0.9847, F1=0.9769\n",
            "  Epoch  90: Train Acc=0.9905, Val Acc=0.9876, F1=0.9815\n",
            "  Epoch 100: Train Acc=0.9919, Val Acc=0.9855, F1=0.9767\n",
            "  Best Val Acc: 0.9901\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9901\n",
            "  Test Acc: 0.9896, F1: 0.9826\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9606, Val Acc=0.9590, F1=0.9324\n",
            "  Epoch  20: Train Acc=0.9832, Val Acc=0.9832, F1=0.9743\n",
            "  Epoch  30: Train Acc=0.9895, Val Acc=0.9876, F1=0.9793\n",
            "  Epoch  40: Train Acc=0.9922, Val Acc=0.9892, F1=0.9809\n",
            "  Epoch  50: Train Acc=0.9946, Val Acc=0.9899, F1=0.9814\n",
            "  Epoch  60: Train Acc=0.9953, Val Acc=0.9907, F1=0.9816\n",
            "  Epoch  70: Train Acc=0.9971, Val Acc=0.9905, F1=0.9814\n",
            "  Epoch  80: Train Acc=0.9967, Val Acc=0.9899, F1=0.9827\n",
            "  Early stopping at epoch 87\n",
            "  Best Val Acc: 0.9915\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9915\n",
            "  Test Acc: 0.9904, F1: 0.9846\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9608, Val Acc=0.9551, F1=0.9268\n",
            "  Epoch  20: Train Acc=0.9834, Val Acc=0.9793, F1=0.9660\n",
            "  Epoch  30: Train Acc=0.9889, Val Acc=0.9849, F1=0.9748\n",
            "  Epoch  40: Train Acc=0.9924, Val Acc=0.9837, F1=0.9751\n",
            "  Epoch  50: Train Acc=0.9938, Val Acc=0.9878, F1=0.9783\n",
            "  Epoch  60: Train Acc=0.9961, Val Acc=0.9865, F1=0.9776\n",
            "  Epoch  70: Train Acc=0.9964, Val Acc=0.9863, F1=0.9778\n",
            "  Epoch  80: Train Acc=0.9978, Val Acc=0.9874, F1=0.9786\n",
            "  Epoch  90: Train Acc=0.9977, Val Acc=0.9872, F1=0.9774\n",
            "  Early stopping at epoch 92\n",
            "  Best Val Acc: 0.9890\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9890\n",
            "  Test Acc: 0.9892, F1: 0.9824\n",
            "\n",
            "[Progress: 6/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_JOGGING_30pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_JOGGING_30pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_JOGGING_30pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9116, Val Acc=0.9120, F1=0.8590\n",
            "  Epoch  20: Train Acc=0.9461, Val Acc=0.9495, F1=0.9229\n",
            "  Epoch  30: Train Acc=0.9635, Val Acc=0.9601, F1=0.9360\n",
            "  Epoch  40: Train Acc=0.9702, Val Acc=0.9716, F1=0.9545\n",
            "  Epoch  50: Train Acc=0.9785, Val Acc=0.9783, F1=0.9664\n",
            "  Epoch  60: Train Acc=0.9828, Val Acc=0.9832, F1=0.9734\n",
            "  Epoch  70: Train Acc=0.9853, Val Acc=0.9837, F1=0.9752\n",
            "  Epoch  80: Train Acc=0.9876, Val Acc=0.9832, F1=0.9724\n",
            "  Epoch  90: Train Acc=0.9902, Val Acc=0.9857, F1=0.9793\n",
            "  Epoch 100: Train Acc=0.9911, Val Acc=0.9882, F1=0.9829\n",
            "  Best Val Acc: 0.9890\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9890\n",
            "  Test Acc: 0.9871, F1: 0.9806\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9576, Val Acc=0.9615, F1=0.9404\n",
            "  Epoch  20: Train Acc=0.9830, Val Acc=0.9826, F1=0.9746\n",
            "  Epoch  30: Train Acc=0.9892, Val Acc=0.9884, F1=0.9840\n",
            "  Epoch  40: Train Acc=0.9923, Val Acc=0.9880, F1=0.9814\n",
            "  Epoch  50: Train Acc=0.9936, Val Acc=0.9890, F1=0.9837\n",
            "  Epoch  60: Train Acc=0.9953, Val Acc=0.9907, F1=0.9863\n",
            "  Epoch  70: Train Acc=0.9966, Val Acc=0.9901, F1=0.9849\n",
            "  Epoch  80: Train Acc=0.9973, Val Acc=0.9894, F1=0.9847\n",
            "  Epoch  90: Train Acc=0.9975, Val Acc=0.9886, F1=0.9813\n",
            "  Early stopping at epoch 95\n",
            "  Best Val Acc: 0.9915\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9915\n",
            "  Test Acc: 0.9877, F1: 0.9815\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9577, Val Acc=0.9561, F1=0.9333\n",
            "  Epoch  20: Train Acc=0.9823, Val Acc=0.9731, F1=0.9562\n",
            "  Epoch  30: Train Acc=0.9887, Val Acc=0.9832, F1=0.9738\n",
            "  Epoch  40: Train Acc=0.9920, Val Acc=0.9865, F1=0.9795\n",
            "  Epoch  50: Train Acc=0.9944, Val Acc=0.9872, F1=0.9805\n",
            "  Epoch  60: Train Acc=0.9943, Val Acc=0.9892, F1=0.9835\n",
            "  Epoch  70: Train Acc=0.9960, Val Acc=0.9851, F1=0.9775\n",
            "  Epoch  80: Train Acc=0.9963, Val Acc=0.9880, F1=0.9810\n",
            "  Epoch  90: Train Acc=0.9975, Val Acc=0.9903, F1=0.9864\n",
            "  Epoch 100: Train Acc=0.9981, Val Acc=0.9884, F1=0.9837\n",
            "  Best Val Acc: 0.9909\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9909\n",
            "  Test Acc: 0.9889, F1: 0.9824\n",
            "\n",
            "[Progress: 7/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_JOGGING_40pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_JOGGING_40pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_JOGGING_40pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9055, Val Acc=0.9131, F1=0.8708\n",
            "  Epoch  20: Train Acc=0.9418, Val Acc=0.9466, F1=0.9168\n",
            "  Epoch  30: Train Acc=0.9617, Val Acc=0.9634, F1=0.9459\n",
            "  Epoch  40: Train Acc=0.9737, Val Acc=0.9685, F1=0.9504\n",
            "  Epoch  50: Train Acc=0.9794, Val Acc=0.9731, F1=0.9604\n",
            "  Epoch  60: Train Acc=0.9838, Val Acc=0.9774, F1=0.9656\n",
            "  Epoch  70: Train Acc=0.9866, Val Acc=0.9843, F1=0.9748\n",
            "  Epoch  80: Train Acc=0.9870, Val Acc=0.9841, F1=0.9744\n",
            "  Epoch  90: Train Acc=0.9888, Val Acc=0.9857, F1=0.9764\n",
            "  Epoch 100: Train Acc=0.9904, Val Acc=0.9820, F1=0.9721\n",
            "  Best Val Acc: 0.9886\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9886\n",
            "  Test Acc: 0.9874, F1: 0.9813\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9605, Val Acc=0.9677, F1=0.9452\n",
            "  Epoch  20: Train Acc=0.9828, Val Acc=0.9822, F1=0.9720\n",
            "  Epoch  30: Train Acc=0.9893, Val Acc=0.9872, F1=0.9797\n",
            "  Epoch  40: Train Acc=0.9916, Val Acc=0.9865, F1=0.9780\n",
            "  Epoch  50: Train Acc=0.9925, Val Acc=0.9853, F1=0.9727\n",
            "  Early stopping at epoch 55\n",
            "  Best Val Acc: 0.9892\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9892\n",
            "  Test Acc: 0.9869, F1: 0.9785\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9503, Val Acc=0.9578, F1=0.9361\n",
            "  Epoch  20: Train Acc=0.9772, Val Acc=0.9774, F1=0.9689\n",
            "  Epoch  30: Train Acc=0.9845, Val Acc=0.9845, F1=0.9761\n",
            "  Epoch  40: Train Acc=0.9894, Val Acc=0.9870, F1=0.9807\n",
            "  Epoch  50: Train Acc=0.9920, Val Acc=0.9886, F1=0.9826\n",
            "  Epoch  60: Train Acc=0.9944, Val Acc=0.9872, F1=0.9805\n",
            "  Epoch  70: Train Acc=0.9951, Val Acc=0.9870, F1=0.9789\n",
            "  Epoch  80: Train Acc=0.9958, Val Acc=0.9880, F1=0.9828\n",
            "  Early stopping at epoch 88\n",
            "  Best Val Acc: 0.9890\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9890\n",
            "  Test Acc: 0.9879, F1: 0.9817\n",
            "\n",
            "[Progress: 8/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: JOGGING_TO_WALKING_10pct\n",
            "================================================================================\n",
            "\n",
            "Loading JOGGING_TO_WALKING_10pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/JOGGING_TO_WALKING_10pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9173, Val Acc=0.9199, F1=0.8766\n",
            "  Epoch  20: Train Acc=0.9521, Val Acc=0.9466, F1=0.9151\n",
            "  Epoch  30: Train Acc=0.9657, Val Acc=0.9706, F1=0.9554\n",
            "  Epoch  40: Train Acc=0.9767, Val Acc=0.9791, F1=0.9659\n",
            "  Epoch  50: Train Acc=0.9827, Val Acc=0.9766, F1=0.9631\n",
            "  Epoch  60: Train Acc=0.9850, Val Acc=0.9861, F1=0.9755\n",
            "  Epoch  70: Train Acc=0.9889, Val Acc=0.9843, F1=0.9730\n",
            "  Epoch  80: Train Acc=0.9902, Val Acc=0.9876, F1=0.9781\n",
            "  Epoch  90: Train Acc=0.9916, Val Acc=0.9874, F1=0.9798\n",
            "  Epoch 100: Train Acc=0.9927, Val Acc=0.9890, F1=0.9813\n",
            "  Best Val Acc: 0.9899\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9899\n",
            "  Test Acc: 0.9901, F1: 0.9845\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9599, Val Acc=0.9665, F1=0.9432\n",
            "  Epoch  20: Train Acc=0.9824, Val Acc=0.9808, F1=0.9617\n",
            "  Epoch  30: Train Acc=0.9895, Val Acc=0.9865, F1=0.9769\n",
            "  Epoch  40: Train Acc=0.9932, Val Acc=0.9870, F1=0.9776\n",
            "  Epoch  50: Train Acc=0.9947, Val Acc=0.9899, F1=0.9824\n",
            "  Epoch  60: Train Acc=0.9964, Val Acc=0.9892, F1=0.9814\n",
            "  Epoch  70: Train Acc=0.9963, Val Acc=0.9909, F1=0.9847\n",
            "  Epoch  80: Train Acc=0.9976, Val Acc=0.9884, F1=0.9800\n",
            "  Epoch  90: Train Acc=0.9983, Val Acc=0.9897, F1=0.9818\n",
            "  Epoch 100: Train Acc=0.9987, Val Acc=0.9905, F1=0.9837\n",
            "  Best Val Acc: 0.9911\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9911\n",
            "  Test Acc: 0.9906, F1: 0.9836\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9556, Val Acc=0.9621, F1=0.9363\n",
            "  Epoch  20: Train Acc=0.9800, Val Acc=0.9783, F1=0.9635\n",
            "  Epoch  30: Train Acc=0.9874, Val Acc=0.9797, F1=0.9669\n",
            "  Epoch  40: Train Acc=0.9908, Val Acc=0.9843, F1=0.9733\n",
            "  Epoch  50: Train Acc=0.9938, Val Acc=0.9878, F1=0.9802\n",
            "  Epoch  60: Train Acc=0.9947, Val Acc=0.9878, F1=0.9809\n",
            "  Epoch  70: Train Acc=0.9961, Val Acc=0.9872, F1=0.9796\n",
            "  Epoch  80: Train Acc=0.9963, Val Acc=0.9865, F1=0.9782\n",
            "  Early stopping at epoch 84\n",
            "  Best Val Acc: 0.9901\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9901\n",
            "  Test Acc: 0.9901, F1: 0.9825\n",
            "\n",
            "[Progress: 9/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: JOGGING_TO_WALKING_20pct\n",
            "================================================================================\n",
            "\n",
            "Loading JOGGING_TO_WALKING_20pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/JOGGING_TO_WALKING_20pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9164, Val Acc=0.9321, F1=0.8967\n",
            "  Epoch  20: Train Acc=0.9495, Val Acc=0.9545, F1=0.9289\n",
            "  Epoch  30: Train Acc=0.9648, Val Acc=0.9667, F1=0.9503\n",
            "  Epoch  40: Train Acc=0.9764, Val Acc=0.9735, F1=0.9600\n",
            "  Epoch  50: Train Acc=0.9810, Val Acc=0.9795, F1=0.9667\n",
            "  Epoch  60: Train Acc=0.9858, Val Acc=0.9830, F1=0.9722\n",
            "  Epoch  70: Train Acc=0.9884, Val Acc=0.9859, F1=0.9764\n",
            "  Epoch  80: Train Acc=0.9900, Val Acc=0.9843, F1=0.9748\n",
            "  Epoch  90: Train Acc=0.9920, Val Acc=0.9872, F1=0.9779\n",
            "  Epoch 100: Train Acc=0.9926, Val Acc=0.9890, F1=0.9808\n",
            "  Best Val Acc: 0.9892\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9892\n",
            "  Test Acc: 0.9897, F1: 0.9831\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9597, Val Acc=0.9630, F1=0.9365\n",
            "  Epoch  20: Train Acc=0.9820, Val Acc=0.9779, F1=0.9600\n",
            "  Epoch  30: Train Acc=0.9887, Val Acc=0.9853, F1=0.9760\n",
            "  Epoch  40: Train Acc=0.9926, Val Acc=0.9859, F1=0.9772\n",
            "  Epoch  50: Train Acc=0.9942, Val Acc=0.9878, F1=0.9792\n",
            "  Epoch  60: Train Acc=0.9954, Val Acc=0.9872, F1=0.9783\n",
            "  Epoch  70: Train Acc=0.9969, Val Acc=0.9861, F1=0.9773\n",
            "  Epoch  80: Train Acc=0.9970, Val Acc=0.9861, F1=0.9785\n",
            "  Early stopping at epoch 88\n",
            "  Best Val Acc: 0.9890\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9890\n",
            "  Test Acc: 0.9901, F1: 0.9845\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9573, Val Acc=0.9636, F1=0.9376\n",
            "  Epoch  20: Train Acc=0.9801, Val Acc=0.9787, F1=0.9640\n",
            "  Epoch  30: Train Acc=0.9888, Val Acc=0.9820, F1=0.9698\n",
            "  Epoch  40: Train Acc=0.9919, Val Acc=0.9849, F1=0.9746\n",
            "  Epoch  50: Train Acc=0.9931, Val Acc=0.9865, F1=0.9771\n",
            "  Epoch  60: Train Acc=0.9951, Val Acc=0.9863, F1=0.9770\n",
            "  Epoch  70: Train Acc=0.9957, Val Acc=0.9882, F1=0.9806\n",
            "  Epoch  80: Train Acc=0.9968, Val Acc=0.9894, F1=0.9838\n",
            "  Epoch  90: Train Acc=0.9971, Val Acc=0.9870, F1=0.9794\n",
            "  Epoch 100: Train Acc=0.9975, Val Acc=0.9857, F1=0.9776\n",
            "  Early stopping at epoch 100\n",
            "  Best Val Acc: 0.9894\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9894\n",
            "  Test Acc: 0.9914, F1: 0.9867\n",
            "\n",
            "[Progress: 10/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: JOGGING_TO_WALKING_30pct\n",
            "================================================================================\n",
            "\n",
            "Loading JOGGING_TO_WALKING_30pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/JOGGING_TO_WALKING_30pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9158, Val Acc=0.9214, F1=0.8724\n",
            "  Epoch  20: Train Acc=0.9487, Val Acc=0.9518, F1=0.9215\n",
            "  Epoch  30: Train Acc=0.9673, Val Acc=0.9644, F1=0.9437\n",
            "  Epoch  40: Train Acc=0.9751, Val Acc=0.9791, F1=0.9657\n",
            "  Epoch  50: Train Acc=0.9821, Val Acc=0.9785, F1=0.9642\n",
            "  Epoch  60: Train Acc=0.9840, Val Acc=0.9826, F1=0.9711\n",
            "  Epoch  70: Train Acc=0.9876, Val Acc=0.9863, F1=0.9768\n",
            "  Epoch  80: Train Acc=0.9893, Val Acc=0.9874, F1=0.9785\n",
            "  Epoch  90: Train Acc=0.9911, Val Acc=0.9865, F1=0.9785\n",
            "  Epoch 100: Train Acc=0.9921, Val Acc=0.9886, F1=0.9820\n",
            "  Best Val Acc: 0.9901\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9901\n",
            "  Test Acc: 0.9896, F1: 0.9829\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9599, Val Acc=0.9642, F1=0.9353\n",
            "  Epoch  20: Train Acc=0.9815, Val Acc=0.9805, F1=0.9605\n",
            "  Epoch  30: Train Acc=0.9886, Val Acc=0.9874, F1=0.9779\n",
            "  Epoch  40: Train Acc=0.9916, Val Acc=0.9892, F1=0.9817\n",
            "  Epoch  50: Train Acc=0.9944, Val Acc=0.9874, F1=0.9763\n",
            "  Epoch  60: Train Acc=0.9961, Val Acc=0.9897, F1=0.9817\n",
            "  Epoch  70: Train Acc=0.9965, Val Acc=0.9892, F1=0.9814\n",
            "  Epoch  80: Train Acc=0.9978, Val Acc=0.9909, F1=0.9838\n",
            "  Epoch  90: Train Acc=0.9981, Val Acc=0.9897, F1=0.9833\n",
            "  Epoch 100: Train Acc=0.9986, Val Acc=0.9905, F1=0.9826\n",
            "  Early stopping at epoch 100\n",
            "  Best Val Acc: 0.9909\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9909\n",
            "  Test Acc: 0.9904, F1: 0.9846\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9563, Val Acc=0.9576, F1=0.9252\n",
            "  Epoch  20: Train Acc=0.9784, Val Acc=0.9805, F1=0.9630\n",
            "  Epoch  30: Train Acc=0.9863, Val Acc=0.9832, F1=0.9699\n",
            "  Epoch  40: Train Acc=0.9909, Val Acc=0.9855, F1=0.9757\n",
            "  Epoch  50: Train Acc=0.9939, Val Acc=0.9870, F1=0.9782\n",
            "  Epoch  60: Train Acc=0.9948, Val Acc=0.9872, F1=0.9780\n",
            "  Epoch  70: Train Acc=0.9958, Val Acc=0.9870, F1=0.9784\n",
            "  Epoch  80: Train Acc=0.9965, Val Acc=0.9888, F1=0.9816\n",
            "  Epoch  90: Train Acc=0.9976, Val Acc=0.9888, F1=0.9820\n",
            "  Epoch 100: Train Acc=0.9973, Val Acc=0.9884, F1=0.9819\n",
            "  Best Val Acc: 0.9903\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9903\n",
            "  Test Acc: 0.9873, F1: 0.9791\n",
            "\n",
            "[Progress: 11/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: JOGGING_TO_WALKING_40pct\n",
            "================================================================================\n",
            "\n",
            "Loading JOGGING_TO_WALKING_40pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/JOGGING_TO_WALKING_40pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9108, Val Acc=0.9193, F1=0.8835\n",
            "  Epoch  20: Train Acc=0.9476, Val Acc=0.9493, F1=0.9266\n",
            "  Epoch  30: Train Acc=0.9623, Val Acc=0.9634, F1=0.9447\n",
            "  Epoch  40: Train Acc=0.9754, Val Acc=0.9669, F1=0.9520\n",
            "  Epoch  50: Train Acc=0.9816, Val Acc=0.9808, F1=0.9688\n",
            "  Epoch  60: Train Acc=0.9858, Val Acc=0.9770, F1=0.9646\n",
            "  Epoch  70: Train Acc=0.9876, Val Acc=0.9868, F1=0.9783\n",
            "  Epoch  80: Train Acc=0.9900, Val Acc=0.9857, F1=0.9756\n",
            "  Epoch  90: Train Acc=0.9900, Val Acc=0.9841, F1=0.9745\n",
            "  Epoch 100: Train Acc=0.9931, Val Acc=0.9892, F1=0.9816\n",
            "  Best Val Acc: 0.9903\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9903\n",
            "  Test Acc: 0.9897, F1: 0.9836\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9534, Val Acc=0.9601, F1=0.9349\n",
            "  Epoch  20: Train Acc=0.9814, Val Acc=0.9770, F1=0.9605\n",
            "  Epoch  30: Train Acc=0.9887, Val Acc=0.9820, F1=0.9706\n",
            "  Epoch  40: Train Acc=0.9918, Val Acc=0.9839, F1=0.9751\n",
            "  Epoch  50: Train Acc=0.9932, Val Acc=0.9847, F1=0.9741\n",
            "  Epoch  60: Train Acc=0.9948, Val Acc=0.9845, F1=0.9740\n",
            "  Epoch  70: Train Acc=0.9963, Val Acc=0.9834, F1=0.9718\n",
            "  Early stopping at epoch 79\n",
            "  Best Val Acc: 0.9859\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9859\n",
            "  Test Acc: 0.9874, F1: 0.9790\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9506, Val Acc=0.9501, F1=0.9202\n",
            "  Epoch  20: Train Acc=0.9806, Val Acc=0.9781, F1=0.9620\n",
            "  Epoch  30: Train Acc=0.9882, Val Acc=0.9814, F1=0.9683\n",
            "  Epoch  40: Train Acc=0.9916, Val Acc=0.9849, F1=0.9749\n",
            "  Epoch  50: Train Acc=0.9937, Val Acc=0.9805, F1=0.9671\n",
            "  Epoch  60: Train Acc=0.9945, Val Acc=0.9849, F1=0.9753\n",
            "  Epoch  70: Train Acc=0.9952, Val Acc=0.9857, F1=0.9755\n",
            "  Early stopping at epoch 73\n",
            "  Best Val Acc: 0.9863\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9863\n",
            "  Test Acc: 0.9874, F1: 0.9791\n",
            "\n",
            "[Progress: 12/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_UPSTAIRS_10pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_UPSTAIRS_10pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_UPSTAIRS_10pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9105, Val Acc=0.9203, F1=0.8783\n",
            "  Epoch  20: Train Acc=0.9460, Val Acc=0.9514, F1=0.9247\n",
            "  Epoch  30: Train Acc=0.9626, Val Acc=0.9632, F1=0.9475\n",
            "  Epoch  40: Train Acc=0.9747, Val Acc=0.9737, F1=0.9616\n",
            "  Epoch  50: Train Acc=0.9805, Val Acc=0.9754, F1=0.9629\n",
            "  Epoch  60: Train Acc=0.9850, Val Acc=0.9810, F1=0.9712\n",
            "  Epoch  70: Train Acc=0.9866, Val Acc=0.9810, F1=0.9695\n",
            "  Epoch  80: Train Acc=0.9895, Val Acc=0.9824, F1=0.9722\n",
            "  Epoch  90: Train Acc=0.9913, Val Acc=0.9776, F1=0.9654\n",
            "  Epoch 100: Train Acc=0.9921, Val Acc=0.9876, F1=0.9799\n",
            "  Best Val Acc: 0.9876\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9876\n",
            "  Test Acc: 0.9886, F1: 0.9819\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9607, Val Acc=0.9621, F1=0.9373\n",
            "  Epoch  20: Train Acc=0.9827, Val Acc=0.9812, F1=0.9687\n",
            "  Epoch  30: Train Acc=0.9901, Val Acc=0.9874, F1=0.9768\n",
            "  Epoch  40: Train Acc=0.9936, Val Acc=0.9872, F1=0.9773\n",
            "  Epoch  50: Train Acc=0.9949, Val Acc=0.9878, F1=0.9793\n",
            "  Epoch  60: Train Acc=0.9958, Val Acc=0.9880, F1=0.9800\n",
            "  Epoch  70: Train Acc=0.9965, Val Acc=0.9901, F1=0.9836\n",
            "  Epoch  80: Train Acc=0.9980, Val Acc=0.9882, F1=0.9801\n",
            "  Epoch  90: Train Acc=0.9979, Val Acc=0.9876, F1=0.9783\n",
            "  Early stopping at epoch 90\n",
            "  Best Val Acc: 0.9901\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9901\n",
            "  Test Acc: 0.9891, F1: 0.9817\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9588, Val Acc=0.9497, F1=0.9233\n",
            "  Epoch  20: Train Acc=0.9803, Val Acc=0.9791, F1=0.9646\n",
            "  Epoch  30: Train Acc=0.9887, Val Acc=0.9851, F1=0.9754\n",
            "  Epoch  40: Train Acc=0.9918, Val Acc=0.9837, F1=0.9749\n",
            "  Epoch  50: Train Acc=0.9948, Val Acc=0.9853, F1=0.9764\n",
            "  Epoch  60: Train Acc=0.9955, Val Acc=0.9876, F1=0.9814\n",
            "  Early stopping at epoch 69\n",
            "  Best Val Acc: 0.9894\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9894\n",
            "  Test Acc: 0.9868, F1: 0.9786\n",
            "\n",
            "[Progress: 13/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_UPSTAIRS_20pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_UPSTAIRS_20pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_UPSTAIRS_20pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9103, Val Acc=0.9220, F1=0.8802\n",
            "  Epoch  20: Train Acc=0.9455, Val Acc=0.9450, F1=0.9155\n",
            "  Epoch  30: Train Acc=0.9620, Val Acc=0.9553, F1=0.9314\n",
            "  Epoch  40: Train Acc=0.9725, Val Acc=0.9698, F1=0.9525\n",
            "  Epoch  50: Train Acc=0.9781, Val Acc=0.9739, F1=0.9584\n",
            "  Epoch  60: Train Acc=0.9821, Val Acc=0.9774, F1=0.9633\n",
            "  Epoch  70: Train Acc=0.9871, Val Acc=0.9814, F1=0.9706\n",
            "  Epoch  80: Train Acc=0.9881, Val Acc=0.9843, F1=0.9734\n",
            "  Epoch  90: Train Acc=0.9891, Val Acc=0.9837, F1=0.9722\n",
            "  Epoch 100: Train Acc=0.9916, Val Acc=0.9828, F1=0.9731\n",
            "  Best Val Acc: 0.9876\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9876\n",
            "  Test Acc: 0.9856, F1: 0.9783\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9604, Val Acc=0.9656, F1=0.9425\n",
            "  Epoch  20: Train Acc=0.9838, Val Acc=0.9785, F1=0.9631\n",
            "  Epoch  30: Train Acc=0.9912, Val Acc=0.9847, F1=0.9725\n",
            "  Epoch  40: Train Acc=0.9939, Val Acc=0.9855, F1=0.9741\n",
            "  Epoch  50: Train Acc=0.9953, Val Acc=0.9876, F1=0.9782\n",
            "  Epoch  60: Train Acc=0.9958, Val Acc=0.9865, F1=0.9761\n",
            "  Epoch  70: Train Acc=0.9967, Val Acc=0.9892, F1=0.9812\n",
            "  Epoch  80: Train Acc=0.9979, Val Acc=0.9890, F1=0.9796\n",
            "  Epoch  90: Train Acc=0.9983, Val Acc=0.9882, F1=0.9793\n",
            "  Epoch 100: Train Acc=0.9983, Val Acc=0.9865, F1=0.9766\n",
            "  Best Val Acc: 0.9903\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9903\n",
            "  Test Acc: 0.9881, F1: 0.9820\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9551, Val Acc=0.9553, F1=0.9294\n",
            "  Epoch  20: Train Acc=0.9791, Val Acc=0.9762, F1=0.9623\n",
            "  Epoch  30: Train Acc=0.9884, Val Acc=0.9822, F1=0.9698\n",
            "  Epoch  40: Train Acc=0.9926, Val Acc=0.9882, F1=0.9804\n",
            "  Epoch  50: Train Acc=0.9944, Val Acc=0.9832, F1=0.9724\n",
            "  Epoch  60: Train Acc=0.9954, Val Acc=0.9861, F1=0.9767\n",
            "  Early stopping at epoch 63\n",
            "  Best Val Acc: 0.9888\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9888\n",
            "  Test Acc: 0.9853, F1: 0.9788\n",
            "\n",
            "[Progress: 14/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_UPSTAIRS_30pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_UPSTAIRS_30pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_UPSTAIRS_30pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9039, Val Acc=0.9170, F1=0.8739\n",
            "  Epoch  20: Train Acc=0.9430, Val Acc=0.9476, F1=0.9216\n",
            "  Epoch  30: Train Acc=0.9584, Val Acc=0.9652, F1=0.9466\n",
            "  Epoch  40: Train Acc=0.9740, Val Acc=0.9727, F1=0.9579\n",
            "  Epoch  50: Train Acc=0.9789, Val Acc=0.9752, F1=0.9595\n",
            "  Epoch  60: Train Acc=0.9839, Val Acc=0.9816, F1=0.9696\n",
            "  Epoch  70: Train Acc=0.9860, Val Acc=0.9824, F1=0.9707\n",
            "  Epoch  80: Train Acc=0.9868, Val Acc=0.9768, F1=0.9656\n",
            "  Epoch  90: Train Acc=0.9890, Val Acc=0.9872, F1=0.9775\n",
            "  Epoch 100: Train Acc=0.9909, Val Acc=0.9868, F1=0.9764\n",
            "  Best Val Acc: 0.9882\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9882\n",
            "  Test Acc: 0.9896, F1: 0.9839\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9606, Val Acc=0.9696, F1=0.9447\n",
            "  Epoch  20: Train Acc=0.9841, Val Acc=0.9814, F1=0.9619\n",
            "  Epoch  30: Train Acc=0.9895, Val Acc=0.9839, F1=0.9729\n",
            "  Epoch  40: Train Acc=0.9920, Val Acc=0.9868, F1=0.9768\n",
            "  Early stopping at epoch 44\n",
            "  Best Val Acc: 0.9868\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9868\n",
            "  Test Acc: 0.9869, F1: 0.9784\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9526, Val Acc=0.9578, F1=0.9307\n",
            "  Epoch  20: Train Acc=0.9790, Val Acc=0.9781, F1=0.9601\n",
            "  Epoch  30: Train Acc=0.9879, Val Acc=0.9826, F1=0.9706\n",
            "  Epoch  40: Train Acc=0.9914, Val Acc=0.9857, F1=0.9767\n",
            "  Epoch  50: Train Acc=0.9939, Val Acc=0.9855, F1=0.9750\n",
            "  Epoch  60: Train Acc=0.9951, Val Acc=0.9847, F1=0.9745\n",
            "  Epoch  70: Train Acc=0.9964, Val Acc=0.9855, F1=0.9756\n",
            "  Early stopping at epoch 71\n",
            "  Best Val Acc: 0.9863\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9863\n",
            "  Test Acc: 0.9873, F1: 0.9801\n",
            "\n",
            "[Progress: 15/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_UPSTAIRS_40pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_UPSTAIRS_40pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_UPSTAIRS_40pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9012, Val Acc=0.8957, F1=0.8358\n",
            "  Epoch  20: Train Acc=0.9355, Val Acc=0.9373, F1=0.9052\n",
            "  Epoch  30: Train Acc=0.9568, Val Acc=0.9520, F1=0.9276\n",
            "  Epoch  40: Train Acc=0.9681, Val Acc=0.9642, F1=0.9465\n",
            "  Epoch  50: Train Acc=0.9754, Val Acc=0.9721, F1=0.9537\n",
            "  Epoch  60: Train Acc=0.9791, Val Acc=0.9731, F1=0.9554\n",
            "  Epoch  70: Train Acc=0.9848, Val Acc=0.9816, F1=0.9699\n",
            "  Epoch  80: Train Acc=0.9861, Val Acc=0.9793, F1=0.9640\n",
            "  Epoch  90: Train Acc=0.9880, Val Acc=0.9818, F1=0.9696\n",
            "  Epoch 100: Train Acc=0.9899, Val Acc=0.9845, F1=0.9751\n",
            "  Best Val Acc: 0.9882\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9882\n",
            "  Test Acc: 0.9897, F1: 0.9831\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9589, Val Acc=0.9594, F1=0.9303\n",
            "  Epoch  20: Train Acc=0.9813, Val Acc=0.9791, F1=0.9616\n",
            "  Epoch  30: Train Acc=0.9891, Val Acc=0.9849, F1=0.9727\n",
            "  Epoch  40: Train Acc=0.9917, Val Acc=0.9855, F1=0.9724\n",
            "  Epoch  50: Train Acc=0.9946, Val Acc=0.9849, F1=0.9720\n",
            "  Epoch  60: Train Acc=0.9954, Val Acc=0.9870, F1=0.9760\n",
            "  Epoch  70: Train Acc=0.9972, Val Acc=0.9857, F1=0.9731\n",
            "  Epoch  80: Train Acc=0.9973, Val Acc=0.9899, F1=0.9815\n",
            "  Epoch  90: Train Acc=0.9974, Val Acc=0.9880, F1=0.9784\n",
            "  Epoch 100: Train Acc=0.9984, Val Acc=0.9897, F1=0.9804\n",
            "  Early stopping at epoch 100\n",
            "  Best Val Acc: 0.9899\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9899\n",
            "  Test Acc: 0.9896, F1: 0.9802\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9546, Val Acc=0.9495, F1=0.9185\n",
            "  Epoch  20: Train Acc=0.9787, Val Acc=0.9772, F1=0.9629\n",
            "  Epoch  30: Train Acc=0.9861, Val Acc=0.9797, F1=0.9662\n",
            "  Epoch  40: Train Acc=0.9913, Val Acc=0.9861, F1=0.9764\n",
            "  Epoch  50: Train Acc=0.9934, Val Acc=0.9878, F1=0.9772\n",
            "  Epoch  60: Train Acc=0.9942, Val Acc=0.9874, F1=0.9786\n",
            "  Epoch  70: Train Acc=0.9960, Val Acc=0.9880, F1=0.9817\n",
            "  Epoch  80: Train Acc=0.9969, Val Acc=0.9886, F1=0.9820\n",
            "  Epoch  90: Train Acc=0.9972, Val Acc=0.9868, F1=0.9789\n",
            "  Early stopping at epoch 91\n",
            "  Best Val Acc: 0.9901\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9901\n",
            "  Test Acc: 0.9846, F1: 0.9756\n",
            "\n",
            "[Progress: 16/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_DOWNSTAIRS_10pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_DOWNSTAIRS_10pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_DOWNSTAIRS_10pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9073, Val Acc=0.9230, F1=0.8824\n",
            "  Epoch  20: Train Acc=0.9427, Val Acc=0.9526, F1=0.9245\n",
            "  Epoch  30: Train Acc=0.9616, Val Acc=0.9588, F1=0.9350\n",
            "  Epoch  40: Train Acc=0.9731, Val Acc=0.9727, F1=0.9591\n",
            "  Epoch  50: Train Acc=0.9794, Val Acc=0.9824, F1=0.9721\n",
            "  Epoch  60: Train Acc=0.9843, Val Acc=0.9845, F1=0.9760\n",
            "  Epoch  70: Train Acc=0.9857, Val Acc=0.9845, F1=0.9751\n",
            "  Epoch  80: Train Acc=0.9884, Val Acc=0.9849, F1=0.9739\n",
            "  Epoch  90: Train Acc=0.9898, Val Acc=0.9928, F1=0.9884\n",
            "  Epoch 100: Train Acc=0.9931, Val Acc=0.9907, F1=0.9844\n",
            "  Best Val Acc: 0.9928\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9928\n",
            "  Test Acc: 0.9886, F1: 0.9827\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9582, Val Acc=0.9621, F1=0.9360\n",
            "  Epoch  20: Train Acc=0.9827, Val Acc=0.9832, F1=0.9724\n",
            "  Epoch  30: Train Acc=0.9901, Val Acc=0.9859, F1=0.9777\n",
            "  Epoch  40: Train Acc=0.9942, Val Acc=0.9894, F1=0.9817\n",
            "  Epoch  50: Train Acc=0.9945, Val Acc=0.9894, F1=0.9825\n",
            "  Epoch  60: Train Acc=0.9962, Val Acc=0.9878, F1=0.9783\n",
            "  Early stopping at epoch 69\n",
            "  Best Val Acc: 0.9917\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9917\n",
            "  Test Acc: 0.9896, F1: 0.9832\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9570, Val Acc=0.9607, F1=0.9335\n",
            "  Epoch  20: Train Acc=0.9815, Val Acc=0.9766, F1=0.9559\n",
            "  Epoch  30: Train Acc=0.9878, Val Acc=0.9868, F1=0.9774\n",
            "  Epoch  40: Train Acc=0.9911, Val Acc=0.9872, F1=0.9791\n",
            "  Epoch  50: Train Acc=0.9935, Val Acc=0.9876, F1=0.9791\n",
            "  Early stopping at epoch 55\n",
            "  Best Val Acc: 0.9878\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9878\n",
            "  Test Acc: 0.9884, F1: 0.9825\n",
            "\n",
            "[Progress: 17/27]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_DOWNSTAIRS_20pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_DOWNSTAIRS_20pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_DOWNSTAIRS_20pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9094, Val Acc=0.9203, F1=0.8756\n",
            "  Epoch  20: Train Acc=0.9457, Val Acc=0.9421, F1=0.9101\n",
            "  Epoch  30: Train Acc=0.9616, Val Acc=0.9650, F1=0.9449\n",
            "  Epoch  40: Train Acc=0.9719, Val Acc=0.9708, F1=0.9565\n",
            "  Epoch  50: Train Acc=0.9781, Val Acc=0.9803, F1=0.9678\n",
            "  Epoch  60: Train Acc=0.9827, Val Acc=0.9758, F1=0.9662\n",
            "  Epoch  70: Train Acc=0.9869, Val Acc=0.9853, F1=0.9758\n",
            "  Epoch  80: Train Acc=0.9887, Val Acc=0.9865, F1=0.9776\n",
            "  Epoch  90: Train Acc=0.9902, Val Acc=0.9863, F1=0.9775\n",
            "  Epoch 100: Train Acc=0.9927, Val Acc=0.9903, F1=0.9841\n",
            "  Best Val Acc: 0.9903\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9903\n",
            "  Test Acc: 0.9882, F1: 0.9815\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9657, Val Acc=0.9636, F1=0.9395\n",
            "  Epoch  20: Train Acc=0.9816, Val Acc=0.9787, F1=0.9645\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"unified_transition_1024.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1q8L0az2N02xlgQ_FLiQds-TEaFqLfsON\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Unified Model Comparison: GAP, TPA, Gated-TPA\n",
        "Compare three models on 41 pre-augmented transition datasets\n",
        "(1 original + 40 transition datasets)\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, random, time, copy, json\n",
        "import numpy as np\n",
        "from typing import Tuple, Dict, List\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ========================\n",
        "# Config & Reproducibility\n",
        "# ========================\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    data_dir: str = \"/content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets\"\n",
        "    save_dir: str = \"/content/drive/MyDrive/AI_data/TPA2\"\n",
        "\n",
        "    epochs: int = 100\n",
        "    batch_size: int = 128\n",
        "    lr: float = 1e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    grad_clip: float = 1.0\n",
        "    label_smoothing: float = 0.05\n",
        "\n",
        "    patience: int = 20\n",
        "    min_delta: float = 0.0001\n",
        "    val_split: float = 0.2\n",
        "\n",
        "    d_model: int = 128\n",
        "\n",
        "    # TPA hyperparameters\n",
        "    tpa_num_prototypes: int = 16\n",
        "    tpa_heads: int = 4\n",
        "    tpa_dropout: float = 0.1\n",
        "    tpa_temperature: float = 0.07\n",
        "    tpa_topk_ratio: float = 0.25\n",
        "\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    num_workers: int = 2\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# ========================\n",
        "# Dataset Class\n",
        "# ========================\n",
        "class PreloadedDataset(Dataset):\n",
        "    \"\"\"Dataset for pre-loaded numpy arrays\"\"\"\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
        "        super().__init__()\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "\n",
        "        # Label     (1-6 -> 0-5)\n",
        "        if y.min() >= 1:\n",
        "            y = y - 1\n",
        "\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ========================\n",
        "# Data Loading Functions\n",
        "# ========================\n",
        "def load_dataset(base_dir: str, dataset_name: str):\n",
        "    \"\"\"\n",
        "    Load pre-augmented dataset\n",
        "    Args:\n",
        "        base_dir: base directory containing all datasets\n",
        "        dataset_name: e.g., \"ORIGINAL\", \"STANDING_TO_SITTING_10pct\", etc.\n",
        "    Returns:\n",
        "        train_dataset, test_dataset\n",
        "    \"\"\"\n",
        "    dataset_dir = os.path.join(base_dir, dataset_name)\n",
        "\n",
        "    print(f\"\\nLoading {dataset_name}...\")\n",
        "    print(f\"  Path: {dataset_dir}\")\n",
        "\n",
        "    # Load data\n",
        "    X_train = np.load(os.path.join(dataset_dir, \"X_train.npy\"))\n",
        "    y_train = np.load(os.path.join(dataset_dir, \"y_train.npy\"))\n",
        "    X_test = np.load(os.path.join(dataset_dir, \"X_test.npy\"))\n",
        "    y_test = np.load(os.path.join(dataset_dir, \"y_test.npy\"))\n",
        "\n",
        "    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "    train_dataset = PreloadedDataset(X_train, y_train)\n",
        "    test_dataset = PreloadedDataset(X_test, y_test)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "# ========================\n",
        "# Model Components\n",
        "# ========================\n",
        "class BiLSTMBackbone(nn.Module):\n",
        "    \"\"\"BiLSTM backbone for all models\n",
        "    Args:\n",
        "        in_ch: input channels (default: 3)\n",
        "        d_model: output dimension (default: 128)\n",
        "        hidden_dim: LSTM hidden dimension (default: 64, bidirectional -> 128)\n",
        "        num_layers: number of LSTM layers (default: 2)\n",
        "        dropout: dropout rate (default: 0.1)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch=3, d_model=128, hidden_dim=64, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # BiLSTM: hidden_dim=64    128\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=in_ch,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        # : BiLSTM (128)  d_model(128)\n",
        "        self.projection = nn.Linear(hidden_dim * 2, d_model)\n",
        "\n",
        "        #   \n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, C, T]  [B, T, C] (LSTM [B, T, C]  )\n",
        "        # x = x.transpose(1, 2)\n",
        "\n",
        "        # BiLSTM\n",
        "        lstm_out, _ = self.lstm(x)  # [B, T, hidden_dim*2=128]\n",
        "\n",
        "        # \n",
        "        out = self.projection(lstm_out)  # [B, T, d_model=128]\n",
        "\n",
        "        #  + \n",
        "        out = self.layer_norm(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        # [B, T, D]  [B, D, T] (  )\n",
        "        return out.transpose(1, 2)\n",
        "\n",
        "# ========================\n",
        "# GAP Model\n",
        "# ========================\n",
        "class GAPModel(nn.Module):\n",
        "    \"\"\"Baseline: Global Average Pooling\"\"\"\n",
        "    def __init__(self, d_model=128, num_classes=6):\n",
        "        super().__init__()\n",
        "        self.backbone = BiLSTMBackbone(d_model=d_model)\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fmap = self.backbone(x)  # [B, D, T]\n",
        "        features = fmap.transpose(1, 2)  # [B, T, D]\n",
        "        pooled = features.mean(dim=1)  # [B, D]\n",
        "        logits = self.fc(pooled)\n",
        "        return logits\n",
        "\n",
        "# ========================\n",
        "# Pure-TPA\n",
        "# ========================\n",
        "class ProductionTPA(nn.Module):\n",
        "    \"\"\"Pure TPA\"\"\"\n",
        "    def __init__(self, dim, num_prototypes=16, heads=4, dropout=0.1,\n",
        "                 temperature=0.07, topk_ratio=0.25):\n",
        "        super().__init__()\n",
        "        assert dim % heads == 0\n",
        "\n",
        "        self.dim = dim\n",
        "        self.heads = heads\n",
        "        self.head_dim = dim // heads\n",
        "        self.num_prototypes = num_prototypes\n",
        "        self.temperature = temperature\n",
        "        self.topk_ratio = topk_ratio\n",
        "\n",
        "        self.proto = nn.Parameter(torch.randn(num_prototypes, dim) * 0.02)\n",
        "\n",
        "        self.pre_norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.q_proj = nn.Linear(dim, dim, bias=False)\n",
        "        self.k_proj = nn.Linear(dim, dim, bias=False)\n",
        "        self.v_proj = nn.Linear(dim, dim, bias=False)\n",
        "\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, D = x.shape\n",
        "        P = self.num_prototypes\n",
        "\n",
        "        x_norm = self.pre_norm(x)\n",
        "\n",
        "        K = self.k_proj(x_norm)\n",
        "        V = self.v_proj(x_norm)\n",
        "        Qp = self.q_proj(self.proto).unsqueeze(0).expand(B, -1, -1)\n",
        "\n",
        "        def split_heads(t, length):\n",
        "            return t.view(B, length, self.heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        Qh = split_heads(Qp, P)\n",
        "        Kh = split_heads(K, T)\n",
        "        Vh = split_heads(V, T)\n",
        "\n",
        "        Qh = F.normalize(Qh, dim=-1)\n",
        "        Kh = F.normalize(Kh, dim=-1)\n",
        "\n",
        "        scores = torch.matmul(Qh, Kh.transpose(-2, -1)) / self.temperature\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        attn = torch.nan_to_num(attn, nan=0.0)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        proto_tokens = torch.matmul(attn, Vh)\n",
        "        proto_tokens = proto_tokens.transpose(1, 2).contiguous().view(B, P, D)\n",
        "\n",
        "        z_tpa = proto_tokens.mean(dim=1)\n",
        "\n",
        "        z = self.fuse(z_tpa)\n",
        "\n",
        "        return z\n",
        "\n",
        "class TPAModel(nn.Module):\n",
        "    def __init__(self, d_model=128, num_classes=6, tpa_config=None):\n",
        "        super().__init__()\n",
        "        self.backbone = BiLSTMBackbone(d_model=d_model)\n",
        "        self.tpa = ProductionTPA(\n",
        "            dim=d_model,\n",
        "            num_prototypes=tpa_config['num_prototypes'],\n",
        "            heads=tpa_config['heads'],\n",
        "            dropout=tpa_config['dropout'],\n",
        "            temperature=tpa_config['temperature'],\n",
        "            topk_ratio=tpa_config['topk_ratio']\n",
        "        )\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fmap = self.backbone(x)  # [B, D, T]\n",
        "        features = fmap.transpose(1, 2)  # [B, T, D]\n",
        "        z = self.tpa(features)  # [B, D]\n",
        "        logits = self.classifier(z)\n",
        "        return logits\n",
        "\n",
        "# ========================\n",
        "# Gated-TPA\n",
        "# ========================\n",
        "class GatedTPAModel(nn.Module):\n",
        "    def __init__(self, d_model=128, num_classes=6, tpa_config=None):\n",
        "        super().__init__()\n",
        "        self.backbone = BiLSTMBackbone(d_model=d_model)\n",
        "        self.tpa = ProductionTPA(\n",
        "            dim=d_model,\n",
        "            num_prototypes=tpa_config['num_prototypes'],\n",
        "            heads=tpa_config['heads'],\n",
        "            dropout=tpa_config['dropout'],\n",
        "            temperature=tpa_config['temperature'],\n",
        "            topk_ratio=tpa_config['topk_ratio']\n",
        "        )\n",
        "\n",
        "        # Gating mechanism\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(d_model * 2, d_model),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fmap = self.backbone(x)  # [B, D, T]\n",
        "        features = fmap.transpose(1, 2)  # [B, T, D]\n",
        "\n",
        "        # GAP branch\n",
        "        z_gap = features.mean(dim=1)  # [B, D]\n",
        "\n",
        "        # TPA branch\n",
        "        z_tpa = self.tpa(features)  # [B, D]\n",
        "\n",
        "        # Gating\n",
        "        gate_input = torch.cat([z_gap, z_tpa], dim=-1)\n",
        "        g = self.gate(gate_input)\n",
        "\n",
        "        # Gated fusion\n",
        "        z = g * z_gap + (1 - g) * z_tpa\n",
        "\n",
        "        logits = self.classifier(z)\n",
        "        return logits\n",
        "\n",
        "# ========================\n",
        "# Training & Evaluation\n",
        "# ========================\n",
        "def train_one_epoch(model, loader, opt, cfg: Config):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(cfg.device).float(), y.to(cfg.device)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(x)\n",
        "\n",
        "        loss = F.cross_entropy(logits, y, label_smoothing=cfg.label_smoothing)\n",
        "        if torch.isnan(loss):\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "        opt.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = logits.argmax(dim=-1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            loss_sum += loss.item() * y.size(0)\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss_sum / total if total > 0 else 0,\n",
        "        \"acc\": correct / total if total > 0 else 0\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, cfg: Config):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(cfg.device), y.to(cfg.device)\n",
        "        logits = model(x)\n",
        "        ps.append(logits.argmax(dim=-1).cpu().numpy())\n",
        "        ys.append(y.cpu().numpy())\n",
        "\n",
        "    y_true, y_pred = np.concatenate(ys), np.concatenate(ps)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return acc, f1\n",
        "\n",
        "def train_model(model, train_loader, val_loader, cfg: Config, model_name: str):\n",
        "    \"\"\"Train a single model\"\"\"\n",
        "    print(f\"\\n[Training {model_name}]\")\n",
        "\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "\n",
        "    best_acc, best_wts = 0.0, None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, cfg.epochs + 1):\n",
        "        stats = train_one_epoch(model, train_loader, opt, cfg)\n",
        "        val_acc, val_f1 = evaluate(model, val_loader, cfg)\n",
        "\n",
        "        if val_acc > best_acc + cfg.min_delta:\n",
        "            best_acc = val_acc\n",
        "            best_wts = copy.deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"  Epoch {epoch:3d}: Train Acc={stats['acc']:.4f}, Val Acc={val_acc:.4f}, F1={val_f1:.4f}\")\n",
        "\n",
        "        if patience_counter >= cfg.patience:\n",
        "            print(f\"  Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    if best_wts:\n",
        "        model.load_state_dict(best_wts)\n",
        "\n",
        "    print(f\"  Best Val Acc: {best_acc:.4f}\")\n",
        "    return best_acc\n",
        "\n",
        "def create_model(model_name: str, cfg: Config):\n",
        "    \"\"\"Create model by name\"\"\"\n",
        "    tpa_config = {\n",
        "        'num_prototypes': cfg.tpa_num_prototypes,\n",
        "        'heads': cfg.tpa_heads,\n",
        "        'dropout': cfg.tpa_dropout,\n",
        "        'temperature': cfg.tpa_temperature,\n",
        "        'topk_ratio': cfg.tpa_topk_ratio\n",
        "    }\n",
        "\n",
        "    if model_name == \"GAP\":\n",
        "        return GAPModel(d_model=cfg.d_model).to(cfg.device).float()\n",
        "    elif model_name == \"TPA\":\n",
        "        return TPAModel(d_model=cfg.d_model, tpa_config=tpa_config).to(cfg.device).float()\n",
        "    elif model_name == \"Gated-TPA\":\n",
        "        return GatedTPAModel(d_model=cfg.d_model, tpa_config=tpa_config).to(cfg.device).float()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "\n",
        "# ========================\n",
        "# Main Experiment\n",
        "# ========================\n",
        "def run_experiment(dataset_name: str, cfg: Config):\n",
        "    \"\"\"Run complete experiment for one dataset\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EXPERIMENT: {dataset_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Load data\n",
        "    train_dataset, test_dataset = load_dataset(cfg.data_dir, dataset_name)\n",
        "\n",
        "    # Split train into train/val using indices\n",
        "    n_total = len(train_dataset)\n",
        "    indices = np.arange(n_total)\n",
        "\n",
        "    # Get labels for stratification\n",
        "    y_labels = train_dataset.y.numpy()\n",
        "\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        indices,\n",
        "        test_size=cfg.val_split,\n",
        "        random_state=SEED,\n",
        "        stratify=y_labels\n",
        "    )\n",
        "\n",
        "    # Create subsets using Subset\n",
        "    from torch.utils.data import Subset\n",
        "    train_subset = Subset(train_dataset, train_indices)\n",
        "    val_subset = Subset(train_dataset, val_indices)\n",
        "\n",
        "    # Create data loaders\n",
        "    g = torch.Generator(device='cpu').manual_seed(SEED)\n",
        "    train_loader = DataLoader(train_subset, cfg.batch_size, shuffle=True,\n",
        "                              num_workers=cfg.num_workers, generator=g)\n",
        "    val_loader = DataLoader(val_subset, cfg.batch_size, num_workers=cfg.num_workers)\n",
        "    test_loader = DataLoader(test_dataset, cfg.batch_size, num_workers=cfg.num_workers)\n",
        "\n",
        "    print(f\"\\nDataset splits:\")\n",
        "    print(f\"  Train: {len(train_subset)}, Val: {len(val_subset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "    # Train and evaluate all models\n",
        "    results = []\n",
        "    model_names = [\"GAP\", \"TPA\", \"Gated-TPA\"]\n",
        "\n",
        "    for model_name in model_names:\n",
        "        # Reset seed for each model\n",
        "        random.seed(SEED)\n",
        "        np.random.seed(SEED)\n",
        "        torch.manual_seed(SEED)\n",
        "\n",
        "        # Create and train model\n",
        "        model = create_model(model_name, cfg)\n",
        "        best_val_acc = train_model(model, train_loader, val_loader, cfg, model_name)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_acc, test_f1 = evaluate(model, test_loader, cfg)\n",
        "\n",
        "        print(f\"\\n[{model_name} Results]\")\n",
        "        print(f\"  Val Acc: {best_val_acc:.4f}\")\n",
        "        print(f\"  Test Acc: {test_acc:.4f}, F1: {test_f1:.4f}\")\n",
        "\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Dataset': dataset_name,\n",
        "            'Val_Accuracy': float(best_val_acc),\n",
        "            'Test_Accuracy': float(test_acc),\n",
        "            'Test_F1_Score': float(test_f1)\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# ========================\n",
        "# Run All Experiments\n",
        "# ========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"UNIFIED MODEL COMPARISON: GAP vs TPA vs Gated-TPA\")\n",
        "    print(\"Testing on 41 Datasets (1 Original + 40 Transition)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Define all 41 datasets\n",
        "    datasets = [\"WALKING_TO_STANDING_20pct\", \"WALKING_TO_STANDING_30pct\", \"WALKING_TO_STANDING_40pct\"]\n",
        "\n",
        "    transitions = [\n",
        "        \"WALKING_TO_JOGGING\",\n",
        "        \"JOGGING_TO_WALKING\",\n",
        "        \"WALKING_TO_UPSTAIRS\",\n",
        "        \"WALKING_TO_DOWNSTAIRS\",\n",
        "        \"UPSTAIRS_TO_WALKING\",\n",
        "        \"DOWNSTAIRS_TO_WALKING\"\n",
        "    ]\n",
        "\n",
        "    #    10%, 20%, 30%, 40% \n",
        "    mix_pcts = [10, 20, 30, 40]\n",
        "\n",
        "    for transition in transitions:\n",
        "        for pct in mix_pcts:\n",
        "            datasets.append(f\"{transition}_{pct}pct\")\n",
        "\n",
        "    print(f\"\\nTotal datasets to test: {len(datasets)}\")\n",
        "    print(f\"  - transitions: {len(transitions) * len(mix_pcts) + 3}\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Run experiments\n",
        "    for i, dataset_name in enumerate(datasets, 1):\n",
        "        print(f\"\\n[Progress: {i}/{len(datasets)}]\")\n",
        "        results = run_experiment(dataset_name, cfg)\n",
        "        all_results.extend(results)\n",
        "\n",
        "    # Save all results\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SAVING RESULTS\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    results_dict = {\n",
        "        'experiment_info': {\n",
        "            'date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'models': ['GAP', 'TPA', 'Gated-TPA'],\n",
        "            'total_datasets': len(datasets),\n",
        "            'datasets': datasets,\n",
        "            'config': {\n",
        "                'epochs': cfg.epochs,\n",
        "                'batch_size': cfg.batch_size,\n",
        "                'lr': cfg.lr,\n",
        "                'd_model': cfg.d_model,\n",
        "                'tpa_num_prototypes': cfg.tpa_num_prototypes,\n",
        "                'tpa_heads': cfg.tpa_heads\n",
        "            }\n",
        "        },\n",
        "        'results': all_results\n",
        "    }\n",
        "\n",
        "    # Save to JSON\n",
        "    json_path = os.path.join(cfg.save_dir, \"unified_comparison_41datasets_results.json\")\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(results_dict, f, indent=2)\n",
        "\n",
        "    print(f\"\\nResults saved to: {json_path}\")\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Total experiments: {len(all_results)}\")\n",
        "    print(f\"Total datasets tested: {len(datasets)}\")\n",
        "    print(f\"Models compared: 3 (GAP, TPA, Gated-TPA)\")\n",
        "\n",
        "    # Calculate average performance per model\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"AVERAGE PERFORMANCE (All Datasets)\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    for model_name in ['GAP', 'TPA', 'Gated-TPA']:\n",
        "        model_results = [r for r in all_results if r['Model'] == model_name]\n",
        "        avg_acc = np.mean([r['Test_Accuracy'] for r in model_results])\n",
        "        avg_f1 = np.mean([r['Test_F1_Score'] for r in model_results])\n",
        "        print(f\"{model_name:12s}: Acc={avg_acc:.4f}, F1={avg_f1:.4f}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"EXPERIMENT COMPLETE\")\n",
        "    print(f\"{'='*80}\")"
      ]
    }
  ]
}