{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj7xi96X01yO",
        "outputId": "b26f6096-500c-4fab-99b3-57095d12ece9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "================================================================================\n",
            "UNIFIED MODEL COMPARISON: GAP vs TPA vs Gated-TPA\n",
            "Testing on 41 Datasets (1 Original + 40 Transition)\n",
            "================================================================================\n",
            "\n",
            "Total datasets to test: 11\n",
            "  - transitions: 11\n",
            "\n",
            "[Progress: 1/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_DOWNSTAIRS_20pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_DOWNSTAIRS_20pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_DOWNSTAIRS_20pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9094, Val Acc=0.9203, F1=0.8756\n",
            "  Epoch  20: Train Acc=0.9457, Val Acc=0.9421, F1=0.9101\n",
            "  Epoch  30: Train Acc=0.9616, Val Acc=0.9650, F1=0.9449\n",
            "  Epoch  40: Train Acc=0.9719, Val Acc=0.9708, F1=0.9565\n",
            "  Epoch  50: Train Acc=0.9781, Val Acc=0.9803, F1=0.9678\n",
            "  Epoch  60: Train Acc=0.9827, Val Acc=0.9758, F1=0.9662\n",
            "  Epoch  70: Train Acc=0.9869, Val Acc=0.9853, F1=0.9758\n",
            "  Epoch  80: Train Acc=0.9887, Val Acc=0.9865, F1=0.9776\n",
            "  Epoch  90: Train Acc=0.9902, Val Acc=0.9863, F1=0.9775\n",
            "  Epoch 100: Train Acc=0.9927, Val Acc=0.9903, F1=0.9841\n",
            "  Best Val Acc: 0.9903\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9903\n",
            "  Test Acc: 0.9882, F1: 0.9815\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9657, Val Acc=0.9636, F1=0.9395\n",
            "  Epoch  20: Train Acc=0.9816, Val Acc=0.9787, F1=0.9645\n",
            "  Epoch  30: Train Acc=0.9891, Val Acc=0.9841, F1=0.9748\n",
            "  Epoch  40: Train Acc=0.9929, Val Acc=0.9890, F1=0.9812\n",
            "  Epoch  50: Train Acc=0.9936, Val Acc=0.9903, F1=0.9845\n",
            "  Epoch  60: Train Acc=0.9952, Val Acc=0.9899, F1=0.9842\n",
            "  Epoch  70: Train Acc=0.9966, Val Acc=0.9901, F1=0.9831\n",
            "  Epoch  80: Train Acc=0.9966, Val Acc=0.9888, F1=0.9826\n",
            "  Epoch  90: Train Acc=0.9974, Val Acc=0.9907, F1=0.9848\n",
            "  Epoch 100: Train Acc=0.9982, Val Acc=0.9903, F1=0.9854\n",
            "  Best Val Acc: 0.9911\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9911\n",
            "  Test Acc: 0.9886, F1: 0.9791\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9543, Val Acc=0.9607, F1=0.9340\n",
            "  Epoch  20: Train Acc=0.9791, Val Acc=0.9810, F1=0.9684\n",
            "  Epoch  30: Train Acc=0.9875, Val Acc=0.9859, F1=0.9772\n",
            "  Epoch  40: Train Acc=0.9915, Val Acc=0.9853, F1=0.9768\n",
            "  Epoch  50: Train Acc=0.9930, Val Acc=0.9899, F1=0.9827\n",
            "  Epoch  60: Train Acc=0.9954, Val Acc=0.9888, F1=0.9820\n",
            "  Epoch  70: Train Acc=0.9957, Val Acc=0.9897, F1=0.9827\n",
            "  Early stopping at epoch 77\n",
            "  Best Val Acc: 0.9901\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9901\n",
            "  Test Acc: 0.9859, F1: 0.9772\n",
            "\n",
            "[Progress: 2/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_DOWNSTAIRS_30pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_DOWNSTAIRS_30pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_DOWNSTAIRS_30pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9095, Val Acc=0.9178, F1=0.8775\n",
            "  Epoch  20: Train Acc=0.9405, Val Acc=0.9371, F1=0.9043\n",
            "  Epoch  30: Train Acc=0.9592, Val Acc=0.9584, F1=0.9403\n",
            "  Epoch  40: Train Acc=0.9703, Val Acc=0.9534, F1=0.9364\n",
            "  Epoch  50: Train Acc=0.9773, Val Acc=0.9750, F1=0.9630\n",
            "  Epoch  60: Train Acc=0.9816, Val Acc=0.9688, F1=0.9538\n",
            "  Epoch  70: Train Acc=0.9851, Val Acc=0.9820, F1=0.9722\n",
            "  Epoch  80: Train Acc=0.9876, Val Acc=0.9834, F1=0.9714\n",
            "  Epoch  90: Train Acc=0.9908, Val Acc=0.9861, F1=0.9791\n",
            "  Epoch 100: Train Acc=0.9915, Val Acc=0.9826, F1=0.9729\n",
            "  Best Val Acc: 0.9886\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9886\n",
            "  Test Acc: 0.9887, F1: 0.9818\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9591, Val Acc=0.9625, F1=0.9388\n",
            "  Epoch  20: Train Acc=0.9798, Val Acc=0.9805, F1=0.9700\n",
            "  Epoch  30: Train Acc=0.9894, Val Acc=0.9861, F1=0.9756\n",
            "  Epoch  40: Train Acc=0.9921, Val Acc=0.9890, F1=0.9820\n",
            "  Epoch  50: Train Acc=0.9937, Val Acc=0.9892, F1=0.9830\n",
            "  Epoch  60: Train Acc=0.9951, Val Acc=0.9905, F1=0.9856\n",
            "  Early stopping at epoch 63\n",
            "  Best Val Acc: 0.9923\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9923\n",
            "  Test Acc: 0.9884, F1: 0.9805\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9545, Val Acc=0.9547, F1=0.9272\n",
            "  Epoch  20: Train Acc=0.9803, Val Acc=0.9772, F1=0.9641\n",
            "  Epoch  30: Train Acc=0.9876, Val Acc=0.9845, F1=0.9737\n",
            "  Epoch  40: Train Acc=0.9908, Val Acc=0.9859, F1=0.9769\n",
            "  Epoch  50: Train Acc=0.9932, Val Acc=0.9872, F1=0.9809\n",
            "  Epoch  60: Train Acc=0.9947, Val Acc=0.9882, F1=0.9819\n",
            "  Early stopping at epoch 68\n",
            "  Best Val Acc: 0.9901\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9901\n",
            "  Test Acc: 0.9892, F1: 0.9821\n",
            "\n",
            "[Progress: 3/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: WALKING_TO_DOWNSTAIRS_40pct\n",
            "================================================================================\n",
            "\n",
            "Loading WALKING_TO_DOWNSTAIRS_40pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/WALKING_TO_DOWNSTAIRS_40pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9095, Val Acc=0.9029, F1=0.8582\n",
            "  Epoch  20: Train Acc=0.9411, Val Acc=0.9251, F1=0.8859\n",
            "  Epoch  30: Train Acc=0.9610, Val Acc=0.9578, F1=0.9366\n",
            "  Epoch  40: Train Acc=0.9681, Val Acc=0.9441, F1=0.9247\n",
            "  Epoch  50: Train Acc=0.9746, Val Acc=0.9756, F1=0.9617\n",
            "  Epoch  60: Train Acc=0.9801, Val Acc=0.9783, F1=0.9662\n",
            "  Epoch  70: Train Acc=0.9852, Val Acc=0.9822, F1=0.9718\n",
            "  Epoch  80: Train Acc=0.9870, Val Acc=0.9837, F1=0.9742\n",
            "  Epoch  90: Train Acc=0.9888, Val Acc=0.9857, F1=0.9768\n",
            "  Epoch 100: Train Acc=0.9910, Val Acc=0.9870, F1=0.9780\n",
            "  Best Val Acc: 0.9872\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9872\n",
            "  Test Acc: 0.9856, F1: 0.9787\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9599, Val Acc=0.9636, F1=0.9404\n",
            "  Epoch  20: Train Acc=0.9800, Val Acc=0.9745, F1=0.9553\n",
            "  Epoch  30: Train Acc=0.9895, Val Acc=0.9839, F1=0.9739\n",
            "  Epoch  40: Train Acc=0.9922, Val Acc=0.9890, F1=0.9820\n",
            "  Epoch  50: Train Acc=0.9939, Val Acc=0.9901, F1=0.9831\n",
            "  Epoch  60: Train Acc=0.9945, Val Acc=0.9865, F1=0.9783\n",
            "  Epoch  70: Train Acc=0.9963, Val Acc=0.9886, F1=0.9822\n",
            "  Early stopping at epoch 70\n",
            "  Best Val Acc: 0.9901\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9901\n",
            "  Test Acc: 0.9869, F1: 0.9783\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9541, Val Acc=0.9555, F1=0.9291\n",
            "  Epoch  20: Train Acc=0.9794, Val Acc=0.9764, F1=0.9595\n",
            "  Epoch  30: Train Acc=0.9857, Val Acc=0.9847, F1=0.9753\n",
            "  Epoch  40: Train Acc=0.9887, Val Acc=0.9803, F1=0.9711\n",
            "  Epoch  50: Train Acc=0.9929, Val Acc=0.9870, F1=0.9795\n",
            "  Epoch  60: Train Acc=0.9939, Val Acc=0.9870, F1=0.9817\n",
            "  Epoch  70: Train Acc=0.9948, Val Acc=0.9886, F1=0.9836\n",
            "  Epoch  80: Train Acc=0.9955, Val Acc=0.9868, F1=0.9811\n",
            "  Early stopping at epoch 85\n",
            "  Best Val Acc: 0.9899\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9899\n",
            "  Test Acc: 0.9882, F1: 0.9815\n",
            "\n",
            "[Progress: 4/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: UPSTAIRS_TO_WALKING_10pct\n",
            "================================================================================\n",
            "\n",
            "Loading UPSTAIRS_TO_WALKING_10pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/UPSTAIRS_TO_WALKING_10pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.9013, Val Acc=0.9176, F1=0.8944\n",
            "  Epoch  20: Train Acc=0.9399, Val Acc=0.9474, F1=0.9286\n",
            "  Epoch  30: Train Acc=0.9598, Val Acc=0.9636, F1=0.9546\n",
            "  Epoch  40: Train Acc=0.9707, Val Acc=0.9733, F1=0.9662\n",
            "  Epoch  50: Train Acc=0.9764, Val Acc=0.9799, F1=0.9754\n",
            "  Epoch  60: Train Acc=0.9821, Val Acc=0.9886, F1=0.9851\n",
            "  Epoch  70: Train Acc=0.9846, Val Acc=0.9791, F1=0.9731\n",
            "  Epoch  80: Train Acc=0.9887, Val Acc=0.9845, F1=0.9792\n",
            "  Epoch  90: Train Acc=0.9892, Val Acc=0.9909, F1=0.9869\n",
            "  Early stopping at epoch 99\n",
            "  Best Val Acc: 0.9928\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9928\n",
            "  Test Acc: 0.9889, F1: 0.9850\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9586, Val Acc=0.9630, F1=0.9439\n",
            "  Epoch  20: Train Acc=0.9805, Val Acc=0.9797, F1=0.9669\n",
            "  Epoch  30: Train Acc=0.9897, Val Acc=0.9865, F1=0.9816\n",
            "  Epoch  40: Train Acc=0.9933, Val Acc=0.9897, F1=0.9860\n",
            "  Epoch  50: Train Acc=0.9940, Val Acc=0.9905, F1=0.9883\n",
            "  Epoch  60: Train Acc=0.9954, Val Acc=0.9899, F1=0.9883\n",
            "  Epoch  70: Train Acc=0.9971, Val Acc=0.9899, F1=0.9877\n",
            "  Early stopping at epoch 77\n",
            "  Best Val Acc: 0.9930\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9930\n",
            "  Test Acc: 0.9901, F1: 0.9840\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9490, Val Acc=0.9553, F1=0.9338\n",
            "  Epoch  20: Train Acc=0.9744, Val Acc=0.9704, F1=0.9559\n",
            "  Epoch  30: Train Acc=0.9844, Val Acc=0.9843, F1=0.9780\n",
            "  Epoch  40: Train Acc=0.9888, Val Acc=0.9882, F1=0.9828\n",
            "  Epoch  50: Train Acc=0.9917, Val Acc=0.9905, F1=0.9871\n",
            "  Epoch  60: Train Acc=0.9928, Val Acc=0.9894, F1=0.9860\n",
            "  Epoch  70: Train Acc=0.9952, Val Acc=0.9901, F1=0.9865\n",
            "  Epoch  80: Train Acc=0.9959, Val Acc=0.9905, F1=0.9872\n",
            "  Early stopping at epoch 81\n",
            "  Best Val Acc: 0.9913\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9913\n",
            "  Test Acc: 0.9876, F1: 0.9822\n",
            "\n",
            "[Progress: 5/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: UPSTAIRS_TO_WALKING_20pct\n",
            "================================================================================\n",
            "\n",
            "Loading UPSTAIRS_TO_WALKING_20pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/UPSTAIRS_TO_WALKING_20pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.8949, Val Acc=0.9038, F1=0.8765\n",
            "  Epoch  20: Train Acc=0.9376, Val Acc=0.9410, F1=0.9211\n",
            "  Epoch  30: Train Acc=0.9607, Val Acc=0.9588, F1=0.9487\n",
            "  Epoch  40: Train Acc=0.9704, Val Acc=0.9729, F1=0.9663\n",
            "  Epoch  50: Train Acc=0.9796, Val Acc=0.9710, F1=0.9653\n",
            "  Epoch  60: Train Acc=0.9832, Val Acc=0.9797, F1=0.9741\n",
            "  Epoch  70: Train Acc=0.9865, Val Acc=0.9803, F1=0.9741\n",
            "  Epoch  80: Train Acc=0.9877, Val Acc=0.9665, F1=0.9583\n",
            "  Epoch  90: Train Acc=0.9898, Val Acc=0.9834, F1=0.9779\n",
            "  Epoch 100: Train Acc=0.9908, Val Acc=0.9841, F1=0.9785\n",
            "  Best Val Acc: 0.9876\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9876\n",
            "  Test Acc: 0.9897, F1: 0.9851\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9570, Val Acc=0.9605, F1=0.9428\n",
            "  Epoch  20: Train Acc=0.9824, Val Acc=0.9793, F1=0.9723\n",
            "  Epoch  30: Train Acc=0.9905, Val Acc=0.9855, F1=0.9801\n",
            "  Epoch  40: Train Acc=0.9932, Val Acc=0.9868, F1=0.9813\n",
            "  Epoch  50: Train Acc=0.9948, Val Acc=0.9865, F1=0.9799\n",
            "  Epoch  60: Train Acc=0.9957, Val Acc=0.9863, F1=0.9790\n",
            "  Epoch  70: Train Acc=0.9972, Val Acc=0.9880, F1=0.9825\n",
            "  Early stopping at epoch 73\n",
            "  Best Val Acc: 0.9897\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9897\n",
            "  Test Acc: 0.9901, F1: 0.9844\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9461, Val Acc=0.9468, F1=0.9259\n",
            "  Epoch  20: Train Acc=0.9752, Val Acc=0.9787, F1=0.9715\n",
            "  Epoch  30: Train Acc=0.9863, Val Acc=0.9843, F1=0.9781\n",
            "  Epoch  40: Train Acc=0.9895, Val Acc=0.9855, F1=0.9797\n",
            "  Epoch  50: Train Acc=0.9929, Val Acc=0.9861, F1=0.9818\n",
            "  Early stopping at epoch 55\n",
            "  Best Val Acc: 0.9861\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9861\n",
            "  Test Acc: 0.9877, F1: 0.9830\n",
            "\n",
            "[Progress: 6/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: UPSTAIRS_TO_WALKING_30pct\n",
            "================================================================================\n",
            "\n",
            "Loading UPSTAIRS_TO_WALKING_30pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/UPSTAIRS_TO_WALKING_30pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.8936, Val Acc=0.8936, F1=0.8517\n",
            "  Epoch  20: Train Acc=0.9339, Val Acc=0.9464, F1=0.9386\n",
            "  Epoch  30: Train Acc=0.9591, Val Acc=0.9590, F1=0.9518\n",
            "  Epoch  40: Train Acc=0.9689, Val Acc=0.9702, F1=0.9650\n",
            "  Epoch  50: Train Acc=0.9765, Val Acc=0.9698, F1=0.9654\n",
            "  Epoch  60: Train Acc=0.9815, Val Acc=0.9776, F1=0.9743\n",
            "  Epoch  70: Train Acc=0.9860, Val Acc=0.9845, F1=0.9800\n",
            "  Epoch  80: Train Acc=0.9877, Val Acc=0.9868, F1=0.9824\n",
            "  Epoch  90: Train Acc=0.9894, Val Acc=0.9888, F1=0.9852\n",
            "  Epoch 100: Train Acc=0.9916, Val Acc=0.9849, F1=0.9750\n",
            "  Best Val Acc: 0.9897\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9897\n",
            "  Test Acc: 0.9877, F1: 0.9848\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9509, Val Acc=0.9584, F1=0.9410\n",
            "  Epoch  20: Train Acc=0.9797, Val Acc=0.9776, F1=0.9714\n",
            "  Epoch  30: Train Acc=0.9869, Val Acc=0.9826, F1=0.9780\n",
            "  Epoch  40: Train Acc=0.9919, Val Acc=0.9849, F1=0.9797\n",
            "  Epoch  50: Train Acc=0.9943, Val Acc=0.9882, F1=0.9837\n",
            "  Epoch  60: Train Acc=0.9954, Val Acc=0.9863, F1=0.9817\n",
            "  Early stopping at epoch 65\n",
            "  Best Val Acc: 0.9886\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9886\n",
            "  Test Acc: 0.9871, F1: 0.9818\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9372, Val Acc=0.9414, F1=0.9252\n",
            "  Epoch  20: Train Acc=0.9737, Val Acc=0.9739, F1=0.9681\n",
            "  Epoch  30: Train Acc=0.9834, Val Acc=0.9783, F1=0.9710\n",
            "  Epoch  40: Train Acc=0.9879, Val Acc=0.9849, F1=0.9796\n",
            "  Epoch  50: Train Acc=0.9921, Val Acc=0.9859, F1=0.9818\n",
            "  Epoch  60: Train Acc=0.9932, Val Acc=0.9861, F1=0.9829\n",
            "  Epoch  70: Train Acc=0.9945, Val Acc=0.9878, F1=0.9844\n",
            "  Epoch  80: Train Acc=0.9969, Val Acc=0.9874, F1=0.9843\n",
            "  Epoch  90: Train Acc=0.9967, Val Acc=0.9847, F1=0.9801\n",
            "  Early stopping at epoch 99\n",
            "  Best Val Acc: 0.9886\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9886\n",
            "  Test Acc: 0.9884, F1: 0.9842\n",
            "\n",
            "[Progress: 7/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: UPSTAIRS_TO_WALKING_40pct\n",
            "================================================================================\n",
            "\n",
            "Loading UPSTAIRS_TO_WALKING_40pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/UPSTAIRS_TO_WALKING_40pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.8860, Val Acc=0.8928, F1=0.8685\n",
            "  Epoch  20: Train Acc=0.9295, Val Acc=0.9282, F1=0.9131\n",
            "  Epoch  30: Train Acc=0.9535, Val Acc=0.9532, F1=0.9472\n",
            "  Epoch  40: Train Acc=0.9648, Val Acc=0.9675, F1=0.9608\n",
            "  Epoch  50: Train Acc=0.9751, Val Acc=0.9729, F1=0.9662\n",
            "  Epoch  60: Train Acc=0.9802, Val Acc=0.9768, F1=0.9697\n",
            "  Epoch  70: Train Acc=0.9835, Val Acc=0.9754, F1=0.9692\n",
            "  Epoch  80: Train Acc=0.9859, Val Acc=0.9826, F1=0.9765\n",
            "  Epoch  90: Train Acc=0.9888, Val Acc=0.9832, F1=0.9791\n",
            "  Epoch 100: Train Acc=0.9917, Val Acc=0.9805, F1=0.9741\n",
            "  Best Val Acc: 0.9872\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9872\n",
            "  Test Acc: 0.9884, F1: 0.9834\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9500, Val Acc=0.9526, F1=0.9320\n",
            "  Epoch  20: Train Acc=0.9792, Val Acc=0.9716, F1=0.9604\n",
            "  Epoch  30: Train Acc=0.9875, Val Acc=0.9789, F1=0.9701\n",
            "  Epoch  40: Train Acc=0.9905, Val Acc=0.9810, F1=0.9745\n",
            "  Epoch  50: Train Acc=0.9943, Val Acc=0.9826, F1=0.9747\n",
            "  Epoch  60: Train Acc=0.9949, Val Acc=0.9834, F1=0.9775\n",
            "  Epoch  70: Train Acc=0.9952, Val Acc=0.9857, F1=0.9803\n",
            "  Epoch  80: Train Acc=0.9974, Val Acc=0.9826, F1=0.9760\n",
            "  Epoch  90: Train Acc=0.9973, Val Acc=0.9830, F1=0.9761\n",
            "  Early stopping at epoch 91\n",
            "  Best Val Acc: 0.9868\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9868\n",
            "  Test Acc: 0.9881, F1: 0.9824\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9398, Val Acc=0.9389, F1=0.9205\n",
            "  Epoch  20: Train Acc=0.9735, Val Acc=0.9659, F1=0.9562\n",
            "  Epoch  30: Train Acc=0.9823, Val Acc=0.9762, F1=0.9674\n",
            "  Epoch  40: Train Acc=0.9892, Val Acc=0.9803, F1=0.9745\n",
            "  Epoch  50: Train Acc=0.9906, Val Acc=0.9826, F1=0.9769\n",
            "  Epoch  60: Train Acc=0.9942, Val Acc=0.9799, F1=0.9736\n",
            "  Epoch  70: Train Acc=0.9943, Val Acc=0.9834, F1=0.9773\n",
            "  Epoch  80: Train Acc=0.9953, Val Acc=0.9824, F1=0.9755\n",
            "  Epoch  90: Train Acc=0.9964, Val Acc=0.9801, F1=0.9726\n",
            "  Early stopping at epoch 91\n",
            "  Best Val Acc: 0.9859\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9859\n",
            "  Test Acc: 0.9873, F1: 0.9821\n",
            "\n",
            "[Progress: 8/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: DOWNSTAIRS_TO_WALKING_10pct\n",
            "================================================================================\n",
            "\n",
            "Loading DOWNSTAIRS_TO_WALKING_10pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/DOWNSTAIRS_TO_WALKING_10pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.8999, Val Acc=0.9017, F1=0.8728\n",
            "  Epoch  20: Train Acc=0.9436, Val Acc=0.9369, F1=0.9190\n",
            "  Epoch  30: Train Acc=0.9643, Val Acc=0.9671, F1=0.9614\n",
            "  Epoch  40: Train Acc=0.9710, Val Acc=0.9685, F1=0.9635\n",
            "  Epoch  50: Train Acc=0.9783, Val Acc=0.9779, F1=0.9740\n",
            "  Epoch  60: Train Acc=0.9853, Val Acc=0.9839, F1=0.9798\n",
            "  Epoch  70: Train Acc=0.9872, Val Acc=0.9837, F1=0.9794\n",
            "  Epoch  80: Train Acc=0.9901, Val Acc=0.9870, F1=0.9831\n",
            "  Epoch  90: Train Acc=0.9918, Val Acc=0.9897, F1=0.9872\n",
            "  Epoch 100: Train Acc=0.9923, Val Acc=0.9880, F1=0.9847\n",
            "  Best Val Acc: 0.9905\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9905\n",
            "  Test Acc: 0.9864, F1: 0.9805\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9584, Val Acc=0.9553, F1=0.9377\n",
            "  Epoch  20: Train Acc=0.9828, Val Acc=0.9799, F1=0.9711\n",
            "  Epoch  30: Train Acc=0.9903, Val Acc=0.9872, F1=0.9804\n",
            "  Epoch  40: Train Acc=0.9928, Val Acc=0.9888, F1=0.9832\n",
            "  Epoch  50: Train Acc=0.9946, Val Acc=0.9888, F1=0.9831\n",
            "  Epoch  60: Train Acc=0.9965, Val Acc=0.9894, F1=0.9845\n",
            "  Epoch  70: Train Acc=0.9969, Val Acc=0.9909, F1=0.9852\n",
            "  Epoch  80: Train Acc=0.9973, Val Acc=0.9903, F1=0.9860\n",
            "  Epoch  90: Train Acc=0.9978, Val Acc=0.9907, F1=0.9843\n",
            "  Epoch 100: Train Acc=0.9981, Val Acc=0.9917, F1=0.9880\n",
            "  Best Val Acc: 0.9919\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9919\n",
            "  Test Acc: 0.9891, F1: 0.9854\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9561, Val Acc=0.9580, F1=0.9460\n",
            "  Epoch  20: Train Acc=0.9797, Val Acc=0.9785, F1=0.9737\n",
            "  Epoch  30: Train Acc=0.9898, Val Acc=0.9814, F1=0.9754\n",
            "  Epoch  40: Train Acc=0.9923, Val Acc=0.9868, F1=0.9817\n",
            "  Epoch  50: Train Acc=0.9942, Val Acc=0.9894, F1=0.9846\n",
            "  Epoch  60: Train Acc=0.9959, Val Acc=0.9888, F1=0.9844\n",
            "  Epoch  70: Train Acc=0.9963, Val Acc=0.9853, F1=0.9787\n",
            "  Epoch  80: Train Acc=0.9974, Val Acc=0.9886, F1=0.9846\n",
            "  Epoch  90: Train Acc=0.9977, Val Acc=0.9899, F1=0.9854\n",
            "  Early stopping at epoch 95\n",
            "  Best Val Acc: 0.9913\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9913\n",
            "  Test Acc: 0.9866, F1: 0.9817\n",
            "\n",
            "[Progress: 9/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: DOWNSTAIRS_TO_WALKING_20pct\n",
            "================================================================================\n",
            "\n",
            "Loading DOWNSTAIRS_TO_WALKING_20pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/DOWNSTAIRS_TO_WALKING_20pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.8971, Val Acc=0.9131, F1=0.8913\n",
            "  Epoch  20: Train Acc=0.9419, Val Acc=0.9427, F1=0.9325\n",
            "  Epoch  30: Train Acc=0.9606, Val Acc=0.9619, F1=0.9571\n",
            "  Epoch  40: Train Acc=0.9711, Val Acc=0.9756, F1=0.9726\n",
            "  Epoch  50: Train Acc=0.9772, Val Acc=0.9816, F1=0.9778\n",
            "  Epoch  60: Train Acc=0.9829, Val Acc=0.9847, F1=0.9813\n",
            "  Epoch  70: Train Acc=0.9856, Val Acc=0.9853, F1=0.9811\n",
            "  Epoch  80: Train Acc=0.9881, Val Acc=0.9899, F1=0.9869\n",
            "  Epoch  90: Train Acc=0.9891, Val Acc=0.9917, F1=0.9871\n",
            "  Epoch 100: Train Acc=0.9894, Val Acc=0.9878, F1=0.9843\n",
            "  Best Val Acc: 0.9932\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9932\n",
            "  Test Acc: 0.9894, F1: 0.9862\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9550, Val Acc=0.9580, F1=0.9411\n",
            "  Epoch  20: Train Acc=0.9811, Val Acc=0.9828, F1=0.9754\n",
            "  Epoch  30: Train Acc=0.9886, Val Acc=0.9872, F1=0.9811\n",
            "  Epoch  40: Train Acc=0.9922, Val Acc=0.9903, F1=0.9844\n",
            "  Epoch  50: Train Acc=0.9940, Val Acc=0.9886, F1=0.9816\n",
            "  Epoch  60: Train Acc=0.9959, Val Acc=0.9886, F1=0.9831\n",
            "  Early stopping at epoch 60\n",
            "  Best Val Acc: 0.9903\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9903\n",
            "  Test Acc: 0.9896, F1: 0.9852\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9541, Val Acc=0.9650, F1=0.9522\n",
            "  Epoch  20: Train Acc=0.9782, Val Acc=0.9822, F1=0.9758\n",
            "  Epoch  30: Train Acc=0.9871, Val Acc=0.9845, F1=0.9788\n",
            "  Epoch  40: Train Acc=0.9912, Val Acc=0.9818, F1=0.9739\n",
            "  Epoch  50: Train Acc=0.9933, Val Acc=0.9876, F1=0.9823\n",
            "  Epoch  60: Train Acc=0.9943, Val Acc=0.9894, F1=0.9850\n",
            "  Epoch  70: Train Acc=0.9960, Val Acc=0.9909, F1=0.9869\n",
            "  Epoch  80: Train Acc=0.9963, Val Acc=0.9892, F1=0.9857\n",
            "  Epoch  90: Train Acc=0.9968, Val Acc=0.9899, F1=0.9868\n",
            "  Epoch 100: Train Acc=0.9976, Val Acc=0.9892, F1=0.9837\n",
            "  Best Val Acc: 0.9913\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9913\n",
            "  Test Acc: 0.9889, F1: 0.9852\n",
            "\n",
            "[Progress: 10/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: DOWNSTAIRS_TO_WALKING_30pct\n",
            "================================================================================\n",
            "\n",
            "Loading DOWNSTAIRS_TO_WALKING_30pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/DOWNSTAIRS_TO_WALKING_30pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.8994, Val Acc=0.8953, F1=0.8791\n",
            "  Epoch  20: Train Acc=0.9379, Val Acc=0.9458, F1=0.9341\n",
            "  Epoch  30: Train Acc=0.9612, Val Acc=0.9621, F1=0.9543\n",
            "  Epoch  40: Train Acc=0.9694, Val Acc=0.9721, F1=0.9692\n",
            "  Epoch  50: Train Acc=0.9752, Val Acc=0.9748, F1=0.9693\n",
            "  Epoch  60: Train Acc=0.9807, Val Acc=0.9793, F1=0.9739\n",
            "  Epoch  70: Train Acc=0.9846, Val Acc=0.9793, F1=0.9757\n",
            "  Epoch  80: Train Acc=0.9872, Val Acc=0.9752, F1=0.9707\n",
            "  Epoch  90: Train Acc=0.9886, Val Acc=0.9861, F1=0.9833\n",
            "  Epoch 100: Train Acc=0.9914, Val Acc=0.9855, F1=0.9815\n",
            "  Best Val Acc: 0.9880\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9880\n",
            "  Test Acc: 0.9846, F1: 0.9820\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9499, Val Acc=0.9516, F1=0.9323\n",
            "  Epoch  20: Train Acc=0.9769, Val Acc=0.9764, F1=0.9661\n",
            "  Epoch  30: Train Acc=0.9883, Val Acc=0.9839, F1=0.9768\n",
            "  Epoch  40: Train Acc=0.9913, Val Acc=0.9874, F1=0.9818\n",
            "  Epoch  50: Train Acc=0.9940, Val Acc=0.9878, F1=0.9836\n",
            "  Epoch  60: Train Acc=0.9949, Val Acc=0.9886, F1=0.9858\n",
            "  Epoch  70: Train Acc=0.9953, Val Acc=0.9884, F1=0.9834\n",
            "  Epoch  80: Train Acc=0.9968, Val Acc=0.9888, F1=0.9856\n",
            "  Epoch  90: Train Acc=0.9982, Val Acc=0.9876, F1=0.9833\n",
            "  Epoch 100: Train Acc=0.9981, Val Acc=0.9884, F1=0.9845\n",
            "  Best Val Acc: 0.9897\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9897\n",
            "  Test Acc: 0.9882, F1: 0.9853\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9505, Val Acc=0.9563, F1=0.9416\n",
            "  Epoch  20: Train Acc=0.9774, Val Acc=0.9774, F1=0.9707\n",
            "  Epoch  30: Train Acc=0.9866, Val Acc=0.9820, F1=0.9764\n",
            "  Epoch  40: Train Acc=0.9899, Val Acc=0.9853, F1=0.9806\n",
            "  Epoch  50: Train Acc=0.9922, Val Acc=0.9865, F1=0.9831\n",
            "  Epoch  60: Train Acc=0.9949, Val Acc=0.9880, F1=0.9851\n",
            "  Epoch  70: Train Acc=0.9955, Val Acc=0.9880, F1=0.9858\n",
            "  Epoch  80: Train Acc=0.9967, Val Acc=0.9884, F1=0.9852\n",
            "  Early stopping at epoch 83\n",
            "  Best Val Acc: 0.9894\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9894\n",
            "  Test Acc: 0.9866, F1: 0.9831\n",
            "\n",
            "[Progress: 11/11]\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT: DOWNSTAIRS_TO_WALKING_40pct\n",
            "================================================================================\n",
            "\n",
            "Loading DOWNSTAIRS_TO_WALKING_40pct...\n",
            "  Path: /content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets/DOWNSTAIRS_TO_WALKING_40pct\n",
            "  Train: (24156, 200, 3), Test: (6040, 200, 3)\n",
            "\n",
            "Dataset splits:\n",
            "  Train: 19324, Val: 4832, Test: 6040\n",
            "\n",
            "[Training GAP]\n",
            "  Epoch  10: Train Acc=0.8904, Val Acc=0.8814, F1=0.8587\n",
            "  Epoch  20: Train Acc=0.9313, Val Acc=0.9222, F1=0.9050\n",
            "  Epoch  30: Train Acc=0.9544, Val Acc=0.9505, F1=0.9380\n",
            "  Epoch  40: Train Acc=0.9662, Val Acc=0.9683, F1=0.9634\n",
            "  Epoch  50: Train Acc=0.9722, Val Acc=0.9737, F1=0.9694\n",
            "  Epoch  60: Train Acc=0.9796, Val Acc=0.9710, F1=0.9670\n",
            "  Epoch  70: Train Acc=0.9820, Val Acc=0.9774, F1=0.9739\n",
            "  Epoch  80: Train Acc=0.9844, Val Acc=0.9812, F1=0.9790\n",
            "  Epoch  90: Train Acc=0.9869, Val Acc=0.9783, F1=0.9770\n",
            "  Epoch 100: Train Acc=0.9891, Val Acc=0.9826, F1=0.9815\n",
            "  Best Val Acc: 0.9861\n",
            "\n",
            "[GAP Results]\n",
            "  Val Acc: 0.9861\n",
            "  Test Acc: 0.9833, F1: 0.9793\n",
            "\n",
            "[Training TPA]\n",
            "  Epoch  10: Train Acc=0.9501, Val Acc=0.9518, F1=0.9351\n",
            "  Epoch  20: Train Acc=0.9782, Val Acc=0.9768, F1=0.9723\n",
            "  Epoch  30: Train Acc=0.9872, Val Acc=0.9832, F1=0.9803\n",
            "  Epoch  40: Train Acc=0.9907, Val Acc=0.9870, F1=0.9848\n",
            "  Epoch  50: Train Acc=0.9924, Val Acc=0.9857, F1=0.9811\n",
            "  Epoch  60: Train Acc=0.9938, Val Acc=0.9859, F1=0.9827\n",
            "  Epoch  70: Train Acc=0.9953, Val Acc=0.9872, F1=0.9829\n",
            "  Early stopping at epoch 74\n",
            "  Best Val Acc: 0.9884\n",
            "\n",
            "[TPA Results]\n",
            "  Val Acc: 0.9884\n",
            "  Test Acc: 0.9887, F1: 0.9847\n",
            "\n",
            "[Training Gated-TPA]\n",
            "  Epoch  10: Train Acc=0.9516, Val Acc=0.9549, F1=0.9398\n",
            "  Epoch  20: Train Acc=0.9769, Val Acc=0.9768, F1=0.9732\n",
            "  Epoch  30: Train Acc=0.9864, Val Acc=0.9826, F1=0.9795\n",
            "  Epoch  40: Train Acc=0.9901, Val Acc=0.9820, F1=0.9770\n",
            "  Epoch  50: Train Acc=0.9919, Val Acc=0.9849, F1=0.9824\n",
            "  Epoch  60: Train Acc=0.9939, Val Acc=0.9837, F1=0.9801\n",
            "  Epoch  70: Train Acc=0.9948, Val Acc=0.9868, F1=0.9852\n",
            "  Epoch  80: Train Acc=0.9961, Val Acc=0.9870, F1=0.9846\n",
            "  Epoch  90: Train Acc=0.9974, Val Acc=0.9865, F1=0.9837\n",
            "  Early stopping at epoch 91\n",
            "  Best Val Acc: 0.9886\n",
            "\n",
            "[Gated-TPA Results]\n",
            "  Val Acc: 0.9886\n",
            "  Test Acc: 0.9877, F1: 0.9850\n",
            "\n",
            "================================================================================\n",
            "SAVING RESULTS\n",
            "================================================================================\n",
            "\n",
            "Results saved to: /content/drive/MyDrive/AI_data/TPA2/unified_comparison_41datasets_results.json\n",
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "Total experiments: 33\n",
            "Total datasets tested: 11\n",
            "Models compared: 3 (GAP, TPA, Gated-TPA)\n",
            "\n",
            "================================================================================\n",
            "AVERAGE PERFORMANCE (All Datasets)\n",
            "================================================================================\n",
            "GAP         : Acc=0.9874, F1=0.9826\n",
            "TPA         : Acc=0.9886, F1=0.9828\n",
            "Gated-TPA   : Acc=0.9877, F1=0.9825\n",
            "\n",
            "================================================================================\n",
            "EXPERIMENT COMPLETE\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"unified_transition_1024.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1q8L0az2N02xlgQ_FLiQds-TEaFqLfsON\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Unified Model Comparison: GAP, TPA, Gated-TPA\n",
        "Compare three models on 41 pre-augmented transition datasets\n",
        "(1 original + 40 transition datasets)\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, random, time, copy, json\n",
        "import numpy as np\n",
        "from typing import Tuple, Dict, List\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ========================\n",
        "# Config & Reproducibility\n",
        "# ========================\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    data_dir: str = \"/content/drive/MyDrive/AI_data/TPA2/wisdm_transition_datasets\"\n",
        "    save_dir: str = \"/content/drive/MyDrive/AI_data/TPA2\"\n",
        "\n",
        "    epochs: int = 100\n",
        "    batch_size: int = 128\n",
        "    lr: float = 1e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    grad_clip: float = 1.0\n",
        "    label_smoothing: float = 0.05\n",
        "\n",
        "    patience: int = 20\n",
        "    min_delta: float = 0.0001\n",
        "    val_split: float = 0.2\n",
        "\n",
        "    d_model: int = 128\n",
        "\n",
        "    # TPA hyperparameters\n",
        "    tpa_num_prototypes: int = 16\n",
        "    tpa_heads: int = 4\n",
        "    tpa_dropout: float = 0.1\n",
        "    tpa_temperature: float = 0.07\n",
        "    tpa_topk_ratio: float = 0.25\n",
        "\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    num_workers: int = 2\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# ========================\n",
        "# Dataset Class\n",
        "# ========================\n",
        "class PreloadedDataset(Dataset):\n",
        "    \"\"\"Dataset for pre-loaded numpy arrays\"\"\"\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
        "        super().__init__()\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "\n",
        "        # Label 범위 확인 및 조정 (1-6 -> 0-5)\n",
        "        if y.min() >= 1:\n",
        "            y = y - 1\n",
        "\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# ========================\n",
        "# Data Loading Functions\n",
        "# ========================\n",
        "def load_dataset(base_dir: str, dataset_name: str):\n",
        "    \"\"\"\n",
        "    Load pre-augmented dataset\n",
        "    Args:\n",
        "        base_dir: base directory containing all datasets\n",
        "        dataset_name: e.g., \"ORIGINAL\", \"STANDING_TO_SITTING_10pct\", etc.\n",
        "    Returns:\n",
        "        train_dataset, test_dataset\n",
        "    \"\"\"\n",
        "    dataset_dir = os.path.join(base_dir, dataset_name)\n",
        "\n",
        "    print(f\"\\nLoading {dataset_name}...\")\n",
        "    print(f\"  Path: {dataset_dir}\")\n",
        "\n",
        "    # Load data\n",
        "    X_train = np.load(os.path.join(dataset_dir, \"X_train.npy\"))\n",
        "    y_train = np.load(os.path.join(dataset_dir, \"y_train.npy\"))\n",
        "    X_test = np.load(os.path.join(dataset_dir, \"X_test.npy\"))\n",
        "    y_test = np.load(os.path.join(dataset_dir, \"y_test.npy\"))\n",
        "\n",
        "    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "\n",
        "    train_dataset = PreloadedDataset(X_train, y_train)\n",
        "    test_dataset = PreloadedDataset(X_test, y_test)\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "# ========================\n",
        "# Model Components\n",
        "# ========================\n",
        "class BiLSTMBackbone(nn.Module):\n",
        "    \"\"\"BiLSTM backbone for all models\n",
        "    Args:\n",
        "        in_ch: input channels (default: 3)\n",
        "        d_model: output dimension (default: 128)\n",
        "        hidden_dim: LSTM hidden dimension (default: 64, bidirectional -> 128)\n",
        "        num_layers: number of LSTM layers (default: 2)\n",
        "        dropout: dropout rate (default: 0.1)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch=3, d_model=128, hidden_dim=64, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # BiLSTM: hidden_dim=64 → 양방향이므로 출력은 128\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=in_ch,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        # 투영층: BiLSTM 출력(128) → d_model(128)\n",
        "        self.projection = nn.Linear(hidden_dim * 2, d_model)\n",
        "\n",
        "        # 정규화 및 드롭아웃\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, C, T] → [B, T, C] (LSTM은 [B, T, C] 형태 입력)\n",
        "        # x = x.transpose(1, 2)\n",
        "\n",
        "        # BiLSTM\n",
        "        lstm_out, _ = self.lstm(x)  # [B, T, hidden_dim*2=128]\n",
        "\n",
        "        # 투영\n",
        "        out = self.projection(lstm_out)  # [B, T, d_model=128]\n",
        "\n",
        "        # 정규화 + 드롭아웃\n",
        "        out = self.layer_norm(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        # [B, T, D] → [B, D, T] (기존 코드와의 호환성)\n",
        "        return out.transpose(1, 2)\n",
        "\n",
        "# ========================\n",
        "# GAP Model\n",
        "# ========================\n",
        "class GAPModel(nn.Module):\n",
        "    \"\"\"Baseline: Global Average Pooling\"\"\"\n",
        "    def __init__(self, d_model=128, num_classes=6):\n",
        "        super().__init__()\n",
        "        self.backbone = BiLSTMBackbone(d_model=d_model)\n",
        "        self.fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fmap = self.backbone(x)  # [B, D, T]\n",
        "        features = fmap.transpose(1, 2)  # [B, T, D]\n",
        "        pooled = features.mean(dim=1)  # [B, D]\n",
        "        logits = self.fc(pooled)\n",
        "        return logits\n",
        "\n",
        "# ========================\n",
        "# Pure-TPA\n",
        "# ========================\n",
        "class ProductionTPA(nn.Module):\n",
        "    \"\"\"Pure TPA\"\"\"\n",
        "    def __init__(self, dim, num_prototypes=16, heads=4, dropout=0.1,\n",
        "                 temperature=0.07, topk_ratio=0.25):\n",
        "        super().__init__()\n",
        "        assert dim % heads == 0\n",
        "\n",
        "        self.dim = dim\n",
        "        self.heads = heads\n",
        "        self.head_dim = dim // heads\n",
        "        self.num_prototypes = num_prototypes\n",
        "        self.temperature = temperature\n",
        "        self.topk_ratio = topk_ratio\n",
        "\n",
        "        self.proto = nn.Parameter(torch.randn(num_prototypes, dim) * 0.02)\n",
        "\n",
        "        self.pre_norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.q_proj = nn.Linear(dim, dim, bias=False)\n",
        "        self.k_proj = nn.Linear(dim, dim, bias=False)\n",
        "        self.v_proj = nn.Linear(dim, dim, bias=False)\n",
        "\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, D = x.shape\n",
        "        P = self.num_prototypes\n",
        "\n",
        "        x_norm = self.pre_norm(x)\n",
        "\n",
        "        K = self.k_proj(x_norm)\n",
        "        V = self.v_proj(x_norm)\n",
        "        Qp = self.q_proj(self.proto).unsqueeze(0).expand(B, -1, -1)\n",
        "\n",
        "        def split_heads(t, length):\n",
        "            return t.view(B, length, self.heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        Qh = split_heads(Qp, P)\n",
        "        Kh = split_heads(K, T)\n",
        "        Vh = split_heads(V, T)\n",
        "\n",
        "        Qh = F.normalize(Qh, dim=-1)\n",
        "        Kh = F.normalize(Kh, dim=-1)\n",
        "\n",
        "        scores = torch.matmul(Qh, Kh.transpose(-2, -1)) / self.temperature\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        attn = torch.nan_to_num(attn, nan=0.0)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        proto_tokens = torch.matmul(attn, Vh)\n",
        "        proto_tokens = proto_tokens.transpose(1, 2).contiguous().view(B, P, D)\n",
        "\n",
        "        z_tpa = proto_tokens.mean(dim=1)\n",
        "\n",
        "        z = self.fuse(z_tpa)\n",
        "\n",
        "        return z\n",
        "\n",
        "class TPAModel(nn.Module):\n",
        "    def __init__(self, d_model=128, num_classes=6, tpa_config=None):\n",
        "        super().__init__()\n",
        "        self.backbone = BiLSTMBackbone(d_model=d_model)\n",
        "        self.tpa = ProductionTPA(\n",
        "            dim=d_model,\n",
        "            num_prototypes=tpa_config['num_prototypes'],\n",
        "            heads=tpa_config['heads'],\n",
        "            dropout=tpa_config['dropout'],\n",
        "            temperature=tpa_config['temperature'],\n",
        "            topk_ratio=tpa_config['topk_ratio']\n",
        "        )\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fmap = self.backbone(x)  # [B, D, T]\n",
        "        features = fmap.transpose(1, 2)  # [B, T, D]\n",
        "        z = self.tpa(features)  # [B, D]\n",
        "        logits = self.classifier(z)\n",
        "        return logits\n",
        "\n",
        "# ========================\n",
        "# Gated-TPA\n",
        "# ========================\n",
        "class GatedTPAModel(nn.Module):\n",
        "    def __init__(self, d_model=128, num_classes=6, tpa_config=None):\n",
        "        super().__init__()\n",
        "        self.backbone = BiLSTMBackbone(d_model=d_model)\n",
        "        self.tpa = ProductionTPA(\n",
        "            dim=d_model,\n",
        "            num_prototypes=tpa_config['num_prototypes'],\n",
        "            heads=tpa_config['heads'],\n",
        "            dropout=tpa_config['dropout'],\n",
        "            temperature=tpa_config['temperature'],\n",
        "            topk_ratio=tpa_config['topk_ratio']\n",
        "        )\n",
        "\n",
        "        # Gating mechanism\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(d_model * 2, d_model),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fmap = self.backbone(x)  # [B, D, T]\n",
        "        features = fmap.transpose(1, 2)  # [B, T, D]\n",
        "\n",
        "        # GAP branch\n",
        "        z_gap = features.mean(dim=1)  # [B, D]\n",
        "\n",
        "        # TPA branch\n",
        "        z_tpa = self.tpa(features)  # [B, D]\n",
        "\n",
        "        # Gating\n",
        "        gate_input = torch.cat([z_gap, z_tpa], dim=-1)\n",
        "        g = self.gate(gate_input)\n",
        "\n",
        "        # Gated fusion\n",
        "        z = g * z_gap + (1 - g) * z_tpa\n",
        "\n",
        "        logits = self.classifier(z)\n",
        "        return logits\n",
        "\n",
        "# ========================\n",
        "# Training & Evaluation\n",
        "# ========================\n",
        "def train_one_epoch(model, loader, opt, cfg: Config):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(cfg.device).float(), y.to(cfg.device)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(x)\n",
        "\n",
        "        loss = F.cross_entropy(logits, y, label_smoothing=cfg.label_smoothing)\n",
        "        if torch.isnan(loss):\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "        opt.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = logits.argmax(dim=-1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            loss_sum += loss.item() * y.size(0)\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss_sum / total if total > 0 else 0,\n",
        "        \"acc\": correct / total if total > 0 else 0\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, cfg: Config):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(cfg.device), y.to(cfg.device)\n",
        "        logits = model(x)\n",
        "        ps.append(logits.argmax(dim=-1).cpu().numpy())\n",
        "        ys.append(y.cpu().numpy())\n",
        "\n",
        "    y_true, y_pred = np.concatenate(ys), np.concatenate(ps)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    return acc, f1\n",
        "\n",
        "def train_model(model, train_loader, val_loader, cfg: Config, model_name: str):\n",
        "    \"\"\"Train a single model\"\"\"\n",
        "    print(f\"\\n[Training {model_name}]\")\n",
        "\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "\n",
        "    best_acc, best_wts = 0.0, None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, cfg.epochs + 1):\n",
        "        stats = train_one_epoch(model, train_loader, opt, cfg)\n",
        "        val_acc, val_f1 = evaluate(model, val_loader, cfg)\n",
        "\n",
        "        if val_acc > best_acc + cfg.min_delta:\n",
        "            best_acc = val_acc\n",
        "            best_wts = copy.deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"  Epoch {epoch:3d}: Train Acc={stats['acc']:.4f}, Val Acc={val_acc:.4f}, F1={val_f1:.4f}\")\n",
        "\n",
        "        if patience_counter >= cfg.patience:\n",
        "            print(f\"  Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    if best_wts:\n",
        "        model.load_state_dict(best_wts)\n",
        "\n",
        "    print(f\"  Best Val Acc: {best_acc:.4f}\")\n",
        "    return best_acc\n",
        "\n",
        "def create_model(model_name: str, cfg: Config):\n",
        "    \"\"\"Create model by name\"\"\"\n",
        "    tpa_config = {\n",
        "        'num_prototypes': cfg.tpa_num_prototypes,\n",
        "        'heads': cfg.tpa_heads,\n",
        "        'dropout': cfg.tpa_dropout,\n",
        "        'temperature': cfg.tpa_temperature,\n",
        "        'topk_ratio': cfg.tpa_topk_ratio\n",
        "    }\n",
        "\n",
        "    if model_name == \"GAP\":\n",
        "        return GAPModel(d_model=cfg.d_model).to(cfg.device).float()\n",
        "    elif model_name == \"TPA\":\n",
        "        return TPAModel(d_model=cfg.d_model, tpa_config=tpa_config).to(cfg.device).float()\n",
        "    elif model_name == \"Gated-TPA\":\n",
        "        return GatedTPAModel(d_model=cfg.d_model, tpa_config=tpa_config).to(cfg.device).float()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "\n",
        "# ========================\n",
        "# Main Experiment\n",
        "# ========================\n",
        "def run_experiment(dataset_name: str, cfg: Config):\n",
        "    \"\"\"Run complete experiment for one dataset\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EXPERIMENT: {dataset_name}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Load data\n",
        "    train_dataset, test_dataset = load_dataset(cfg.data_dir, dataset_name)\n",
        "\n",
        "    # Split train into train/val using indices\n",
        "    n_total = len(train_dataset)\n",
        "    indices = np.arange(n_total)\n",
        "\n",
        "    # Get labels for stratification\n",
        "    y_labels = train_dataset.y.numpy()\n",
        "\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        indices,\n",
        "        test_size=cfg.val_split,\n",
        "        random_state=SEED,\n",
        "        stratify=y_labels\n",
        "    )\n",
        "\n",
        "    # Create subsets using Subset\n",
        "    from torch.utils.data import Subset\n",
        "    train_subset = Subset(train_dataset, train_indices)\n",
        "    val_subset = Subset(train_dataset, val_indices)\n",
        "\n",
        "    # Create data loaders\n",
        "    g = torch.Generator(device='cpu').manual_seed(SEED)\n",
        "    train_loader = DataLoader(train_subset, cfg.batch_size, shuffle=True,\n",
        "                              num_workers=cfg.num_workers, generator=g)\n",
        "    val_loader = DataLoader(val_subset, cfg.batch_size, num_workers=cfg.num_workers)\n",
        "    test_loader = DataLoader(test_dataset, cfg.batch_size, num_workers=cfg.num_workers)\n",
        "\n",
        "    print(f\"\\nDataset splits:\")\n",
        "    print(f\"  Train: {len(train_subset)}, Val: {len(val_subset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "    # Train and evaluate all models\n",
        "    results = []\n",
        "    model_names = [\"GAP\", \"TPA\", \"Gated-TPA\"]\n",
        "\n",
        "    for model_name in model_names:\n",
        "        # Reset seed for each model\n",
        "        random.seed(SEED)\n",
        "        np.random.seed(SEED)\n",
        "        torch.manual_seed(SEED)\n",
        "\n",
        "        # Create and train model\n",
        "        model = create_model(model_name, cfg)\n",
        "        best_val_acc = train_model(model, train_loader, val_loader, cfg, model_name)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_acc, test_f1 = evaluate(model, test_loader, cfg)\n",
        "\n",
        "        print(f\"\\n[{model_name} Results]\")\n",
        "        print(f\"  Val Acc: {best_val_acc:.4f}\")\n",
        "        print(f\"  Test Acc: {test_acc:.4f}, F1: {test_f1:.4f}\")\n",
        "\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Dataset': dataset_name,\n",
        "            'Val_Accuracy': float(best_val_acc),\n",
        "            'Test_Accuracy': float(test_acc),\n",
        "            'Test_F1_Score': float(test_f1)\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# ========================\n",
        "# Run All Experiments\n",
        "# ========================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"UNIFIED MODEL COMPARISON: GAP vs TPA vs Gated-TPA\")\n",
        "    print(\"Testing on 41 Datasets (1 Original + 40 Transition)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Define all 41 datasets\n",
        "    datasets = [\"WALKING_TO_DOWNSTAIRS_20pct\", \"WALKING_TO_DOWNSTAIRS_30pct\", \"WALKING_TO_DOWNSTAIRS_40pct\"]\n",
        "\n",
        "    transitions = [\n",
        "        \"UPSTAIRS_TO_WALKING\",\n",
        "        \"DOWNSTAIRS_TO_WALKING\"\n",
        "    ]\n",
        "\n",
        "    # 모든 전이에 대해 10%, 20%, 30%, 40% 추가\n",
        "    mix_pcts = [10, 20, 30, 40]\n",
        "\n",
        "    for transition in transitions:\n",
        "        for pct in mix_pcts:\n",
        "            datasets.append(f\"{transition}_{pct}pct\")\n",
        "\n",
        "    print(f\"\\nTotal datasets to test: {len(datasets)}\")\n",
        "    print(f\"  - transitions: {len(transitions) * len(mix_pcts) + 3}\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    # Run experiments\n",
        "    for i, dataset_name in enumerate(datasets, 1):\n",
        "        print(f\"\\n[Progress: {i}/{len(datasets)}]\")\n",
        "        results = run_experiment(dataset_name, cfg)\n",
        "        all_results.extend(results)\n",
        "\n",
        "    # Save all results\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SAVING RESULTS\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    results_dict = {\n",
        "        'experiment_info': {\n",
        "            'date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'models': ['GAP', 'TPA', 'Gated-TPA'],\n",
        "            'total_datasets': len(datasets),\n",
        "            'datasets': datasets,\n",
        "            'config': {\n",
        "                'epochs': cfg.epochs,\n",
        "                'batch_size': cfg.batch_size,\n",
        "                'lr': cfg.lr,\n",
        "                'd_model': cfg.d_model,\n",
        "                'tpa_num_prototypes': cfg.tpa_num_prototypes,\n",
        "                'tpa_heads': cfg.tpa_heads\n",
        "            }\n",
        "        },\n",
        "        'results': all_results\n",
        "    }\n",
        "\n",
        "    # Save to JSON\n",
        "    json_path = os.path.join(cfg.save_dir, \"unified_comparison_41datasets_results.json\")\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(results_dict, f, indent=2)\n",
        "\n",
        "    print(f\"\\nResults saved to: {json_path}\")\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Total experiments: {len(all_results)}\")\n",
        "    print(f\"Total datasets tested: {len(datasets)}\")\n",
        "    print(f\"Models compared: 3 (GAP, TPA, Gated-TPA)\")\n",
        "\n",
        "    # Calculate average performance per model\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"AVERAGE PERFORMANCE (All Datasets)\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    for model_name in ['GAP', 'TPA', 'Gated-TPA']:\n",
        "        model_results = [r for r in all_results if r['Model'] == model_name]\n",
        "        avg_acc = np.mean([r['Test_Accuracy'] for r in model_results])\n",
        "        avg_f1 = np.mean([r['Test_F1_Score'] for r in model_results])\n",
        "        print(f\"{model_name:12s}: Acc={avg_acc:.4f}, F1={avg_f1:.4f}\")\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"EXPERIMENT COMPLETE\")\n",
        "    print(f\"{'='*80}\")"
      ]
    }
  ]
}