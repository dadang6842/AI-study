{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoQaSIpuudkZuQNykOVdCe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dadang6842/AI-study/blob/main/practice/recurrence_regression/Univariate_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Univariate LSTM\n",
        "- 과거 한 가지 변수(예: 기온)만으로 미래 값을 예측\n",
        "- 참고 자료: https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
      ],
      "metadata": {
        "id": "8jLqzTaxnDg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(samples, timesteps. features)\n",
        "- samples: 학습용 샘플 총 개수\n",
        "- timesteps: 한 샘플당 바라보는 과거 시점의 개수\n",
        "- features: 각 시점에 측정된 변수의 개수"
      ],
      "metadata": {
        "id": "d6Oaf5sufvRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "LFi-Sq_hoHtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)"
      ],
      "metadata": {
        "id": "cfqD4oWxoKE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ],
      "metadata": {
        "id": "fJ_m1gCCpchk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanila LSTM"
      ],
      "metadata": {
        "id": "XQfQmfIhps0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features)) # reshape into [samples, timesteps, features]\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7jTmDLFrdGO",
        "outputId": "c4c0aeac-7797-47cf-dc1c-5104aea76163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fc7e66c18a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[102.65567]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacked LSTM\n",
        "return_sequences=True\n",
        "- 3D output -> 다음 LSTM layer에 입력할 수 있게끔"
      ],
      "metadata": {
        "id": "3_Sb0WoZsCEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX0vMN8Tr3IE",
        "outputId": "ac5ced3b-aac9-4480-867a-e22ec7049a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[103.64697]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional LSTM\n",
        "- 양방향 LSTM\n",
        "- 순방향 뿐만 아니라 역방향으로도 정보를 추출\n",
        "- 과거 정보 뿐만 아니라 미래 정보까지 반영하여 양방향 문맥 활용\n",
        "- Bidirectional(LSTM(...)) 형식으로 사용"
      ],
      "metadata": {
        "id": "pLdevrMpswaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate bidirectional lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Bidirectional\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDXP03Ubtnvm",
        "outputId": "2bd3ea36-5bbb-4901-9721-f18326676c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101.43526]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN LSTM\n",
        "- CNN이 입력의 부분 시퀀스를 해석, 해석 결과들이 모여 LSTM이 처리할 시퀀스를 이룸\n",
        "\n",
        "과정\n",
        "1. 원본 시계열 분할\n",
        "- 전체 시퀀스를 윈도우(window) 방식으로 자르고, (입력 길이=T_in, 출력 길이=T_out) 샘플 생성\n",
        "2. 부분 시퀀스(subsequence) 생성\n",
        "- 입력 길이 T_in을 n_seq개의 동일 크기 n_steps로 분할\n",
        "- T_in = n_seq × n_steps 여야 함\n",
        "3. 데이터 재구조화\n",
        "- 원래 (샘플, T_in, 피처) → (샘플, n_seq, n_steps, 피처)\n",
        "4. CNN 처리\n",
        "- TimeDistributed(Conv1D/Conv2D, …) 레이어로 각 부분 시퀀스별 특징 맵(feature map) 생성\n",
        "- TimeDistrubuted() subsequence 축(n_seq가 위치한 축(axis=1)을 따라 Conv1D 연산을 적용\n",
        "5. LSTM 처리\n",
        "- CNN 출력 시퀀스 (샘플, n_seq, CNN_피처) → LSTM → 최종 예측\n",
        "\n",
        "파라미터\n",
        "- n_seq: 부분 시퀀스 개수, LSTM에 공급되는 타입 스텝 수와 동일\n",
        "- n_steps: 각 부분 시퀀스의 길이, CNN이 한 번에 보는 시퀀스 길이\n",
        "\n",
        "kernel_size=1\n",
        "- 한 번에 1개의 time step만 읽겠다\n",
        "- 각 시점에 대해 독립적인 특징 추출이 필요하거나, 채널 확장 또는 축소가 필요할 때 사용\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "e.g.\n",
        "\n",
        "1. 원본 시계열 T_in = n_seq · n_steps\n",
        "- e.g. T_in = 4, n_seq = 2, n_steps = 2\n",
        "- [t1, t2, t3, t4] → [[t1, t2], [t3, t4]]\n",
        "\n",
        "2. 각 subsequence(길이 n_steps)에 CNN+Pooling+Flatten\n",
        "- [t1, t2] → CNN → Pool → Flatten → 64 차원 벡터 v₁\n",
        "- [t3, t4] → CNN → Pool → Flatten → 64 차원 벡터 v₂\n",
        "\n",
        "3. Flatten 결과\n",
        "- (batch, 2, 64) 형태.\n",
        "- 2는 subsequence 갯수(n_seq),\n",
        "- 64는 그 subsequence 당 뽑힌 특징(feature) 차원.\n",
        "\n",
        "4. LSTM 의 timesteps = n_seq\n",
        "- LSTM 은 [v₁, v₂] 라는 길이 2의 시퀀스를 보고,  각 vᵢ에는 “그 메타 시점(2 스텝 묶음)”의 요약된 특징이 담겨 있음\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "KzKWC1jfui5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate cnn lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, n_steps, n_features))\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features))) # n_seq를 런타임에 변경 가능\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=500, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = array([60, 70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XNmG0_vuhpj",
        "outputId": "61e66bc0-1305-46eb-918e-534b9bad89bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[100.42851]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConvLSTM\n",
        "- CNN 연산을 LSTM 셀 내부에서 수행함 → 공간 + 시간 정보를 동시에 학습\n",
        "- 2D 데이터를 처리하기 위해 고안\n",
        "- 입력 형태: [samples, timesteps, rows, columns, channels]\n",
        "- 예: (N, 10, 64, 64, 1) → 10장의 64x64 이미지를 시퀀스로 입력\n",
        "- 시계열 처리 시 row를 1로 설정\n",
        "\n",
        "CNN-LSTM과 비교\n",
        "- LSTM 셀 내부에서 Conv 연산 수행\n",
        "- CNN + LSTM이 한 셀 안에 있어 더 복잡한 패턴을 학습 -> 시공간 정보가 중요한 경우에 사용\n",
        "- CNN, LSTM을 따로 튜닝할 수 없음\n",
        "- 구조 복잡\n",
        "- 5D 입력이 필요해서 전처리 복잡도 상승"
      ],
      "metadata": {
        "id": "CtSrlSqS50BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# univariate convlstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import ConvLSTM2D\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 4\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps = 2\n",
        "X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_steps, n_features)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=500, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = array([60, 70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCHib_nW5zaI",
        "outputId": "ef6efc0b-ed8b-42d1-c531-22d765531058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101.17176]]\n"
          ]
        }
      ]
    }
  ]
}