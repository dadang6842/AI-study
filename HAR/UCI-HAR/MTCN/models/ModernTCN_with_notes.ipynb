{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "causal conv와 dilation을 적용하지 않은 이유\n",
        "- 시계열 예측 과제의 경우 인과성이 중요하지만 분류는 시계열 전체의 패턴을 학습하는 데 초점을 맞추기 때문에 모든 시점의 정보를 활용하는 것이 효과적\n",
        "- 대형 커널을 사용해서 넓은 수용 영역을 커버 -> dilation을 적용할 필요 없음"
      ],
      "metadata": {
        "id": "Tn-nmM0zijEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from layers.RevIN import RevIN\n",
        "from models.ModernTCN_Layer import series_decomp, Flatten_Head"
      ],
      "metadata": {
        "id": "UCpTmFeJKE5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LayerNorm\n",
        "- B: batch\n",
        "- M: 배치 안의 추가적인 그룹 차원 (변수 개수, patch, window 등)\n",
        "- D: feature/channel (LayerNorm이 적용되는 대상)\n",
        "- N: 시계열 길이 (sequence length, time steps)\n",
        "- Layernorm()은 마지막 차원을 정규화 대상으로 하기 때문에 permute()를 통해 마지막 차원이 feature(=D)가 되도록 바꿈\n",
        "- (B*M, N, D)에서 각 (N, D) 조각마다 feature 차원(D)에 대해 정규화가 이루어짐"
      ],
      "metadata": {
        "id": "HIYYh-heLXk1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU5pk05-J_qw"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, channels, eps=1e-6, data_format=\"channels_last\"):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.norm = nn.Layernorm(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        B, M, D, N = x.shape\n",
        "        x = x.permute(0, 1, 3, 2)\n",
        "        x = x.reshape(B * M, N, D)\n",
        "        x = self.norm(\n",
        "            x)\n",
        "        x = x.reshape(B, M, N, D)\n",
        "        x = x.permute(0, 1, 3, 2)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias):\n",
        "    return nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                     padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
        "\n",
        "\n",
        "def get_bn(channels):\n",
        "    return nn.BatchNorm1d(channels)\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups, dilation=1,bias=False):\n",
        "    if padding is None:\n",
        "        padding = kernel_size // 2\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', get_conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                         stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias))\n",
        "    result.add_module('bn', get_bn(out_channels))\n",
        "    return result"
      ],
      "metadata": {
        "id": "0q6a4Nh0NlaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fuse_bn()\n",
        "- BN을 포함한 Conv는 새로운 Conv 하나로 대체할 수 있음\n",
        "- BN 식을 Conv 출력에 직접 대입해 weight와 bias를 다시 정의\n",
        "- 추론 시 BN 레이어를 제거할 수 있어서 속도와 메모리 효율이 개선됨\n",
        "- 반환값은 새로운 Conv 파라미터인 fused_weight, fused_bias"
      ],
      "metadata": {
        "id": "DU9mp4fiO6D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fuse_bn(conv, bn):\n",
        "\n",
        "    kernel = conv.weight\n",
        "    running_mean = bn.running_mean\n",
        "    running_var = bn.running_var\n",
        "    gamma = bn.weight\n",
        "    beta = bn.bias\n",
        "    eps = bn.eps\n",
        "    std = (running_var + eps).sqrt()\n",
        "    t = (gamma / std).reshape(-1, 1, 1)\n",
        "    return kernel * t, beta - running_mean * gamma / std"
      ],
      "metadata": {
        "id": "pqivPgYLOCkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReparamLargeKernelConv\n",
        " structural re-parameterization\n",
        " - 큰 커널을 작은 커널과 함께 학습하다가 추론 시에 하나의 Conv로 합쳐서 연산 효율을 높임\n",
        " - Conv는 선형 연산이므로 weight와 bias를 합쳐줄 수 있음\n",
        "- RepLKNet 같은 대형 커널 기반 네트워크에서 쓰인 아이디어\n",
        "\n",
        "`__init__`\n",
        "- lkb_origin: 큰 커널 Conv + BN\n",
        "- small_conv: 작은 커널 Conv + BN (선택적, None이면 없음)\n",
        "- lkb_reparam: 추론 시 사용할 단일 Conv (처음엔 없음)\n",
        "- small_kernel_merged=True라면 학습할 때도 이미 합쳐진 Conv를 쓰도록 설정\n",
        "\n",
        "`forward`\n",
        "- 추론 모드에서 merge_kernel()을 이미 실행했다면 → lkb_reparam 하나만 실행\n",
        "- 학습 모드라면 → 큰 커널 conv + 작은 커널 conv를 동시에 실행하고 결과를 합산\n",
        "\n",
        "`PaddingTwoEdge1d()`\n",
        "- 작은 커널을 큰 커널 크기로 맞추기 위해 좌우에 패딩 추가\n",
        "- x는 Conv weight, shape은 (out_channels, in_channels, kernel_size)\n",
        "\n",
        "\n",
        "`get_equivalent_kernel_bias`\n",
        "- Conv+BN → Conv로 바꾼 후 large/small conv를 합산\n",
        "1. 큰 커널 Conv+BN → fuse_bn()으로 합침 → (eq_k, eq_b)\n",
        "2. 작은 커널도 Conv+BN 합침 → (small_k, small_b)\n",
        "3. bias는 그냥 더하고 kernel은 작은 커널을 패딩으로 확장한 후 더함\n",
        "- 최종적으로 large, small을 합친 kernel, bias를 반환\n",
        "\n",
        "`merge_kernel`\n",
        "- 추론용 Conv(큰 커널, 작은 커널 합친 것)으로 변환\n",
        "- weight는 nn.Parameter, nn.Parameter의 .data 속성에 직접 할당하면 gradient 추적을 거치지 않고 바로 값을 바꿈 (추론 단계여서 gradient는 필요 없음)\n",
        "- `__delattr__`: 기존 1kb_origin, small_conv는 삭제\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gvn6qp2ZR-PJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReparamLargeKernelConv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride, groups,\n",
        "                 small_kernel,\n",
        "                 small_kernel_merged=False, nvars=7):\n",
        "        super(ReparamLargeKernelConv, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.small_kernel = small_kernel\n",
        "        # We assume the conv does not change the feature map size, so padding = k//2. Otherwise, you may configure padding as you wish, and change the padding of small_conv accordingly.\n",
        "        padding = kernel_size // 2\n",
        "        if small_kernel_merged:\n",
        "            self.lkb_reparam = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                         stride=stride, padding=padding, dilation=1, groups=groups, bias=True)\n",
        "        else:\n",
        "            self.lkb_origin = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                        stride=stride, padding=padding, dilation=1, groups=groups,bias=False)\n",
        "            if small_kernel is not None:\n",
        "                assert small_kernel <= kernel_size, 'The kernel size for re-param cannot be larger than the large kernel!'\n",
        "                self.small_conv = conv_bn(in_channels=in_channels, out_channels=out_channels,\n",
        "                                            kernel_size=small_kernel,\n",
        "                                            stride=stride, padding=small_kernel // 2, groups=groups, dilation=1,bias=False)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        if hasattr(self, 'lkb_reparam'):\n",
        "            out = self.lkb_reparam(inputs)\n",
        "        else:\n",
        "            out = self.lkb_origin(inputs)\n",
        "            if hasattr(self, 'small_conv'):\n",
        "                out += self.small_conv(inputs)\n",
        "        return out\n",
        "\n",
        "    def PaddingTwoEdge1d(self,x,pad_length_left,pad_length_right,pad_values=0):\n",
        "\n",
        "        D_out,D_in,ks=x.shape\n",
        "        if pad_values ==0:\n",
        "            pad_left = torch.zeros(D_out,D_in,pad_length_left)\n",
        "            pad_right = torch.zeros(D_out,D_in,pad_length_right)\n",
        "        else:\n",
        "            pad_left = torch.ones(D_out, D_in, pad_length_left) * pad_values\n",
        "            pad_right = torch.ones(D_out, D_in, pad_length_right) * pad_values\n",
        "        x = torch.cat([pad_left,x],dims=-1)\n",
        "        x = torch.cat([x,pad_right],dims=-1)\n",
        "        return x\n",
        "\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        eq_k, eq_b = fuse_bn(self.lkb_origin.conv, self.lkb_origin.bn)\n",
        "        if hasattr(self, 'small_conv'):\n",
        "            small_k, small_b = fuse_bn(self.small_conv.conv, self.small_conv.bn)\n",
        "            eq_b += small_b\n",
        "            eq_k += self.PaddingTwoEdge1d(small_k, (self.kernel_size - self.small_kernel) // 2,\n",
        "                                          (self.kernel_size - self.small_kernel) // 2, 0)\n",
        "        return eq_k, eq_b\n",
        "\n",
        "    def merge_kernel(self):\n",
        "        eq_k, eq_b = self.get_equivalent_kernel_bias()\n",
        "        self.lkb_reparam = nn.Conv1d(in_channels=self.lkb_origin.conv.in_channels,\n",
        "                                     out_channels=self.lkb_origin.conv.out_channels,\n",
        "                                     kernel_size=self.lkb_origin.conv.kernel_size, stride=self.lkb_origin.conv.stride,\n",
        "                                     padding=self.lkb_origin.conv.padding, dilation=self.lkb_origin.conv.dilation,\n",
        "                                     groups=self.lkb_origin.conv.groups, bias=True)\n",
        "        self.lkb_reparam.weight.data = eq_k\n",
        "        self.lkb_reparam.bias.data = eq_b\n",
        "        self.__delattr__('lkb_origin')\n",
        "        if hasattr(self, 'small_conv'):\n",
        "            self.__delattr__('small_conv')"
      ],
      "metadata": {
        "id": "bO_VbP0tQbl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block\n",
        "`convffn1`\n",
        "- groups=nvars로 설정\n",
        "`convffn2`\n",
        "- groups=dmoel로 설정\n",
        "\n",
        "### **reshape을 이해해보자!**\n",
        "- B: batch, M: 변수 개수, D: dmodel(각 변수의 feature 차원), N: sequence length\n",
        "- Conv1d, BatchNorm은 (batch, channels, length)를 받기를 기대함\n",
        "#### 1. depthwise large-kernel conv\n",
        "\n",
        "```\n",
        "x = x.reshape(B,M*D,N)\n",
        "x = self.dw(x)\n",
        "```\n",
        "- 목표: 각 변수-특징 조합마다 독립적으로 1D conv 적용\n",
        "- M*D개의 channel을 독립적으로 convolve -> depthwise conv\n",
        "\n",
        "#### 2. BatchNorm\n",
        "```\n",
        "x = x.reshape(B*M, D, N)\n",
        "self.norm(x)\n",
        "```\n",
        "- 목표: 각 변수(M)별로 독립적인 정규화\n",
        "- BatchNorm은 channels=D를 정규화\n",
        "- 변수 M개를 batch 차원에 흡수시킴으로써 변수마다 D차원 feature를 정규화할 수 있음\n",
        "\n",
        "#### 3. FFN1\n",
        "```\n",
        "x = x.reshape(B, M*D, N)\n",
        "self.ffn1pw1(x)\n",
        "```\n",
        "- 목표: 변수별 독립 FFN\n",
        "- M*D를 채널로 묶고 groups=M(nvar)으로 지정\n",
        "- 각 그룹 크기는 D -> 변수별로 D차원 묶음을 독립적으로 처리\n",
        "\n",
        "#### 4. FFN2\n",
        "```\n",
        "x = x.permute(0, 2, 1, 3)   # (B, D, M, N)\n",
        "x = x.reshape(B, D*M, N)\n",
        "self.ffn2pw1(x)\n",
        "```\n",
        "- 목표: feature별 cross-variable 연산 (변수 간 상관관계 학습, MTCN의 핵심)\n",
        "- D*M을 채널로 묶고 groups=D로 설정\n",
        "- 각 그룹 크기는 M, 같은 feature index(D) 안에서 변수 M개를 묶어 연산\n",
        "\n",
        "#### 5. 마지막에 residual connection"
      ],
      "metadata": {
        "id": "7YKpSwXa91ll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GELU()**\n",
        "- Gaussian Error Linear Unit\n",
        "- ReLU와 유사하지만 음수에서 기울기가 조금 있고, 양수 부분도 선형 증가가 아닌 약간 곡선 형식\n",
        "- ReLU보다 부드러워서 gradient 흐름이 원할\n",
        "- Transformer 같은 대규모 모델에서 안정성과 성능이 좋음\n",
        "- 언어/시계열/연속 패턴 데이터에서 성능 우위\n"
      ],
      "metadata": {
        "id": "Cn2xQSrmFA98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, large_size, small_size, dmodel, dff, nvars, small_kernel_merged=False, drop=0.1):\n",
        "\n",
        "        super(Block, self).__init__()\n",
        "        self.dw = ReparamLargeKernelConv(in_channels=nvars * dmodel, out_channels=nvars * dmodel,\n",
        "                                         kernel_size=large_size, stride=1, groups=nvars * dmodel,\n",
        "                                         small_kernel=small_size, small_kernel_merged=small_kernel_merged, nvars=nvars)\n",
        "        self.norm = nn.BatchNorm1d(dmodel)\n",
        "\n",
        "        #convffn1\n",
        "        self.ffn1pw1 = nn.Conv1d(in_channels=nvars * dmodel, out_channels=nvars * dff, kernel_size=1, stride=1,\n",
        "                                 padding=0, dilation=1, groups=nvars)\n",
        "        self.ffn1act = nn.GELU()\n",
        "        self.ffn1pw2 = nn.Conv1d(in_channels=nvars * dff, out_channels=nvars * dmodel, kernel_size=1, stride=1,\n",
        "                                 padding=0, dilation=1, groups=nvars)\n",
        "        self.ffn1drop1 = nn.Dropout(drop)\n",
        "        self.ffn1drop2 = nn.Dropout(drop)\n",
        "\n",
        "        #convffn2\n",
        "        self.ffn2pw1 = nn.Conv1d(in_channels=nvars * dmodel, out_channels=nvars * dff, kernel_size=1, stride=1,\n",
        "                                 padding=0, dilation=1, groups=dmodel)\n",
        "        self.ffn2act = nn.GELU()\n",
        "        self.ffn2pw2 = nn.Conv1d(in_channels=nvars * dff, out_channels=nvars * dmodel, kernel_size=1, stride=1,\n",
        "                                 padding=0, dilation=1, groups=dmodel)\n",
        "        self.ffn2drop1 = nn.Dropout(drop)\n",
        "        self.ffn2drop2 = nn.Dropout(drop)\n",
        "\n",
        "        self.ffn_ratio = dff//dmodel\n",
        "    def forward(self,x):\n",
        "\n",
        "        input = x\n",
        "        B, M, D, N = x.shape\n",
        "        x = x.reshape(B,M*D,N)\n",
        "        x = self.dw(x)\n",
        "        x = x.reshape(B,M,D,N)\n",
        "        x = x.reshape(B*M,D,N)\n",
        "        x = self.norm(x)\n",
        "        x = x.reshape(B, M, D, N)\n",
        "        x = x.reshape(B, M * D, N)\n",
        "\n",
        "        x = self.ffn1drop1(self.ffn1pw1(x))\n",
        "        x = self.ffn1act(x)\n",
        "        x = self.ffn1drop2(self.ffn1pw2(x))\n",
        "        x = x.reshape(B, M, D, N)\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "        x = x.reshape(B, D * M, N)\n",
        "        x = self.ffn2drop1(self.ffn2pw1(x))\n",
        "        x = self.ffn2act(x)\n",
        "        x = self.ffn2drop2(self.ffn2pw2(x))\n",
        "        x = x.reshape(B, D, M, N)\n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "\n",
        "        x = input + x\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "bw_JzxETZ6-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage\n",
        "- block을 순차적으로 쌓아주는 역할\n",
        "- dff: FFN의 내부 확장 차원 역할\n",
        "- 복잡한 패턴 학습 후 원래 차원으로 압축"
      ],
      "metadata": {
        "id": "AkuQhoRrGqy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Stage(nn.Module):\n",
        "    def __init__(self, ffn_ratio, num_blocks, large_size, small_size, dmodel, dw_model, nvars,\n",
        "                 small_kernel_merged=False, drop=0.1):\n",
        "\n",
        "        super(Stage, self).__init__()\n",
        "        d_ffn = dmodel * ffn_ratio\n",
        "        blks = []\n",
        "        for i in range(num_blocks):\n",
        "            blk = Block(large_size=large_size, small_size=small_size, dmodel=dmodel, dff=d_ffn, nvars=nvars, small_kernel_merged=small_kernel_merged, drop=drop)\n",
        "            blks.append(blk)\n",
        "\n",
        "        self.blocks = nn.ModuleList(blks)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "pYhujSbMGRWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ModernTCN\n",
        "### `__init__`\n",
        "1. RevIN 정규화 사용 가능\n",
        "\n",
        "2. Stem\n",
        "- 입력 시계열을 patch_size 단위로 자름\n",
        "\n",
        "3. stage 사이마다 dowmsample\n",
        "4. stage마다 num_blocks개의 block을 쌓음 -> 각 block은 ReparamLargeKernelConv + FFN1 + FFN2 + Residual\n",
        "5. head\n",
        "- use_multi_scale=True면 모든 patch를 flatten해서 head에 넣음, patch 단위 정보 전체를 보존 -> 다양한 시간 범위 패턴 학습\n",
        "- False면, downsampling을 통해 줄어든 patch 개수에 맞춰 flatten해서 head에 넣음 -> 계산량은 줄지만 정보 손실\n",
        "6. classification 과제면 Linear를 마지막에 붙임\n",
        "\n",
        "### `forward_feature`\n",
        "- 입력 시계열 -> 패치 -> 다운샘플링 -> 여러 stage 통과 -> feature map\n",
        "1. (B, M, L) -> (B, M, 1, L) 변환\n",
        "- 1은 channel 축처럼 사용됨 (conv1d 맞추기용)\n",
        "2. stage별로 downsample (Conv1d) 적용, 필요 시 padding\n",
        "3. Stage(Block stack) 통과\n",
        "4. 최종 (B, M, D, N) feature map 반환\n",
        "\n",
        "### `structural_reparam`\n",
        "- merge_kernel() 메소드를 가진 모듈(=ReparamLargeKernelConv)만 골라서 실행\n",
        "- m.merge_kernel(): 학습 시 분리돼 있던 여러 Conv + BN을 하나의 Conv로 합침"
      ],
      "metadata": {
        "id": "TeV8ZuKDJ3TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModernTCN(nn.Module):\n",
        "    def __init__(self,task_name,patch_size,patch_stride, stem_ratio, downsample_ratio, ffn_ratio, num_blocks, large_size, small_size, dims, dw_dims,\n",
        "                 nvars, small_kernel_merged=False, backbone_dropout=0.1, head_dropout=0.1, use_multi_scale=True, revin=True, affine=True,\n",
        "                 subtract_last=False, freq=None, seq_len=512, c_in=7, individual=False, target_window=96, class_drop=0.,class_num = 10):\n",
        "\n",
        "        super(ModernTCN, self).__init__()\n",
        "\n",
        "        self.task_name = task_name\n",
        "        self.class_drop = class_drop\n",
        "        self.class_num = class_num\n",
        "\n",
        "\n",
        "        # RevIN\n",
        "        self.revin = revin\n",
        "        if self.revin: self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
        "\n",
        "        # stem layer & down sampling layers\n",
        "        self.downsample_layers = nn.ModuleList()\n",
        "        stem = nn.Sequential(\n",
        "            nn.Conv1d(1, dims[0], kernel_size=patch_size, stride=patch_stride),\n",
        "            nn.BatchNorm1d(dims[0])\n",
        "        )\n",
        "        self.downsample_layers.append(stem)\n",
        "\n",
        "        self.num_stage = len(num_blocks)\n",
        "        if self.num_stage > 1:\n",
        "            for i in range(self.num_stage - 1):\n",
        "                downsample_layer = nn.Sequential(\n",
        "                    nn.BatchNorm1d(dims[i]),\n",
        "                    nn.Conv1d(dims[i], dims[i + 1], kernel_size=downsample_ratio, stride=downsample_ratio),\n",
        "                )\n",
        "                self.downsample_layers.append(downsample_layer)\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "        self.patch_stride = patch_stride\n",
        "        self.downsample_ratio = downsample_ratio\n",
        "\n",
        "        # backbone\n",
        "        self.num_stage = len(num_blocks)\n",
        "        self.stages = nn.ModuleList()\n",
        "        for stage_idx in range(self.num_stage):\n",
        "            layer = Stage(ffn_ratio, num_blocks[stage_idx], large_size[stage_idx], small_size[stage_idx], dmodel=dims[stage_idx],\n",
        "                          dw_model=dw_dims[stage_idx], nvars=nvars, small_kernel_merged=small_kernel_merged, drop=backbone_dropout)\n",
        "            self.stages.append(layer)\n",
        "\n",
        "\n",
        "        # head\n",
        "        patch_num = seq_len // patch_stride\n",
        "        self.n_vars = c_in\n",
        "        self.individual = individual\n",
        "        d_model = dims[self.num_stage-1]\n",
        "\n",
        "\n",
        "        if use_multi_scale:\n",
        "            self.head_nf = d_model * patch_num\n",
        "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, target_window,\n",
        "                                     head_dropout=head_dropout)\n",
        "        else:\n",
        "            if patch_num % pow(downsample_ratio,(self.num_stage - 1)) == 0:\n",
        "                self.head_nf = d_model * patch_num // pow(downsample_ratio,(self.num_stage - 1))\n",
        "            else:\n",
        "                self.head_nf = d_model * (patch_num // pow(downsample_ratio, (self.num_stage - 1))+1)\n",
        "\n",
        "\n",
        "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, target_window,\n",
        "                                     head_dropout=head_dropout)\n",
        "\n",
        "        if self.task_name == 'classification':\n",
        "            self.act_class = F.gelu\n",
        "            self.class_dropout = nn.Dropout(self.class_drop)\n",
        "\n",
        "            self.head_class = nn.Linear(self.n_vars[0]*self.head_nf,self.class_num)\n",
        "\n",
        "\n",
        "    def forward_feature(self, x, te=None):\n",
        "\n",
        "        B,M,L=x.shape\n",
        "\n",
        "        x = x.unsqueeze(-2) # (B, M, 1, L)\n",
        "\n",
        "        for i in range(self.num_stage):\n",
        "            B, M, D, N = x.shape\n",
        "            x = x.reshape(B * M, D, N) # Conv1D 입력 형식(batch, channels, length)에 맞춰서 변환\n",
        "            if i==0: # 첫 stage\n",
        "                if self.patch_size != self.patch_stride: # patch_stride < patch_size인 경우 마지막에 patch를 하나 더 만들 수 있게 padding\n",
        "                    # stem layer padding\n",
        "                    pad_len = self.patch_size - self.patch_stride\n",
        "                    pad = x[:,:,-1:].repeat(1,1,pad_len)\n",
        "                    x = torch.cat([x,pad],dim=-1)\n",
        "            else: # 이후 stage\n",
        "                if N % self.downsample_ratio != 0: # downsample conv의 stride 때문에 길이가 안 나눠떨어질 수 있음 -> 마지막 구간 패딩\n",
        "                    pad_len = self.downsample_ratio - (N % self.downsample_ratio)\n",
        "                    x = torch.cat([x, x[:, :, -pad_len:]],dim=-1)\n",
        "            x = self.downsample_layers[i](x)\n",
        "            _, D_, N_ = x.shape\n",
        "            x = x.reshape(B, M, D_, N_)\n",
        "            x = self.stages[i](x)\n",
        "        return x\n",
        "\n",
        "    def classification(self,x):\n",
        "\n",
        "        x =  self.forward_feature(x,te=None)\n",
        "        x = self.act_class(x)\n",
        "        x = self.class_dropout(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.head_class(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x, te=None):\n",
        "\n",
        "        if self.task_name == 'classification':\n",
        "            x = self.classification(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def structural_reparam(self):\n",
        "        for m in self.modules():\n",
        "            if hasattr(m, 'merge_kernel'):\n",
        "                m.merge_kernel()"
      ],
      "metadata": {
        "id": "ZaALa34RIlW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "forward의 인자\n",
        "- x: 입력 시계열 데이터 (실제로 쓰이는 유일한 값)\n",
        "- x_mark_enc: 인코더용 시간 인코딩 (호환성용, 여기선 안 씀)\n",
        "- x_dec / x_mark_dec: 디코더 입력/시간 인코딩 (여기선 안 씀)\n",
        "- mask: attention 모델용 mask (여기선 안 씀)\n",
        "- te: temporal encoding (현재는 None으로 비활성화)\n",
        "- forecasting, seq2seq 모델 전반에서 쓰이는 인터페이스를 맞추기 위해 들어있는 인자"
      ],
      "metadata": {
        "id": "3OVFFFa6UBSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, configs):\n",
        "        super(Model, self).__init__()\n",
        "        # hyper param\n",
        "        self.task_name = configs.task_name\n",
        "        self.stem_ratio = configs.stem_ratio\n",
        "        self.downsample_ratio = configs.downsample_ratio\n",
        "        self.ffn_ratio = configs.ffn_ratio\n",
        "        self.num_blocks = configs.num_blocks\n",
        "        self.large_size = configs.large_size\n",
        "        self.small_size = configs.small_size\n",
        "        self.dims = configs.dims\n",
        "        self.dw_dims = configs.dw_dims\n",
        "\n",
        "        self.nvars = configs.enc_in\n",
        "        self.small_kernel_merged = configs.small_kernel_merged\n",
        "        self.drop_backbone = configs.dropout\n",
        "        self.drop_head = configs.head_dropout\n",
        "        self.use_multi_scale = configs.use_multi_scale\n",
        "        self.revin = configs.revin\n",
        "        self.affine = configs.affine\n",
        "        self.subtract_last = configs.subtract_last\n",
        "\n",
        "        self.freq = configs.freq\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.c_in = self.nvars,\n",
        "        self.individual = configs.individual\n",
        "        self.target_window = configs.pred_len\n",
        "\n",
        "        self.kernel_size = configs.kernel_size\n",
        "        self.patch_size = configs.patch_size\n",
        "        self.patch_stride = configs.patch_stride\n",
        "\n",
        "        #classification\n",
        "        self.class_dropout = configs.class_dropout\n",
        "        self.class_num = configs.num_class\n",
        "\n",
        "\n",
        "        # decomp\n",
        "        self.decomposition = configs.decomposition\n",
        "\n",
        "\n",
        "        self.model = ModernTCN(task_name=self.task_name,patch_size=self.patch_size, patch_stride=self.patch_stride, stem_ratio=self.stem_ratio,\n",
        "                           downsample_ratio=self.downsample_ratio, ffn_ratio=self.ffn_ratio, num_blocks=self.num_blocks,\n",
        "                           large_size=self.large_size, small_size=self.small_size, dims=self.dims, dw_dims=self.dw_dims,\n",
        "                           nvars=self.nvars, small_kernel_merged=self.small_kernel_merged,\n",
        "                           backbone_dropout=self.drop_backbone, head_dropout=self.drop_head,\n",
        "                           use_multi_scale=self.use_multi_scale, revin=self.revin, affine=self.affine,\n",
        "                           subtract_last=self.subtract_last, freq=self.freq, seq_len=self.seq_len, c_in=self.c_in,\n",
        "                           individual=self.individual, target_window=self.target_window,\n",
        "                            class_drop = self.class_dropout, class_num = self.class_num)\n",
        "\n",
        "    def forward(self, x, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        te = None\n",
        "        x = self.model(x, te)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7SdR6laCTTwR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}